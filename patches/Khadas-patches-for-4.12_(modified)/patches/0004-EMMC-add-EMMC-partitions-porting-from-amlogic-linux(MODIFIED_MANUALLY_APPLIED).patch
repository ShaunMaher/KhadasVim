From 3e80c0fde99b27f678dd264061f158b2bcbfa11c Mon Sep 17 00:00:00 2001
From: nick <nick@khadas.com>
Date: Thu, 22 Jun 2017 18:00:56 +0800
Subject: [PATCH 4/9] EMMC: add EMMC partitions (porting from amlogic linux
 4.9.26)

---
 .../dts/amlogic/meson-gxl-s905x-khadas-vim.dts     |    1 +
 arch/arm64/boot/dts/amlogic/partitions.dtsi        |   44 +
 arch/arm64/configs/kvim_defconfig                  |    4 +
 drivers/Kconfig                                    |    2 +
 drivers/Makefile                                   |    1 +
 drivers/amlogic/Kconfig                            |   30 +
 drivers/amlogic/Makefile                           |    5 +
 drivers/amlogic/iomap/Kconfig                      |    7 +
 drivers/amlogic/iomap/Makefile                     |    1 +
 drivers/amlogic/iomap/iomap.c                      |  270 ++
 drivers/amlogic/mmc/Kconfig                        |   30 +
 drivers/amlogic/mmc/Makefile                       |    7 +
 drivers/amlogic/mmc/aml_sd_emmc.c                  | 2934 ++++++++++++++++++++
 drivers/amlogic/mmc/aml_sdhc_m8.c                  | 2477 +++++++++++++++++
 drivers/amlogic/mmc/aml_sdio.c                     | 1367 +++++++++
 drivers/amlogic/mmc/amlsd.c                        |  853 ++++++
 drivers/amlogic/mmc/amlsd_of.c                     |  216 ++
 drivers/amlogic/mmc/emmc_key.c                     |  213 ++
 drivers/amlogic/mmc/emmc_key.h                     |   74 +
 drivers/amlogic/mmc/emmc_partitions.c              | 1018 +++++++
 drivers/mmc/core/block.c                           |   10 +
 include/linux/amlogic/amlsd.h                      |  239 ++
 include/linux/amlogic/cpu_version.h                |  144 +
 include/linux/amlogic/iomap.h                      |   83 +
 include/linux/amlogic/key_manage.h                 |   37 +
 include/linux/amlogic/sd.h                         | 1514 ++++++++++
 include/linux/mmc/card.h                           |   26 +
 include/linux/mmc/emmc_partitions.h                |   78 +
 include/linux/mmc/host.h                           |    6 +
 29 files changed, 11691 insertions(+)
 create mode 100644 arch/arm64/boot/dts/amlogic/partitions.dtsi
 create mode 100644 drivers/amlogic/Kconfig
 create mode 100644 drivers/amlogic/Makefile
 create mode 100644 drivers/amlogic/iomap/Kconfig
 create mode 100644 drivers/amlogic/iomap/Makefile
 create mode 100644 drivers/amlogic/iomap/iomap.c
 create mode 100644 drivers/amlogic/mmc/Kconfig
 create mode 100644 drivers/amlogic/mmc/Makefile
 create mode 100644 drivers/amlogic/mmc/aml_sd_emmc.c
 create mode 100644 drivers/amlogic/mmc/aml_sdhc_m8.c
 create mode 100644 drivers/amlogic/mmc/aml_sdio.c
 create mode 100644 drivers/amlogic/mmc/amlsd.c
 create mode 100644 drivers/amlogic/mmc/amlsd_of.c
 create mode 100644 drivers/amlogic/mmc/emmc_key.c
 create mode 100644 drivers/amlogic/mmc/emmc_key.h
 create mode 100644 drivers/amlogic/mmc/emmc_partitions.c
 create mode 100644 include/linux/amlogic/amlsd.h
 create mode 100644 include/linux/amlogic/cpu_version.h
 create mode 100644 include/linux/amlogic/iomap.h
 create mode 100644 include/linux/amlogic/key_manage.h
 create mode 100644 include/linux/amlogic/sd.h
 create mode 100644 include/linux/mmc/emmc_partitions.h

diff --git a/arch/arm64/boot/dts/amlogic/meson-gxl-s905x-khadas-vim.dts b/arch/arm64/boot/dts/amlogic/meson-gxl-s905x-khadas-vim.dts
index 329fe71..5df1dbc 100644
--- a/arch/arm64/boot/dts/amlogic/meson-gxl-s905x-khadas-vim.dts
+++ b/arch/arm64/boot/dts/amlogic/meson-gxl-s905x-khadas-vim.dts
@@ -9,6 +9,7 @@
 #include <dt-bindings/input/input.h>

 #include "meson-gxl-s905x-p212.dtsi"
+#include "partitions.dtsi"

 / {
 	compatible = "khadas,vim", "amlogic,s905x", "amlogic,meson-gxl";
diff --git a/arch/arm64/boot/dts/amlogic/partitions.dtsi b/arch/arm64/boot/dts/amlogic/partitions.dtsi
new file mode 100644
index 0000000..a35161a
--- /dev/null
+++ b/arch/arm64/boot/dts/amlogic/partitions.dtsi
@@ -0,0 +1,44 @@
+/*
+ * arch/arm64/boot/dts/partitions.dtsi
+ * Partitions for Linux Distro(i.e. Ubuntu)
+ *
+ * Copyright (C) 2017 Khadsa.com All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+*/
+
+/ {
+	partitions: partitions{
+        parts = <3>;
+		part-0 = <&logo>;
+		part-1 = <&ramdisk>;
+		part-2 = <&rootfs>;
+
+		logo:logo{
+			pname = "logo";
+			size = <0x0 0x2000000>;
+			mask = <1>;
+		};
+		ramdisk:ramdisk
+		{
+			pname = "ramdisk";
+			size = <0x0 0x2000000>;
+			mask = <1>;
+		};
+		rootfs:rootfs
+		{
+			pname = "rootfs";
+			size = <0xffffffff 0xffffffff>;
+			mask = <4>;
+		};
+	};
+};
diff --git a/arch/arm64/configs/kvim_defconfig b/arch/arm64/configs/kvim_defconfig
index e66cead..7ff1c19 100644
--- a/arch/arm64/configs/kvim_defconfig
+++ b/arch/arm64/configs/kvim_defconfig
@@ -140,6 +140,10 @@ CONFIG_MAC80211_LEDS=y
 CONFIG_RFKILL=y
 CONFIG_NET_9P=y
 CONFIG_NET_9P_VIRTIO=y
+CONFIG_AMLOGIC_DRIVER=y
+CONFIG_AMLOGIC_MODIFY=y
+CONFIG_AMLOGIC_IOMAP=y
+CONFIG_AMLOGIC_MMC=y
 CONFIG_UEVENT_HELPER_PATH="/sbin/hotplug"
 CONFIG_DEVTMPFS=y
 CONFIG_DEVTMPFS_MOUNT=y
diff --git a/drivers/amlogic/Kconfig b/drivers/amlogic/Kconfig
new file mode 100644
index 0000000..24e0724
--- /dev/null
+++ b/drivers/amlogic/Kconfig
@@ -0,0 +1,30 @@
+#
+# Amlogic driver configuration
+#
+config AMLOGIC_DRIVER
+	bool "Amlogic Peripheral drivers"
+	default n
+	help
+		this option is provided for control amlogic
+		drivers, if you want to use amlogic driver
+		please open it
+
+config AMLOGIC_MODIFY
+	bool "Amlogic modify for kernel code"
+	default n
+	help
+		this option is set up for AMLOGIC modify of
+		standard kernel source code. All modify of kernel
+		standard code should be wrapped by this config
+
+if AMLOGIC_DRIVER
+menu "Amlogic Device Drivers"
+
+source "drivers/amlogic/iomap/Kconfig"
+
+source "drivers/amlogic/mmc/Kconfig"
+
+
+
+endmenu
+endif
diff --git a/drivers/amlogic/Makefile b/drivers/amlogic/Makefile
new file mode 100644
index 0000000..b5eb5a9
--- /dev/null
+++ b/drivers/amlogic/Makefile
@@ -0,0 +1,5 @@
+
+
+obj-$(CONFIG_AMLOGIC_MMC)             += mmc/
+
+obj-$(CONFIG_AMLOGIC_IOMAP)     += iomap/
diff --git a/drivers/amlogic/iomap/Kconfig b/drivers/amlogic/iomap/Kconfig
new file mode 100644
index 0000000..2e3acd1
--- /dev/null
+++ b/drivers/amlogic/iomap/Kconfig
@@ -0,0 +1,7 @@
+# Amlogic iomap driver
+#
+config AMLOGIC_IOMAP
+    bool "Amlogic iomap support"
+    select REGMAP_MMIO
+    help
+      This is the Amlogic Iomap  driver
diff --git a/drivers/amlogic/iomap/Makefile b/drivers/amlogic/iomap/Makefile
new file mode 100644
index 0000000..a12a73d
--- /dev/null
+++ b/drivers/amlogic/iomap/Makefile
@@ -0,0 +1 @@
+obj-$(CONFIG_AMLOGIC_IOMAP)	+=iomap.o
diff --git a/drivers/amlogic/iomap/iomap.c b/drivers/amlogic/iomap/iomap.c
new file mode 100644
index 0000000..d39f69c
--- /dev/null
+++ b/drivers/amlogic/iomap/iomap.c
@@ -0,0 +1,270 @@
+/*
+ * drivers/amlogic/iomap/iomap.c
+ *
+ * Copyright (C) 2017 Amlogic, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/printk.h>
+#include <linux/string.h>
+#include <linux/of_address.h>
+#include <linux/io.h>
+#include <linux/regmap.h>
+#include <linux/device.h>
+#include <linux/of_platform.h>
+#include <linux/platform_device.h>
+#include <linux/amlogic/iomap.h>
+#include <asm/compiler.h>
+#undef pr_fmt
+#define pr_fmt(fmt) "aml_iomap: " fmt
+
+
+static const struct of_device_id iomap_dt_match[] = {
+	{ .compatible = "amlogic, iomap" },
+	{ /* sentinel */ },
+};
+void __iomem *meson_reg_map[IO_BUS_MAX];
+
+int aml_reg_read(u32 bus_type, unsigned int reg, unsigned int *val)
+{
+	if ((bus_type >= IO_CBUS_BASE) && (bus_type < IO_BUS_MAX)) {
+		*val = readl((meson_reg_map[bus_type]+reg));
+		return 0;
+	} else
+		return -1;
+}
+EXPORT_SYMBOL(aml_reg_read);
+
+int aml_reg_write(u32 bus_type, unsigned int reg, unsigned int val)
+{
+	if ((bus_type >= IO_CBUS_BASE) && (bus_type < IO_BUS_MAX)) {
+		writel(val, (meson_reg_map[bus_type]+reg));
+		return 0;
+	} else
+		return -1;
+}
+EXPORT_SYMBOL(aml_reg_write);
+
+int aml_regmap_update_bits(u32 bus_type,
+					unsigned int reg, unsigned int mask,
+					unsigned int val)
+{
+	if ((bus_type >= IO_CBUS_BASE) && (bus_type < IO_BUS_MAX)) {
+		unsigned int tmp, orig;
+
+		aml_reg_read(bus_type, reg, &orig);
+		tmp = orig & ~mask;
+		tmp |= val & mask;
+		aml_reg_write(bus_type, reg, tmp);
+		return 0;
+	} else
+		return -1;
+}
+EXPORT_SYMBOL(aml_regmap_update_bits);
+
+/*
+ * CBUS REG Read Write and Update some bits
+ */
+int aml_read_cbus(unsigned int reg)
+{
+	int ret, val;
+
+	ret = aml_reg_read(IO_CBUS_BASE, reg<<2, &val);
+	if (ret) {
+		pr_err("read cbus reg %x error %d\n", reg, ret);
+		return -1;
+	} else
+		return val;
+}
+EXPORT_SYMBOL(aml_read_cbus);
+
+void aml_write_cbus(unsigned int reg, unsigned int val)
+{
+	int ret;
+
+	ret = aml_reg_write(IO_CBUS_BASE, reg<<2, val);
+	if (ret)
+		pr_err("write cbus reg %x error %d\n", reg, ret);
+}
+EXPORT_SYMBOL(aml_write_cbus);
+
+void aml_cbus_update_bits(unsigned int reg,
+		unsigned int mask, unsigned int val)
+{
+	int ret;
+
+	ret = aml_regmap_update_bits(IO_CBUS_BASE, reg<<2, mask, val);
+	if (ret)
+		pr_err("write cbus reg %x error %d\n", reg, ret);
+}
+EXPORT_SYMBOL(aml_cbus_update_bits);
+
+/*
+ * AO REG Read Write and Update some bits
+ */
+int aml_read_aobus(unsigned int reg)
+{
+	int ret, val;
+
+	ret = aml_reg_read(IO_AOBUS_BASE, reg, &val);
+	if (ret) {
+		pr_err("read ao bus reg %x error %d\n", reg, ret);
+		return -1;
+	} else
+		return val;
+}
+EXPORT_SYMBOL(aml_read_aobus);
+
+void aml_write_aobus(unsigned int reg, unsigned int val)
+{
+	int ret;
+
+	ret = aml_reg_write(IO_AOBUS_BASE, reg, val);
+	if (ret)
+		pr_err("write ao bus reg %x error %d\n", reg, ret);
+}
+EXPORT_SYMBOL(aml_write_aobus);
+
+void aml_aobus_update_bits(unsigned int reg,
+		unsigned int mask, unsigned int val)
+{
+	int ret;
+
+	ret = aml_regmap_update_bits(IO_AOBUS_BASE, reg, mask, val);
+	if (ret)
+		pr_err("write aobus reg %x error %d\n", reg, ret);
+}
+EXPORT_SYMBOL(aml_aobus_update_bits);
+
+
+/*
+ ** VCBUS Bus REG Read Write and Update some bits
+ */
+int aml_read_vcbus(unsigned int reg)
+{
+	int ret, val;
+
+	ret = aml_reg_read(IO_APB_BUS_BASE, (0x100000+(reg<<2)), &val);
+	if (ret) {
+		pr_err("read vcbus reg %x error %d\n", reg, ret);
+		return -1;
+	} else
+		return val;
+}
+EXPORT_SYMBOL(aml_read_vcbus);
+
+
+void aml_write_vcbus(unsigned int reg, unsigned int val)
+{
+	int ret;
+
+	ret = aml_reg_write(IO_APB_BUS_BASE, (0x100000+(reg<<2)), val);
+	if (ret)
+		pr_err("write vcbus reg %x error %d\n", reg, ret);
+}
+EXPORT_SYMBOL(aml_write_vcbus);
+
+void aml_vcbus_update_bits(unsigned int reg,
+		unsigned int mask, unsigned int val)
+{
+	int ret;
+
+	ret = aml_regmap_update_bits(IO_APB_BUS_BASE,
+						(0x100000+(reg<<2)), mask, val);
+	if (ret)
+		pr_err("write vcbus reg %x error %d\n", reg, ret);
+}
+EXPORT_SYMBOL(aml_vcbus_update_bits);
+
+
+/*
+ ** DOS BUS Bus REG Read Write and Update some bits
+ */
+int aml_read_dosbus(unsigned int reg)
+{
+	int ret, val;
+
+	ret = aml_reg_read(IO_APB_BUS_BASE, (0x50000+(reg<<2)), &val);
+	if (ret) {
+		pr_err("read vcbus reg %x error %d\n", reg, ret);
+		return -1;
+	} else
+		return val;
+}
+EXPORT_SYMBOL(aml_read_dosbus);
+
+void aml_write_dosbus(unsigned int reg, unsigned int val)
+{
+	int ret;
+
+	ret = aml_reg_write(IO_APB_BUS_BASE, (0x50000+(reg<<2)), val);
+	if (ret)
+		pr_err("write vcbus reg %x error %d\n", reg, ret);
+}
+EXPORT_SYMBOL(aml_write_dosbus);
+
+void aml_dosbus_update_bits(unsigned int reg,
+		unsigned int mask, unsigned int val)
+{
+	int ret;
+
+	ret = aml_regmap_update_bits(IO_APB_BUS_BASE,
+						(0x50000+(reg<<2)), mask, val);
+	if (ret)
+		pr_err("write vcbus reg %x error %d\n", reg, ret);
+}
+EXPORT_SYMBOL(aml_dosbus_update_bits);
+
+static int iomap_probe(struct platform_device *pdev)
+{
+	int i = 0;
+/* void __iomem *base; */
+	struct resource res;
+	struct device_node *np, *child;
+
+	np = pdev->dev.of_node;
+
+	for_each_child_of_node(np, child) {
+		if (of_address_to_resource(child, 0, &res))
+			return -1;
+		meson_reg_map[i] = ioremap(res.start, resource_size(&res));
+		i++;
+	}
+	pr_info("amlogic iomap probe done\n");
+	return 0;
+}
+
+
+
+static  struct platform_driver iomap_platform_driver = {
+	.probe		= iomap_probe,
+	.driver		= {
+		.owner		= THIS_MODULE,
+		.name		= "iomap_version",
+		.of_match_table	= iomap_dt_match,
+	},
+};
+
+int __init meson_iomap_version_init(void)
+{
+
+	int ret;
+
+	ret = platform_driver_register(&iomap_platform_driver);
+
+	return ret;
+}
+core_initcall(meson_iomap_version_init);
diff --git a/drivers/amlogic/mmc/Kconfig b/drivers/amlogic/mmc/Kconfig
new file mode 100644
index 0000000..8512d5b
--- /dev/null
+++ b/drivers/amlogic/mmc/Kconfig
@@ -0,0 +1,30 @@
+# Amlogic MMC driver
+
+comment "MMC/SD/SDIO Host Controller Drivers"
+
+menu "Multimedia Card support"
+
+config AMLOGIC_MMC
+	bool "Amlogic Multimedia Card support"
+	depends on MMC
+	depends on MMC_BLOCK
+	depends on MMC_BLOCK_BOUNCE
+	default n
+	help
+	This selects support for the Amlogic SD/MMC Host Controller
+	found on the S912/GXM family of SoCs.  This controller is
+	MMC 5.1 compliant and supports SD, eMMC and SDIO interfaces.
+	If you have a controller with this interface, say Y here.
+
+config AMLOGIC_M8B_MMC
+	bool "Amlogic M8B Multimedia Card support"
+	depends on AMLOGIC_MMC
+	default n
+	help
+	This selects support for the Amlogic SD/MMC Host Controller
+	found on the S805/M8B family of SoCs.  This controller is
+	MMC 5.1 compliant and supports SD, eMMC and SDIO interfaces.
+	If you have a controller with this interface, say Y here.
+
+
+endmenu
diff --git a/drivers/amlogic/mmc/Makefile b/drivers/amlogic/mmc/Makefile
new file mode 100644
index 0000000..8df5f3d
--- /dev/null
+++ b/drivers/amlogic/mmc/Makefile
@@ -0,0 +1,7 @@
+#
+# Amlogic MMC specific Makefile
+#
+
+obj-$(CONFIG_AMLOGIC_MMC)	+=  amlsd.o  amlsd_of.o emmc_partitions.o   emmc_key.o
+
+obj-$(CONFIG_AMLOGIC_M8B_MMC)	+= aml_sdhc_m8.o aml_sdio.o
diff --git a/drivers/amlogic/mmc/aml_sd_emmc.c b/drivers/amlogic/mmc/aml_sd_emmc.c
new file mode 100644
index 0000000..01088b0
--- /dev/null
+++ b/drivers/amlogic/mmc/aml_sd_emmc.c
@@ -0,0 +1,2934 @@
+/*
+ * drivers/amlogic/mmc/aml_sd_emmc.c
+ *
+ * Copyright (C) 2017 Amlogic, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/interrupt.h>
+#include <linux/device.h>
+#include <linux/of_device.h>
+#include <linux/slab.h>
+#include <linux/platform_device.h>
+#include <linux/ioport.h>
+#include <linux/spinlock.h>
+#include <linux/dma-mapping.h>
+#include <linux/delay.h>
+#include <linux/mmc/host.h>
+#include <linux/mmc/mmc.h>
+#include <linux/mmc/sdio.h>
+#include <linux/mmc/sd.h>
+#include <linux/mmc/slot-gpio.h>
+#include <linux/io.h>
+#include <linux/clk.h>
+#include <linux/clk-provider.h>
+#include <linux/regulator/consumer.h>
+#include <linux/highmem.h>
+#include <linux/amlogic/sd.h>
+#include <linux/amlogic/cpu_version.h>
+#include <linux/mmc/emmc_partitions.h>
+#include <linux/amlogic/amlsd.h>
+
+struct mmc_host *sdio_host;
+
+static unsigned int log2i(unsigned int val)
+{
+	unsigned int ret = -1;
+
+	while (val != 0) {
+		val >>= 1;
+		ret++;
+	}
+	return ret;
+}
+
+#ifdef AML_CALIBRATION
+u32 checksum_cali(u32 *buffer, u32 length)
+{
+	u32 sum = 0, *i = buffer;
+
+	buffer += length;
+	for (; i < buffer; sum += *(i++))
+		;
+	return sum;
+}
+
+static int is_larger(u8 value, u8 base, u8 wrap)
+{
+	int ret = 0;
+
+	if ((value > base) || ((value < base) && (base == wrap)))
+		ret = 1;
+	return ret;
+}
+
+static void find_base(struct amlsd_platform *pdata, u8 *is_base_index,
+		u8 fir_base[2][2], u8 *first_base_temp_num, u32 base_index_val,
+			u8 *calout_cmp_num)
+{
+	u8 first_base_temp, line_x, dly_tmp, cal_time, max_index;
+
+	line_x = pdata->c_ctrl.line_x;
+	dly_tmp = pdata->c_ctrl.dly_tmp;
+	cal_time = pdata->c_ctrl.cal_time;
+	max_index = pdata->c_ctrl.max_index;
+
+	if (pdata->calout[dly_tmp][cal_time] != 0xFF) {
+		/* calculate base index! */
+		if (*is_base_index == 1) {
+			first_base_temp = pdata->calout[dly_tmp][cal_time];
+			*first_base_temp_num = *first_base_temp_num + 1;
+			if (*first_base_temp_num == 1) {
+				fir_base[0][0] = first_base_temp;
+				fir_base[0][1] = fir_base[0][1] + 1;
+			} else {
+					if (first_base_temp == fir_base[0][0])
+						fir_base[0][1]++;
+					else {
+						fir_base[1][0] =
+							first_base_temp;
+						fir_base[1][1]++;
+					}
+			}
+			/* get a higher index, add the counter! */
+		} else if (is_larger(pdata->calout[dly_tmp][cal_time],
+					base_index_val, max_index))
+			*calout_cmp_num = *calout_cmp_num + 1;
+	} else {
+		/* todo, if we do not capture a valid value,
+		 * HIGHLIGHT(cal_time = 0) may cause error!!!
+		 */
+			pr_err("!!!Do not capture a valid index");
+			pr_err("@ line %d on capture %d\n",
+						line_x, cal_time);
+	}
+}
+
+static int aml_sd_emmc_cali_transfer(struct mmc_host *mmc,
+			u8 opcode, u8 *blk_test, u32 blksz)
+{
+	struct amlsd_host *host = mmc_priv(mmc);
+	struct mmc_request mrq = {NULL};
+	struct mmc_command cmd = {0};
+	struct mmc_command stop = {0};
+	struct mmc_data data = {0};
+	struct scatterlist sg;
+
+	cmd.opcode = opcode;
+	cmd.arg = CALI_PATTERN_OFFSET;
+	cmd.flags = MMC_RSP_R1 | MMC_CMD_ADTC;
+
+	stop.opcode = MMC_STOP_TRANSMISSION;
+	stop.arg = 0;
+	stop.flags = MMC_RSP_R1B | MMC_CMD_AC;
+
+	data.blksz = blksz;
+	if (opcode == 18)
+		data.blocks = CALI_BLK_CNT;
+	else
+		data.blocks = 1;
+	data.flags = MMC_DATA_READ;
+	data.sg = &sg;
+	data.sg_len = 1;
+
+	memset(blk_test, 0, blksz * data.blocks);
+	sg_init_one(&sg, blk_test, blksz * data.blocks);
+
+	mrq.cmd = &cmd;
+	mrq.stop = &stop;
+	mrq.data = &data;
+	host->mrq = &mrq;
+	mmc_wait_for_req(mmc, &mrq);
+	return data.error | cmd.error;
+}
+
+static int aml_cali_auto(struct mmc_host *mmc, struct cali_data *c_data)
+{
+	struct amlsd_host *host = mmc_priv(mmc);
+	struct amlsd_platform *pdata = host->pdata;
+	u8 i, max_cali_i = 0;
+	u32 max_cali_count = 0;
+	u32 cali_tmp[4] = {0};
+	u32 line_delay = 0;
+	u32 base_index_val = 0;
+	u32 adjust;
+	u8 is_base_index, max_index, line_x, dly_tmp;
+	u8 bus_width = 8;
+	struct sd_emmc_adjust *gadjust = (struct sd_emmc_adjust *)&adjust;
+	u32 blksz = 512;
+	u8 *blk_test;
+	int ret = 0;
+
+	blk_test = kmalloc(blksz * CALI_BLK_CNT, GFP_KERNEL);
+	if (!blk_test)
+		return -ENOMEM;
+
+	if (mmc->ios.bus_width == 0)
+		bus_width = 1;
+	else if (mmc->ios.bus_width == 2)
+		bus_width = 4;
+	else
+		bus_width = 8;
+
+	max_index = pdata->c_ctrl.max_index;
+	/* for each line */
+	for (line_x = 0; line_x < bus_width; line_x++) {
+		base_index_val = 0;
+		is_base_index = 1;
+		memset(pdata->calout, 0xFF, 20 * 20);
+		pdata->c_ctrl.line_x = line_x;
+		/* for each delay index! */
+		for (dly_tmp = 0; dly_tmp < MAX_DELAY_CNT; dly_tmp++) {
+			line_delay = dly_tmp << (4 * line_x);
+			writel(line_delay, host->base + SD_EMMC_DELAY);
+			pdata->caling = 1;
+			aml_sd_emmc_cali_transfer(mmc,
+					MMC_READ_MULTIPLE_BLOCK,
+					blk_test, blksz);
+			for (i = 0; i < 4; i++) {
+				cali_tmp[i]	= readl(host->base
+						+ SD_EMMC_CALOUT + i*4);
+				if (max_cali_count < (cali_tmp[i] & 0xffffff)) {
+					max_cali_count
+						= (cali_tmp[i] & 0xffffff);
+					max_cali_i = i;
+				}
+			}
+			pdata->calout[dly_tmp][line_x]
+				= (cali_tmp[max_cali_i] >> 24) & 0x3f;
+#ifdef CHOICE_DEBUG
+			for (i = 0; i < 4; i++)
+				pr_info("cali_index[%d] =0x%x, cali_count[%d] = %d\n",
+						i, cali_tmp[i] >> 24, i,
+						cali_tmp[i] & 0xffffff);
+#endif
+			pdata->caling = 0;
+			adjust = readl(host->base + SD_EMMC_ADJUST);
+			gadjust->cali_enable = 0;
+			gadjust->cali_sel = 0;
+			writel(adjust, host->base + SD_EMMC_ADJUST);
+			if (is_base_index == 1) {
+				is_base_index = 0;
+				c_data->base_index[line_x] =
+					pdata->calout[dly_tmp][line_x];
+				if (c_data->base_index[line_x]
+						< c_data->base_index_min)
+					c_data->base_index_min
+						= c_data->base_index[line_x];
+				if (c_data->base_index[line_x]
+						> c_data->base_index_max)
+					c_data->base_index_max
+						= c_data->base_index[line_x];
+			}
+			if (is_larger(pdata->calout[dly_tmp][line_x],
+						c_data->base_index[line_x],
+						max_index))
+				break;
+		}  /* endof dly_tmp loop... */
+		/* get a valid index on current line! */
+		if (dly_tmp == MAX_DELAY_CNT)
+			ret = -1;
+		else
+			c_data->ln_delay[line_x] = dly_tmp;
+		if (ret)
+			break;
+#ifdef CHOICE_DEBUG
+		for (i = 0; i < 16; i++)
+			pr_info("%02x, ", pdata->calout[i][line_x]);
+		pr_info("\n");
+#endif
+	}
+	kfree(blk_test);
+	blk_test = NULL;
+	return ret;
+}
+
+static int aml_cali_index(struct mmc_host *mmc, struct cali_data *c_data)
+{
+	struct amlsd_host *host = mmc_priv(mmc);
+	struct amlsd_platform *pdata = host->pdata;
+	u32 line_delay = 0;
+	u8 calout_cmp_num = 0;
+	u32 base_index_val = 0;
+	u32 adjust;
+	u8 bus_width = 8;
+	u8 line_x, dly_tmp, cal_time;
+	u8 is_base_index;
+	u8 fir_base[2][2] = { {0} };
+	u8 first_base_temp_num = 0;
+	u8 cal_per_line_num = 8;
+	struct sd_emmc_adjust *gadjust = (struct sd_emmc_adjust *)&adjust;
+	u32 blksz = 512;
+	u8 *blk_test;
+	int ret = 0;
+
+	blk_test = kmalloc(blksz * CALI_BLK_CNT, GFP_KERNEL);
+	if (!blk_test)
+		return -ENOMEM;
+
+	if (mmc->ios.bus_width == 0)
+		bus_width = 1;
+	else if (mmc->ios.bus_width == 2)
+		bus_width = 4;
+	else
+		bus_width = 8;
+
+	for (line_x = 0; line_x < bus_width; line_x++) {
+		base_index_val = 0;
+		is_base_index = 1;
+		memset(pdata->calout, 0xFF, 20 * 20);
+		first_base_temp_num = 0;
+		fir_base[0][0] = 0;
+		fir_base[0][1] = 0;
+		fir_base[1][0] = 0;
+		fir_base[1][1] = 0;
+		pdata->c_ctrl.line_x = line_x;
+		/* for each delay index! */
+		for (dly_tmp = 0; dly_tmp < MAX_DELAY_CNT; dly_tmp++) {
+			line_delay = 0;
+			line_delay = dly_tmp << (4 * line_x);
+			writel(line_delay, host->base + SD_EMMC_DELAY);
+			calout_cmp_num = 0;
+			pdata->c_ctrl.dly_tmp = dly_tmp;
+			/* cal_time */
+			for (cal_time = 0; cal_time < cal_per_line_num;
+					cal_time++) {
+				/* send read cmd. */
+				pdata->caling = 1;
+				aml_sd_emmc_cali_transfer(mmc,
+					MMC_READ_MULTIPLE_BLOCK,
+					blk_test, blksz);
+				pdata->calout[dly_tmp][cal_time]
+					= readl(host->base + SD_EMMC_CALOUT)
+					& 0x3f;
+				pdata->caling = 0;
+				adjust = readl(host->base + SD_EMMC_ADJUST);
+				gadjust->cali_enable = 0;
+				gadjust->cali_sel = 0;
+				writel(adjust, host->base + SD_EMMC_ADJUST);
+				/*get a valid index*/
+				pdata->c_ctrl.cal_time = cal_time;
+				find_base(pdata, &is_base_index,
+				fir_base, &first_base_temp_num,
+				base_index_val, &calout_cmp_num);
+			}	/* endof cal_time loop... */
+			/* get base index value */
+			/* if ((base_index_val > 0) && (is_base_index == 1)) {*/
+			if (is_base_index == 1) {
+				is_base_index = 0;
+				if (fir_base[1][1] > fir_base[0][1])
+					base_index_val = fir_base[1][0];
+				else
+					base_index_val = fir_base[0][0];
+				/*base_index_val = valid_base_index; */
+				if (base_index_val < c_data->base_index_min)
+					c_data->base_index_min = base_index_val;
+				if (base_index_val > c_data->base_index_max)
+					c_data->base_index_max = base_index_val;
+				c_data->base_index[line_x] = base_index_val;
+				/* pr_err("get base index %d
+				 * value @ line (%d)\n",
+				 * base_index_val, line_x);
+				 */
+			} else if (calout_cmp_num == cal_per_line_num) {
+				break;
+			}
+		}  /* endof dly_tmp loop... */
+		/* get a valid index on current line! */
+		if ((dly_tmp == MAX_DELAY_CNT)
+				&& (calout_cmp_num != cal_per_line_num))
+			ret = -1;
+		else
+			c_data->ln_delay[line_x] = dly_tmp;
+		if (ret)
+			break;
+#ifdef CHOICE_DEBUG
+		for (i = 0; i < 16; i++) {
+			pr_info("%02x %02x %02x %02x %02x %02x %02x %02x\n",
+					pdata->calout[i][0],
+					pdata->calout[i][1],
+					pdata->calout[i][2],
+					pdata->calout[i][3],
+					pdata->calout[i][4],
+					pdata->calout[i][5],
+					pdata->calout[i][6],
+					pdata->calout[i][7]);
+		}
+#endif
+	}
+	kfree(blk_test);
+	blk_test = NULL;
+	return ret;
+}
+
+static int aml_cali_find(struct mmc_host *mmc, struct cali_data *c_data)
+{
+	struct amlsd_host *host = mmc_priv(mmc);
+	struct amlsd_platform *pdata = host->pdata;
+	u32 line_delay;
+	struct sd_emmc_delay *line_dly = (struct sd_emmc_delay *)&line_delay;
+	u32 max_cal_result = 0;
+	u32 min_cal_result = 10000;
+	u32 cal_result[8];
+	u8 delay_step, max_index, bus_width = 8, line_x = 8;
+
+	if (get_cpu_type() == MESON_CPU_MAJOR_ID_GXBB)
+		delay_step = 125;
+	else
+		delay_step = 200;
+	if (mmc->ios.bus_width == 0)
+		bus_width = 1;
+	else if (mmc->ios.bus_width == 2)
+		bus_width = 4;
+	else
+		bus_width = 8;
+
+	max_index = pdata->c_ctrl.max_index;
+	/* if base index wrap, fix */
+	for (line_x = 0; line_x < bus_width; line_x++) {
+		/* 1000 means index is 1ns */
+		/* make sure no neg-value  for ln_delay*/
+		if (c_data->ln_delay[line_x]*delay_step > 1000)
+			c_data->ln_delay[line_x] = 1000 / delay_step;
+
+		if (c_data->base_index[line_x] == max_index) {
+			cal_result[line_x] = ((max_index+1))*1000 -
+				c_data->ln_delay[line_x]*delay_step;
+		} else if ((c_data->base_index_max == max_index) &&
+			(c_data->base_index[line_x] != (max_index - 1)) &&
+			(c_data->base_index[line_x] != (max_index - 2))) {
+			cal_result[line_x] = ((c_data->base_index[line_x]+1)%
+			(max_index+1) + (max_index+1))*1000 -
+				c_data->ln_delay[line_x]*delay_step;
+		} else {
+			cal_result[line_x] = (c_data->base_index[line_x]+1)%
+				(max_index+1) * 1000 -
+					c_data->ln_delay[line_x]*delay_step;
+		}
+		max_cal_result = (max_cal_result < cal_result[line_x])
+				? cal_result[line_x] : max_cal_result;
+		min_cal_result = (min_cal_result > cal_result[line_x])
+				? cal_result[line_x] : min_cal_result;
+		pr_info("%s: delay[%d]=%5d padding=%2d, bidx=%d\n",
+				mmc_hostname(mmc), line_x, cal_result[line_x],
+				c_data->ln_delay[line_x],
+				c_data->base_index[line_x]);
+	}
+	pr_info("%s: calibration result : max(%d), min(%d)\n",
+		mmc_hostname(mmc), max_cal_result, min_cal_result);
+	/* retry cali here! */
+	if ((max_cal_result - min_cal_result) >= 2000)
+		return -1;
+
+	/* swap base_index_max */
+	if ((c_data->base_index_max == max_index)
+			&& (c_data->base_index_min == 0))
+		c_data->base_index_max = 0;
+	if (max_cal_result < (c_data->base_index_max * 1000))
+		max_cal_result = (c_data->base_index_max * 1000);
+	/* calculate each line delay we should use! */
+	line_delay = readl(host->base + SD_EMMC_DELAY);
+	line_dly->dat0 = (((max_cal_result - cal_result[0]) / delay_step)
+			> 15) ? 15 :
+			((max_cal_result - cal_result[0]) / delay_step);
+	line_dly->dat1 = (((max_cal_result - cal_result[1]) / delay_step)
+			> 15) ? 15 :
+			((max_cal_result - cal_result[1]) / delay_step);
+	line_dly->dat2 = (((max_cal_result - cal_result[2]) / delay_step)
+			> 15) ? 15 :
+			((max_cal_result - cal_result[2]) / delay_step);
+	line_dly->dat3 = (((max_cal_result - cal_result[3]) / delay_step)
+			> 15) ? 15 :
+			((max_cal_result - cal_result[3]) / delay_step);
+	line_dly->dat4 = (((max_cal_result - cal_result[4]) / delay_step)
+			> 15) ? 15 :
+			((max_cal_result - cal_result[4]) / delay_step);
+	line_dly->dat5 = (((max_cal_result - cal_result[5]) / delay_step)
+			> 15) ? 15 :
+			((max_cal_result - cal_result[5]) / delay_step);
+	line_dly->dat6 = (((max_cal_result - cal_result[6]) / delay_step)
+			> 15) ? 15 :
+			((max_cal_result - cal_result[6]) / delay_step);
+	line_dly->dat7 = (((max_cal_result - cal_result[7]) / delay_step)
+			> 15) ? 15 :
+			((max_cal_result - cal_result[7]) / delay_step);
+
+	pr_info("%s: line_delay =0x%x, max_cal_result =%d\n",
+		mmc_hostname(mmc), line_delay, max_cal_result);
+	/* set delay count into reg*/
+	writel(line_delay, host->base + SD_EMMC_DELAY);
+	return 0;
+}
+
+static int aml_sd_emmc_execute_calibration(struct mmc_host *mmc,
+			u32 *adj_win_start, u32 type)
+{
+	struct amlsd_host *host = mmc_priv(mmc);
+	struct amlsd_platform *pdata = host->pdata;
+	u32 adjust;
+	struct sd_emmc_adjust *gadjust = (struct sd_emmc_adjust *)&adjust;
+	u32 vclk, cali_retry = 0;
+#ifdef SD_EMMC_CLK_CTRL
+	struct sd_emmc_clock *clkc = (struct sd_emmc_clock *)&(vclk);
+	u8 clk_div_tmp;
+#else
+	unsigned long clk_tmp;
+#endif
+	struct cali_data c_data;
+	int ret = 0;
+#ifdef CHOICE_DEBUG
+	u8 i;
+#endif
+
+	memset(&c_data, 0, sizeof(struct cali_data));
+#ifdef SD_EMMC_CLK_CTRL
+	vclk = readl(host->base + SD_EMMC_CLOCK);
+	clk_div_tmp = clkc->div;
+	if (type)
+		clkc->div = 5;
+	writel(vclk, host->base + SD_EMMC_CLOCK);
+#else
+	clk_tmp = clk_get_rate(host->cfg_div_clk);
+	if (type)
+		clk_set_rate(host->cfg_div_clk, 200000000);
+	vclk = readl(host->base + SD_EMMC_CLOCK);
+#endif
+	pdata->clkc = vclk;
+	pdata->c_ctrl.max_index = (vclk & 0x3f) - 1;
+
+_cali_retry:
+	c_data.base_index_min = pdata->c_ctrl.max_index + 1;
+	c_data.base_index_max = 0;
+	pr_info("%s: trying cali %d-th time(s)\n",
+				mmc_hostname(mmc), cali_retry);
+	host->is_tunning = 1;
+	/* for each line */
+	if (type)
+		ret = aml_cali_auto(mmc, &c_data);
+	else
+		ret = aml_cali_index(mmc, &c_data);
+	if (ret) {
+		/* Do not get a valid line delay index value! */
+		if (cali_retry < MAX_CALI_RETRY) {
+			pr_err("Do't get valid ln_delay @ line %d, try\n",
+					pdata->c_ctrl.line_x);
+			cali_retry++;
+			goto _cali_retry;
+		} else {
+			pr_info("%s: calibration failed, use default\n",
+					mmc_hostname(host->mmc));
+			return -1;
+		}
+	}
+	host->is_tunning = 0;
+
+	ret = aml_cali_find(mmc, &c_data);
+	/* retry cali here! */
+	if (ret) {
+		if (cali_retry < MAX_CALI_RETRY) {
+			cali_retry++;
+			goto _cali_retry;
+		} else {
+			pr_info("%s: calibration failed, use default\n",
+				mmc_hostname(host->mmc));
+			return -1;
+		}
+	}
+	pr_info("calibration @%d times ok\n", cali_retry);
+
+	/* restore original clk setting */
+#ifdef SD_EMMC_CLK_CTRL
+	vclk = readl(host->base + SD_EMMC_CLOCK);
+	clkc->div = clk_div_tmp;
+	writel(vclk, host->base + SD_EMMC_CLOCK);
+#else
+	clk_set_rate(host->cfg_div_clk, clk_tmp);
+	vclk = readl(host->base + SD_EMMC_CLOCK);
+#endif
+	pdata->clkc = vclk;
+	if (!type) {
+		/* set default cmd delay*/
+		adjust = readl(host->base + SD_EMMC_ADJUST);
+		if (get_cpu_type() == MESON_CPU_MAJOR_ID_GXBB)
+			gadjust->cmd_delay = 7;
+		writel(adjust, host->base + SD_EMMC_ADJUST);
+	}
+
+	pr_info("%s: base_index_max %d, base_index_min %d\n",
+			mmc_hostname(mmc), c_data.base_index_max,
+			c_data.base_index_min);
+
+	/* get adjust point! */
+	*adj_win_start = c_data.base_index_max + 2;
+
+	return 0;
+}
+#endif
+
+static u32 aml_sd_emmc_tuning_transfer(struct mmc_host *mmc,
+	u32 opcode, const u8 *blk_pattern, u8 *blk_test, u32 blksz)
+{
+	struct amlsd_host *host = mmc_priv(mmc);
+	u32 vctrl = readl(host->base + SD_EMMC_CFG);
+	struct sd_emmc_config *ctrl = (struct sd_emmc_config *)&vctrl;
+	u32 tuning_err = 0;
+	u32 n, nmatch;
+	/* try ntries */
+	for (n = 0, nmatch = 0; n < TUNING_NUM_PER_POINT; n++) {
+		tuning_err = aml_sd_emmc_cali_transfer(mmc,
+						opcode, blk_test, blksz);
+		if (!tuning_err) {
+			if (ctrl->ddr == 1)
+				nmatch++;
+			else if (!memcmp(blk_pattern, blk_test, blksz))
+				nmatch++;
+			else {
+				sd_emmc_dbg(AMLSD_DBG_TUNING,
+				"nmatch=%d\n", nmatch);
+				break;
+			}
+		} else {
+			sd_emmc_dbg(AMLSD_DBG_TUNING,
+				"Tuning transfer error:");
+			sd_emmc_dbg(AMLSD_DBG_TUNING,
+		       "nmatch=%d\n", nmatch);
+			break;
+		}
+	}
+	return nmatch;
+}
+
+static int aml_tuning_adj(struct mmc_host *mmc, u32 opcode,
+		struct aml_tuning_data *tuning_data,
+		int *best_start, int *best_size)
+{
+	struct amlsd_host *host = mmc_priv(mmc);
+	u32 adjust;
+	struct sd_emmc_adjust *gadjust = (struct sd_emmc_adjust *)&adjust;
+	u32 vclk;
+	struct sd_emmc_clock *clkc = (struct sd_emmc_clock *)&(vclk);
+	u32 vctrl;
+	struct sd_emmc_config *ctrl = (struct sd_emmc_config *)&vctrl;
+	u32 clk_rate = 1000000000, clock, clk_div, nmatch = 0;
+	int adj_delay = 0;
+	const u8 *blk_pattern = tuning_data->blk_pattern;
+	unsigned int blksz = tuning_data->blksz;
+	u8 *blk_test;
+	int wrap_win_start = -1, wrap_win_size = 0;
+	int best_win_start = -1, best_win_size = 0;
+	int curr_win_start = -1, curr_win_size = 0;
+
+	vclk = readl(host->base + SD_EMMC_CLOCK);
+	vctrl = readl(host->base + SD_EMMC_CFG);
+	clk_div = clkc->div;
+	clock = clk_rate / clk_div;/*200MHz, bus_clk */
+	mmc->actual_clock = ctrl->ddr ?
+		(clock / 2) : clock;/*100MHz in ddr */
+	if (ctrl->ddr == 1) {
+		blksz = 512;
+		opcode = 17;
+	}
+	blk_test = kmalloc(blksz, GFP_KERNEL);
+	if (!blk_test)
+		return -ENOMEM;
+
+	pr_info("%s: clk %d %s tuning start\n",
+		mmc_hostname(mmc), (ctrl->ddr ? (clock / 2) : clock),
+			(ctrl->ddr ? "DDR mode" : "SDR mode"));
+	for (adj_delay = 0; adj_delay < clk_div; adj_delay++) {
+		adjust = readl(host->base + SD_EMMC_ADJUST);
+		gadjust->adj_delay = adj_delay;
+		gadjust->adj_enable = 1;
+		gadjust->cali_enable = 0;
+		gadjust->cali_rise = 0;
+		writel(adjust, host->base + SD_EMMC_ADJUST);
+		nmatch = aml_sd_emmc_tuning_transfer(mmc, opcode,
+				blk_pattern, blk_test, blksz);
+		/*get a ok adjust point!*/
+		if (nmatch == TUNING_NUM_PER_POINT) {
+			if (adj_delay == 0)
+				wrap_win_start = adj_delay;
+			if (wrap_win_start >= 0)
+				wrap_win_size++;
+			if (curr_win_start < 0)
+				curr_win_start = adj_delay;
+			curr_win_size++;
+			pr_info("%s: rx_tuning_result[%d] = %d\n",
+				mmc_hostname(host->mmc), adj_delay, nmatch);
+		} else {
+			if (curr_win_start >= 0) {
+				if (best_win_start < 0) {
+					best_win_start = curr_win_start;
+					best_win_size = curr_win_size;
+				} else {
+					if (best_win_size < curr_win_size) {
+						best_win_start = curr_win_start;
+						best_win_size = curr_win_size;
+					}
+				}
+				wrap_win_start = -1;
+				curr_win_start = -1;
+				curr_win_size = 0;
+			}
+		}
+	}
+	/* last point is ok! */
+	if (curr_win_start >= 0) {
+		if (best_win_start < 0) {
+			best_win_start = curr_win_start;
+			best_win_size = curr_win_size;
+		} else if (wrap_win_size > 0) {
+			/* Wrap around case */
+			if (curr_win_size + wrap_win_size > best_win_size) {
+				best_win_start = curr_win_start;
+				best_win_size = curr_win_size + wrap_win_size;
+			}
+		} else if (best_win_size < curr_win_size) {
+			best_win_start = curr_win_start;
+			best_win_size = curr_win_size;
+		}
+
+		curr_win_start = -1;
+		curr_win_size = 0;
+	}
+	*best_start = best_win_start;
+	*best_size = best_win_size;
+	kfree(blk_test);
+	return 0;
+}
+
+/* TODO....., based on new tuning function */
+static int aml_sd_emmc_execute_tuning_(struct mmc_host *mmc, u32 opcode,
+					struct aml_tuning_data *tuning_data,
+					u32 adj_win_start)
+{
+	struct amlsd_host *host = mmc_priv(mmc);
+	struct amlsd_platform *pdata = host->pdata;
+	u32 vclk;
+	struct sd_emmc_clock *clkc = (struct sd_emmc_clock *)&(vclk);
+	u32 adjust;
+	struct sd_emmc_adjust *gadjust = (struct sd_emmc_adjust *)&adjust;
+	u32 clk_rate = 1000000000;
+	unsigned long flags;
+	int ret = 0;
+	struct aml_emmc_adjust *emmc_adj = &host->emmc_adj;
+	u8 tuning_num = 0;
+	u32 clock, clk_div;
+	u32 adj_delay_find;
+	int best_win_start = -1, best_win_size = 0;
+
+	writel(0, host->base + SD_EMMC_ADJUST);
+
+tunning:
+	spin_lock_irqsave(&host->mrq_lock, flags);
+	pdata->need_retuning = false;
+	spin_unlock_irqrestore(&host->mrq_lock, flags);
+	vclk = readl(host->base + SD_EMMC_CLOCK);
+	clk_div = clkc->div;
+	clock = clk_rate / clk_div;/*200MHz, bus_clk */
+
+	host->is_tunning = 1;
+	ret = aml_tuning_adj(mmc, opcode,
+			tuning_data, &best_win_start, &best_win_size);
+	if (ret)
+		return -ENOMEM;
+	if (best_win_size <= 0) {
+		if ((tuning_num++ > MAX_TUNING_RETRY)
+			|| (clkc->div >= 10)) {
+			pr_info("%s: final result of tuning failed\n",
+				 mmc_hostname(host->mmc));
+			return -1;
+		}
+		clkc->div += 1;
+		writel(vclk, host->base + SD_EMMC_CLOCK);
+		mmc->actual_clock = clk_rate / clkc->div;
+		pdata->clkc = vclk;
+		pr_info("%s: tuning failed, reduce freq and retuning\n",
+			mmc_hostname(host->mmc));
+		goto tunning;
+	} else {
+		pr_info("%s: best_win_start =%d, best_win_size =%d\n",
+			mmc_hostname(host->mmc), best_win_start, best_win_size);
+	}
+
+	if ((best_win_size != clk_div)
+		|| (aml_card_type_sdio(pdata)
+			&& (get_cpu_type() == MESON_CPU_MAJOR_ID_GXM))) {
+		adj_delay_find = best_win_start + (best_win_size - 1) / 2
+						+ (best_win_size - 1) % 2;
+		adj_delay_find = adj_delay_find % clk_div;
+	} else
+		adj_delay_find = 0;
+
+	/* fixme, for retry debug. */
+	if (aml_card_type_mmc(pdata)
+		&& (clk_div <= 5) && (adj_win_start != 100)
+		&& (get_cpu_type() == MESON_CPU_MAJOR_ID_GXBB)) {
+		pr_info("%s: adj_win_start %d\n",
+			mmc_hostname(host->mmc), adj_win_start);
+		adj_delay_find = adj_win_start % clk_div;
+	}
+	adjust = readl(host->base + SD_EMMC_ADJUST);
+	gadjust->adj_delay = adj_delay_find;
+	gadjust->adj_enable = 1;
+	gadjust->cali_enable = 0;
+	gadjust->cali_rise = 0;
+	writel(adjust, host->base + SD_EMMC_ADJUST);
+	host->is_tunning = 0;
+
+	/* fixme, yyh for retry flow. */
+	emmc_adj->adj_win_start = best_win_start;
+	emmc_adj->adj_win_len = best_win_size;
+	emmc_adj->adj_point = adj_delay_find;
+	emmc_adj->clk_div = clk_div;
+	pr_info("%s: clock=0x%x, adjust=0x%x\n",
+			mmc_hostname(host->mmc),
+			readl(host->base + SD_EMMC_CLOCK),
+			readl(host->base + SD_EMMC_ADJUST));
+	return ret;
+}
+
+static int aml_sd_emmc_rxclk_find(struct mmc_host *mmc,
+		u8 *rx_tuning_result, u8 total_point,
+		int *best_win_start, int *best_win_size)
+{
+	struct amlsd_host *host = mmc_priv(mmc);
+	int wrap_win_start = -1, wrap_win_size = 0;
+	int curr_win_start = -1, curr_win_size = 0;
+	u8 n;
+	int rxclk_find;
+
+	for (n = 0; n < total_point; n++) {
+		if (rx_tuning_result[n] == TUNING_NUM_PER_POINT) {
+			if (n == 0)
+				wrap_win_start = n;
+			if (wrap_win_start >= 0)
+				wrap_win_size++;
+			if (curr_win_start < 0)
+				curr_win_start = n;
+			curr_win_size++;
+			pr_info("%s: rx_tuning_result[%d] = %d\n",
+				mmc_hostname(host->mmc), n,
+				TUNING_NUM_PER_POINT);
+		} else {
+			if (curr_win_start >= 0) {
+				if (*best_win_start < 0) {
+					*best_win_start = curr_win_start;
+					*best_win_size = curr_win_size;
+				} else {
+					if (*best_win_size < curr_win_size) {
+						*best_win_start =
+								curr_win_start;
+						*best_win_size = curr_win_size;
+					}
+				}
+
+				wrap_win_start = -1;
+				curr_win_start = -1;
+				curr_win_size = 0;
+			}
+
+		}
+	}
+	/* last point is ok! */
+	if (curr_win_start >= 0) {
+		if (*best_win_start < 0) {
+			*best_win_start = curr_win_start;
+			*best_win_size = curr_win_size;
+		} else if (wrap_win_size > 0) {
+			/* Wrap around case */
+			if (curr_win_size + wrap_win_size > *best_win_size) {
+				*best_win_start = curr_win_start;
+				*best_win_size = curr_win_size + wrap_win_size;
+			}
+		} else if (*best_win_size < curr_win_size) {
+			*best_win_start = curr_win_start;
+			*best_win_size = curr_win_size;
+		}
+
+		curr_win_start = -1;
+		curr_win_size = 0;
+	}
+	if (*best_win_size <= 0) {
+		rxclk_find = -1;
+	} else {
+		pr_info("%s: best_win_start =%d, best_win_size =%d\n",
+			mmc_hostname(host->mmc), *best_win_start,
+			*best_win_size);
+		rxclk_find = *best_win_start + (*best_win_size + 1) / 2;
+		rxclk_find %= total_point;
+	}
+
+	return rxclk_find;
+}
+
+static int aml_sd_emmc_execute_tuning_rxclk(struct mmc_host *mmc, u32 opcode,
+		struct aml_tuning_data *tuning_data)
+{
+	/* need finish later */
+	struct amlsd_host *host = mmc_priv(mmc);
+	struct amlsd_platform *pdata = host->pdata;
+	u32 vclk;
+	struct sd_emmc_clock *clkc = (struct sd_emmc_clock *)&(vclk);
+	u32 vctrl;
+	struct sd_emmc_config *ctrl = (struct sd_emmc_config *)&vctrl;
+	u32 clk_rate = 1000000000;
+	const u8 *blk_pattern = tuning_data->blk_pattern;
+	unsigned int blksz = tuning_data->blksz;
+	unsigned long flags;
+	u8 steps, nmatch;
+	u8 rx_phase, rx_delay;
+	struct aml_emmc_rxclk *emmc_rxclk = &host->emmc_rxclk;
+	u8 *blk_test;
+	u32 clock;
+	int rxclk_find;
+	u8 rx_tuning_result[25] = {0};
+	u8 total_point = 25;
+	int best_win_start = -1, best_win_size = 0;
+
+	spin_lock_irqsave(&host->mrq_lock, flags);
+	pdata->need_retuning = false;
+	spin_unlock_irqrestore(&host->mrq_lock, flags);
+	vclk = readl(host->base + SD_EMMC_CLOCK);
+	vctrl = readl(host->base + SD_EMMC_CFG);
+
+	clock = clk_rate / clkc->div;/*200mhz, bus_clk */
+	mmc->actual_clock = ctrl->ddr ?
+		(clock / 2) : clock;/*100mhz in ddr */
+
+	if (ctrl->ddr == 1) {
+		blksz = 512;
+		opcode = 17;
+	}
+	blk_test = kmalloc(blksz, GFP_KERNEL);
+	if (!blk_test)
+		return -ENOMEM;
+
+	host->is_tunning = 1;
+	pr_info("%s: clk %d %s tuning start\n",
+			mmc_hostname(mmc), (ctrl->ddr ? (clock / 2) : clock),
+			(ctrl->ddr ? "DDR mode" : "SDR mode"));
+	for (rx_phase = 0; rx_phase < 4; rx_phase += 2) {
+		if (rx_phase == 0)
+			steps = 10;
+		else
+			steps = 15;
+		for (rx_delay = 0; rx_delay < steps; rx_delay++) {
+			vclk = readl(host->base + SD_EMMC_CLOCK);
+			clkc->rx_delay = rx_delay;
+			clkc->rx_phase = rx_phase;
+			writel(vclk, host->base + SD_EMMC_CLOCK);
+			pdata->clkc = vclk;
+			nmatch = aml_sd_emmc_tuning_transfer(mmc, opcode,
+				blk_pattern, blk_test, blksz);
+			rx_tuning_result[rx_phase * 5 + rx_delay] = nmatch;
+		}
+	}
+	host->is_tunning = 0;
+	rxclk_find = aml_sd_emmc_rxclk_find(mmc,
+					rx_tuning_result, total_point,
+					&best_win_start, &best_win_size);
+
+	if (rxclk_find < 0) {
+		pr_info("%s: tuning failed\n", mmc_hostname(host->mmc));
+		kfree(blk_test);
+		return -1;
+	} else if (rxclk_find < 10) {
+		rx_phase = 0;
+		rx_delay = rxclk_find;
+	} else {
+		rx_phase = 2;
+		rx_delay = rxclk_find - 10;
+	}
+
+	pr_info("%s: rx_phase = %d, rx_delay = %d,",
+			mmc_hostname(host->mmc), rx_phase, rx_delay);
+
+	vclk = readl(host->base + SD_EMMC_CLOCK);
+	clkc->rx_phase = rx_phase;
+	clkc->rx_delay = rx_delay;
+	writel(vclk, host->base + SD_EMMC_CLOCK);
+	pdata->clkc = vclk;
+
+	emmc_rxclk->rxclk_win_start = best_win_start;
+	emmc_rxclk->rxclk_win_len = best_win_size;
+	emmc_rxclk->rxclk_rx_phase = rx_phase;
+	emmc_rxclk->rxclk_rx_delay = rx_delay;
+	emmc_rxclk->rxclk_point = rxclk_find;
+
+	kfree(blk_test);
+	return 0;
+}
+
+static int aml_mmc_execute_tuning(struct mmc_host *mmc, u32 opcode)
+{
+	int err = 0;
+	struct amlsd_host *host = mmc_priv(mmc);
+	struct amlsd_platform *pdata = host->pdata;
+	u32 adjust;
+	struct sd_emmc_adjust *gadjust = (struct sd_emmc_adjust *)&adjust;
+	u32 vclk = readl(host->base + SD_EMMC_CLOCK);
+	struct sd_emmc_clock *clkc = (struct sd_emmc_clock *)&(vclk);
+	struct aml_tuning_data tuning_data;
+	u32 adj_win_start = 100;
+
+	if (opcode == MMC_SEND_TUNING_BLOCK_HS200) {
+		if (mmc->ios.bus_width == MMC_BUS_WIDTH_8) {
+			tuning_data.blk_pattern = tuning_blk_pattern_8bit;
+			tuning_data.blksz = sizeof(tuning_blk_pattern_8bit);
+		} else if (mmc->ios.bus_width == MMC_BUS_WIDTH_4) {
+			tuning_data.blk_pattern = tuning_blk_pattern_4bit;
+			tuning_data.blksz = sizeof(tuning_blk_pattern_4bit);
+		} else {
+			return -EINVAL;
+		}
+	} else if (opcode == MMC_SEND_TUNING_BLOCK) {
+		tuning_data.blk_pattern = tuning_blk_pattern_4bit;
+		tuning_data.blksz = sizeof(tuning_blk_pattern_4bit);
+	} else {
+		sd_emmc_err("Undefined command(%d) for tuning\n", opcode);
+		return -EINVAL;
+	}
+
+#ifdef AML_CALIBRATION
+	if ((aml_card_type_mmc(pdata))
+			&& (mmc->ios.timing != MMC_TIMING_MMC_HS400)) {
+		if (clkc->div <= 10) {
+			if (get_cpu_type() >= MESON_CPU_MAJOR_ID_GXL)
+				err = aml_sd_emmc_execute_calibration(mmc,
+						&adj_win_start, 1);
+			else if (clkc->div <= 7)
+				err = aml_sd_emmc_execute_calibration(mmc,
+						&adj_win_start, 0);
+		}
+		/* if calibration failed, gdelay use default value */
+		if (err) {
+			if (get_cpu_type() == MESON_CPU_MAJOR_ID_GXBB)
+				writel(0x85854055, host->base + SD_EMMC_DELAY);
+			else
+				writel(0x10101331, host->base + SD_EMMC_DELAY);
+		}
+	}
+#endif
+	/* execute tuning... */
+	if ((clkc->div > 5)
+		|| (get_cpu_type() == MESON_CPU_MAJOR_ID_GXBB)) {
+		err = aml_sd_emmc_execute_tuning_(mmc, opcode,
+				&tuning_data, adj_win_start);
+		if (!err)
+			host->tuning_mode = ADJ_TUNING_MODE;
+	} else if (get_cpu_type() >= MESON_CPU_MAJOR_ID_GXL) {
+		if (aml_card_type_sdio(pdata)) {
+			err = aml_sd_emmc_execute_tuning_(mmc, opcode,
+					&tuning_data, adj_win_start);
+			if (!err)
+				host->tuning_mode = ADJ_TUNING_MODE;
+		} else {
+			err = 0;
+			adjust = readl(host->base + SD_EMMC_ADJUST);
+			gadjust->cali_enable = 1;
+			gadjust->adj_auto = 1;
+			writel(adjust, host->base + SD_EMMC_ADJUST);
+			host->tuning_mode = AUTO_TUNING_MODE;
+		}
+	} else {
+		err = aml_sd_emmc_execute_tuning_rxclk(mmc, opcode,
+				&tuning_data);
+		if (!err)
+			host->tuning_mode = RX_PHASE_DELAY_TUNING_MODE;
+	}
+
+	pr_info("%s: clock =0x%x, delay=0x%x, adjust=0x%x\n",
+			mmc_hostname(mmc),
+			readl(host->base + SD_EMMC_CLOCK),
+			readl(host->base + SD_EMMC_DELAY),
+			readl(host->base + SD_EMMC_ADJUST));
+
+	return err;
+
+}
+
+static void aml_mmc_clk_switch_off(struct amlsd_host *host)
+{
+	u32 vcfg = 0;
+	struct sd_emmc_config *conf = (struct sd_emmc_config *)&vcfg;
+
+	if (host->is_gated) {
+		sd_emmc_dbg(AMLSD_DBG_IOS, "direct return\n");
+		return;
+	}
+
+	/*Turn off Clock, here close whole clk for controller*/
+	vcfg = readl(host->base + SD_EMMC_CFG);
+	conf->stop_clk = 1;
+	writel(vcfg, host->base + SD_EMMC_CFG);
+
+	host->is_gated = true;
+	/* sd_emmc_err("clock off\n"); */
+}
+
+void aml_mmc_clk_switch_on(
+	struct amlsd_host *host, int clk_div, int clk_src_sel)
+{
+	u32 vclkc = 0;
+	struct sd_emmc_clock *clkc = (struct sd_emmc_clock *)&vclkc;
+	u32 vcfg = 0;
+	struct sd_emmc_config *conf = (struct sd_emmc_config *)&vcfg;
+	struct amlsd_platform *pdata = host->pdata;
+
+	WARN_ON(!clk_div);
+
+	vclkc = readl(host->base + SD_EMMC_CLOCK);
+	/*Set clock divide*/
+	clkc->div = clk_div;
+	clkc->src = clk_src_sel;
+	writel(vclkc, host->base + SD_EMMC_CLOCK);
+	pdata->clkc = vclkc;
+
+	/*Turn on Clock*/
+	vcfg = readl(host->base + SD_EMMC_CFG);
+	conf->stop_clk = 0;
+	writel(vcfg, host->base + SD_EMMC_CFG);
+
+	host->is_gated = false;
+}
+
+static void aml_mmc_clk_switch(struct amlsd_host *host,
+	int clk_div, int clk_src_sel)
+{
+	u32 vclkc = 0;
+	struct sd_emmc_clock *clkc = (struct sd_emmc_clock *)&vclkc;
+
+	vclkc = readl(host->base + SD_EMMC_CLOCK);
+	if (!host->is_gated && (clkc->div == clk_div)
+				&& (clkc->src == clk_src_sel)) {
+		/* sd_emmc_err("direct return\n"); */
+		return; /* if the same, return directly */
+	}
+
+	aml_mmc_clk_switch_off(host);
+	/* mdelay(1); */
+
+	WARN_ON(!clk_div);
+
+	aml_mmc_clk_switch_on(host, clk_div, clk_src_sel);
+}
+
+void aml_sd_emmc_set_clkc(struct amlsd_host *host)
+{
+	u32 vclkc = 0;
+	struct sd_emmc_clock *clkc = (struct sd_emmc_clock *)&vclkc;
+	struct amlsd_platform *pdata = host->pdata;
+
+	vclkc = readl(host->base + SD_EMMC_CLOCK);
+	if (!host->is_gated && (pdata->clkc == vclkc))
+		return;
+
+	if (host->is_gated)
+		aml_mmc_clk_switch(host, clkc->div, clkc->src);
+	else
+		writel(pdata->clkc, host->base + SD_EMMC_CLOCK);
+}
+
+static int meson_mmc_clk_set_rate(struct amlsd_host *host,
+		unsigned long clk_ios)
+{
+	struct mmc_host *mmc = host->mmc;
+	int ret = 0;
+#ifdef SD_EMMC_CLK_CTRL
+	u32 clk_rate, clk_div, clk_src_sel;
+	struct amlsd_platform *pdata = host->pdata;
+#else
+	u32 vcfg = 0;
+	struct sd_emmc_config *conf = (struct sd_emmc_config *)&vcfg;
+#endif
+
+#ifdef SD_EMMC_CLK_CTRL
+	if (clk_ios == 0) {
+		aml_mmc_clk_switch_off(host);
+		return ret;
+	}
+
+	clk_src_sel = SD_EMMC_CLOCK_SRC_OSC;
+	if (clk_ios < 20000000)
+		clk_src_sel = SD_EMMC_CLOCK_SRC_OSC;
+	else
+		clk_src_sel = SD_EMMC_CLOCK_SRC_FCLK_DIV2;
+#endif
+
+	if (clk_ios) {
+		if (WARN_ON(clk_ios > mmc->f_max))
+			clk_ios = mmc->f_max;
+		else if (WARN_ON(clk_ios < mmc->f_min))
+			clk_ios = mmc->f_min;
+	}
+
+#ifdef SD_EMMC_CLK_CTRL
+	WARN_ON(clk_src_sel > SD_EMMC_CLOCK_SRC_FCLK_DIV2);
+	switch (clk_src_sel) {
+	case SD_EMMC_CLOCK_SRC_OSC:
+		clk_rate = 24000000;
+		break;
+	case SD_EMMC_CLOCK_SRC_FCLK_DIV2:
+		clk_rate = 1000000000;
+		break;
+	default:
+		pr_err("%s: clock source error: %d\n",
+			mmc_hostname(host->mmc), clk_src_sel);
+		ret = -1;
+	}
+	clk_div = (clk_rate / clk_ios) + (!!(clk_rate % clk_ios));
+
+	aml_mmc_clk_switch(host, clk_div, clk_src_sel);
+	pdata->clkc = readl(host->base + SD_EMMC_CLOCK);
+
+	mmc->actual_clock = clk_rate / clk_div;
+#else
+	if (clk_ios == mmc->actual_clock)
+		return 0;
+
+	/* stop clock */
+	vcfg = readl(host->base + SD_EMMC_CFG);
+	if (!conf->stop_clk) {
+		conf->stop_clk = 1;
+		writel(vcfg, host->base + SD_EMMC_CFG);
+	}
+
+	dev_dbg(host->dev, "change clock rate %u -> %lu\n",
+		mmc->actual_clock, clk_ios);
+	ret = clk_set_rate(host->cfg_div_clk, clk_ios);
+	if (clk_ios && clk_ios != clk_get_rate(host->cfg_div_clk))
+		dev_warn(host->dev, "divider requested rate %lu != actual rate %lu: ret=%d\n",
+			 clk_ios, clk_get_rate(host->cfg_div_clk), ret);
+	else
+		mmc->actual_clock = clk_ios;
+
+	/* (re)start clock, if non-zero */
+	if (clk_ios) {
+		vcfg = readl(host->base + SD_EMMC_CFG);
+		conf->stop_clk = 0;
+		writel(vcfg, host->base + SD_EMMC_CFG);
+	}
+#endif
+
+	return ret;
+}
+
+static int aml_emmc_clktree_init(struct amlsd_host *host)
+{
+	int i, ret = 0;
+	unsigned int f_min = UINT_MAX, mux_parent_count = 0;
+	const char *mux_parent_names[MUX_CLK_NUM_PARENTS];
+	struct clk_init_data init;
+	char clk_name[32], name[16];
+	const char *clk_div_parents[1];
+
+	host->core_clk = devm_clk_get(host->dev, "core");
+	if (IS_ERR(host->core_clk)) {
+		ret = PTR_ERR(host->core_clk);
+		return ret;
+	}
+	ret = clk_prepare_enable(host->core_clk);
+	if (ret)
+		return ret;
+
+	/* get the mux parents */
+	for (i = 0; i < MUX_CLK_NUM_PARENTS; i++) {
+		snprintf(name, sizeof(name), "clkin%d", i);
+		host->mux_parent[i] = devm_clk_get(host->dev, name);
+		if (IS_ERR(host->mux_parent[i])) {
+			ret = PTR_ERR(host->mux_parent[i]);
+			if (PTR_ERR(host->mux_parent[i]) != -EPROBE_DEFER)
+				dev_err(host->dev, "Missing clock %s\n", name);
+			host->mux_parent[i] = NULL;
+			return ret;
+		}
+		host->mux_parent_rate[i] = clk_get_rate(host->mux_parent[i]);
+		mux_parent_names[i] = __clk_get_name(host->mux_parent[i]);
+		mux_parent_count++;
+		if (host->mux_parent_rate[i] < f_min)
+			f_min = host->mux_parent_rate[i];
+		ret = clk_prepare_enable(host->mux_parent[i]);
+	}
+
+	/* cacluate f_min based on input clocks, and max divider value */
+	if (f_min != UINT_MAX)
+		f_min = DIV_ROUND_UP(CLK_SRC_XTAL_RATE, CLK_DIV_MAX);
+	else
+		f_min = 400000;  /* default min: 400 KHz */
+	host->mmc->f_min = f_min;
+
+	/* create the mux */
+	snprintf(clk_name, sizeof(clk_name), "%s#mux", dev_name(host->dev));
+	init.name = clk_name;
+	init.ops = &clk_mux_ops;
+	init.flags = 0;
+	init.parent_names = mux_parent_names;
+	init.num_parents = mux_parent_count;
+	host->mux.reg = host->base + SD_EMMC_CLOCK;
+	host->mux.shift = CLK_SRC_SHIFT;
+	host->mux.mask = CLK_SRC_MASK;
+	host->mux.flags = 0;
+	host->mux.table = NULL;
+	host->mux.hw.init = &init;
+	host->mux_clk = devm_clk_register(host->dev, &host->mux.hw);
+	if (WARN_ON(IS_ERR(host->mux_clk)))
+		return PTR_ERR(host->mux_clk);
+
+	/* create the divider */
+	snprintf(clk_name, sizeof(clk_name), "%s#div", dev_name(host->dev));
+	init.name = devm_kstrdup(host->dev, clk_name, GFP_KERNEL);
+	init.ops = &clk_divider_ops;
+	init.flags = CLK_SET_RATE_PARENT;
+	clk_div_parents[0] = __clk_get_name(host->mux_clk);
+	init.parent_names = clk_div_parents;
+	init.num_parents = ARRAY_SIZE(clk_div_parents);
+	host->cfg_div.reg = host->base + SD_EMMC_CLOCK;
+	host->cfg_div.shift = CLK_DIV_SHIFT;
+	host->cfg_div.width = CLK_DIV_WIDTH;
+	host->cfg_div.hw.init = &init;
+	host->cfg_div.flags = CLK_DIVIDER_ONE_BASED |
+		CLK_DIVIDER_ROUND_CLOSEST | CLK_DIVIDER_ALLOW_ZERO;
+	host->cfg_div_clk = devm_clk_register(host->dev, &host->cfg_div.hw);
+	if (WARN_ON(PTR_ERR_OR_ZERO(host->cfg_div_clk)))
+		return PTR_ERR(host->cfg_div_clk);
+
+	ret = clk_prepare_enable(host->cfg_div_clk);
+
+	return ret;
+}
+
+/*
+ * The SD/eMMC IP block has an internal mux and divider used for
+ * generating the MMC clock.  Use the clock framework to create and
+ * manage these clocks.
+ */
+static int meson_mmc_clk_init(struct amlsd_host *host)
+{
+	int ret = 0;
+	u32 vclkc = 0;
+	struct sd_emmc_clock *pclkc = (struct sd_emmc_clock *)&vclkc;
+	u32 vconf = 0;
+	struct sd_emmc_config *pconf = (struct sd_emmc_config *)&vconf;
+	struct amlsd_platform *pdata = host->pdata;
+
+	ret = aml_emmc_clktree_init(host);
+	if (ret)
+		return ret;
+
+	/* init SD_EMMC_CLOCK to sane defaults w/min clock rate */
+	vclkc = 0;
+	pclkc->div = 60;	 /* 400KHz */
+	pclkc->src = 0;	  /* 0: Crystal 24MHz */
+	pclkc->core_phase = 2;	  /* 2: 180 phase */
+	pclkc->rx_phase = 0;
+	pclkc->tx_phase = 0;
+	pclkc->always_on = 1;	  /* Keep clock always on */
+	writel(vclkc, host->base + SD_EMMC_CLOCK);
+	pdata->clkc = vclkc;
+
+	vconf = 0;
+	/* 1bit mode */
+	pconf->bus_width = 0;
+	/* 512byte block length */
+	pconf->bl_len = 9;
+	/* 64 CLK cycle, here 2^8 = 256 clk cycles */
+	pconf->resp_timeout = 8;
+	/* 1024 CLK cycle, Max. 100mS. */
+	pconf->rc_cc = 4;
+	pconf->err_abort = 0;
+	pconf->auto_clk = 1;
+	writel(vconf, host->base + SD_EMMC_CFG);
+
+	writel(0xffff, host->base + SD_EMMC_STATUS);
+	writel(SD_EMMC_IRQ_ALL, host->base + SD_EMMC_IRQ_EN);
+
+	return ret;
+}
+
+static void aml_sd_emmc_tx_phase_set(struct amlsd_host *host)
+{
+	struct amlsd_platform *pdata = host->pdata;
+	u32 vclkc = 0;
+	struct sd_emmc_clock *pclkc = (struct sd_emmc_clock *)&vclkc;
+
+	vclkc = readl(host->base + SD_EMMC_CLOCK);
+	pclkc->tx_phase = pdata->tx_phase;
+	if (pdata->tx_delay)
+		pclkc->tx_delay = pdata->tx_delay;
+
+	writel(vclkc, host->base + SD_EMMC_CLOCK);
+}
+
+static void aml_sd_emmc_set_timing(
+		struct amlsd_host *host, u32 timing)
+{
+	struct amlsd_platform *pdata = host->pdata;
+	u32 vctrl;
+	struct sd_emmc_config *ctrl = (struct sd_emmc_config *)&vctrl;
+	u32 vclkc;
+	struct sd_emmc_clock *clkc = (struct sd_emmc_clock *)&vclkc;
+	u32 adjust;
+	struct sd_emmc_adjust *gadjust = (struct sd_emmc_adjust *)&adjust;
+	u8 clk_div;
+	u32 clk_rate = 1000000000;
+
+	vctrl = readl(host->base + SD_EMMC_CFG);
+	if ((timing == MMC_TIMING_MMC_HS400) ||
+			(timing == MMC_TIMING_MMC_DDR52) ||
+			(timing == MMC_TIMING_UHS_DDR50)) {
+		if (timing == MMC_TIMING_MMC_HS400) {
+			ctrl->chk_ds = 1;
+			if (get_cpu_type() >= MESON_CPU_MAJOR_ID_GXL) {
+				adjust = readl(host->base + SD_EMMC_ADJUST);
+				gadjust->ds_enable = 1;
+				writel(adjust, host->base + SD_EMMC_ADJUST);
+				host->tuning_mode = AUTO_TUNING_MODE;
+			}
+		}
+		vclkc = readl(host->base + SD_EMMC_CLOCK);
+		ctrl->ddr = 1;
+		clk_div = clkc->div;
+		if (clk_div & 0x01)
+			clk_div++;
+		clkc->div = clk_div / 2;
+		writel(vclkc, host->base + SD_EMMC_CLOCK);
+		pdata->clkc = vclkc;
+		host->mmc->actual_clock = clk_rate / clk_div;
+		pr_info("%s: try set sd/emmc to DDR mode\n",
+				mmc_hostname(host->mmc));
+	} else
+		ctrl->ddr = 0;
+
+	writel(vctrl, host->base + SD_EMMC_CFG);
+	sd_emmc_dbg(AMLSD_DBG_IOS, "sd emmc is %s\n",
+			ctrl->ddr?"DDR mode":"SDR mode");
+}
+
+/*setup bus width, 1bit, 4bits, 8bits*/
+static void aml_sd_emmc_set_buswidth(
+		struct amlsd_host *host, u32 busw_ios)
+{
+	u32 vconf;
+	struct sd_emmc_config *conf = (struct sd_emmc_config *)&vconf;
+	u32 width = 0;
+
+	switch (busw_ios) {
+	case MMC_BUS_WIDTH_1:
+			width = 0;
+		break;
+	case MMC_BUS_WIDTH_4:
+			width = 1;
+		break;
+	case MMC_BUS_WIDTH_8:
+			width = 2;
+		break;
+	default:
+		sd_emmc_err("%s: error Data Bus\n",
+				mmc_hostname(host->mmc));
+		break;
+	}
+
+	if (width != host->bus_width) {
+		vconf = readl(host->base + SD_EMMC_CFG);
+		conf->bus_width = width;
+		writel(vconf, host->base + SD_EMMC_CFG);
+		host->bus_width = width;
+		sd_emmc_dbg(AMLSD_DBG_IOS, "Bus Width Ios %d\n", busw_ios);
+	}
+}
+
+/*call by mmc, power on, power off ...*/
+static void aml_sd_emmc_set_power(struct amlsd_host *host, u32 power_mode)
+{
+	struct amlsd_platform *pdata = host->pdata;
+
+	switch (power_mode) {
+	case MMC_POWER_ON:
+		if (pdata->pwr_pre)
+			pdata->pwr_pre(pdata);
+		if (pdata->pwr_on)
+			pdata->pwr_on(pdata);
+		break;
+	case MMC_POWER_UP:
+		break;
+	case MMC_POWER_OFF:
+		writel(0, host->base + SD_EMMC_DELAY);
+		writel(0, host->base + SD_EMMC_ADJUST);
+	default:
+		if (pdata->pwr_pre)
+			pdata->pwr_pre(pdata);
+		if (pdata->pwr_off)
+			pdata->pwr_off(pdata);
+		break;
+	}
+}
+
+static void meson_mmc_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
+{
+	struct amlsd_host *host = mmc_priv(mmc);
+	struct amlsd_platform *pdata = host->pdata;
+
+	if (!pdata->is_in)
+		return;
+
+	/*Set Power*/
+	aml_sd_emmc_set_power(host, ios->power_mode);
+
+	/* Set Clock */
+	meson_mmc_clk_set_rate(host, ios->clock);
+
+	/* Set Bus Width */
+	aml_sd_emmc_set_buswidth(host, ios->bus_width);
+
+	/* Set Date Mode */
+	aml_sd_emmc_set_timing(host, ios->timing);
+
+	if (ios->chip_select == MMC_CS_HIGH)
+		aml_cs_high(mmc);
+	else if (ios->chip_select == MMC_CS_DONTCARE)
+		aml_cs_dont_care(mmc);
+}
+
+#ifdef SD_EMMC_REQ_DMA_SGMAP
+static char *aml_sd_emmc_kmap_atomic(
+		struct scatterlist *sg, unsigned long *flags)
+{
+	local_irq_save(*flags);
+	return kmap_atomic(sg_page(sg)) + sg->offset;
+}
+
+static void aml_sd_emmc_kunmap_atomic(
+		void *buffer, unsigned long *flags)
+{
+	kunmap_atomic(buffer);
+	local_irq_restore(*flags);
+}
+
+/*
+ * aml_sg_copy_buffer - Copy data between
+ * a linear buffer and an SG list  for amlogic,
+ * We don't disable irq in this function
+ */
+static unsigned int aml_sd_emmc_pre_dma(struct amlsd_host *host,
+	struct mmc_request *mrq, struct sd_emmc_desc_info *desc)
+{
+	struct mmc_data *data = NULL;
+	struct scatterlist *sg;
+	struct sd_emmc_desc_info *desc_cur = NULL;
+	struct cmd_cfg *des_cmd_cur = NULL;
+	dma_addr_t sg_addr = 0;
+	char *buffer = NULL;
+	unsigned int desc_cnt = 0, i = 0, data_len = 0;
+	unsigned int data_size = 0, sg_blocks = 0;
+	unsigned char direction = 0, data_rw = 0;
+	unsigned char block_mode = 0, data_num = 0, bl_len = 0;
+	unsigned long flags;
+
+	data = mrq->cmd->data;
+	if (data == NULL) {
+		WARN_ON(1);
+		goto err_exit;
+	}
+
+	if (data->flags & MMC_DATA_READ) {
+		direction = DMA_FROM_DEVICE;
+		data_rw = 0;
+	} else{
+		direction = DMA_TO_DEVICE;
+		data_rw = 1;
+	}
+
+	host->sg_cnt = dma_map_sg(mmc_dev(host->mmc),
+		data->sg, data->sg_len, direction);
+	/*
+	 * This only happens when someone fed
+	 * us an invalid request.
+	 */
+	if (host->sg_cnt == 0) {
+		WARN_ON(1);
+		goto err_exit;
+	}
+#ifdef CHOICE_DEBUG
+	pr_info("%s %d sg_cnt:%d, direction:%d\n",
+	 __func__, __LINE__, host->sg_cnt, direction);
+#endif
+
+	data_size = (mrq->cmd->data->blksz * mrq->cmd->data->blocks);
+	block_mode = ((mrq->cmd->data->blocks > 1)
+		|| (mrq->cmd->data->blksz >= 512)) ? 1 : 0;
+
+	data_num = 0;/*(data_size > 4) ? 0 : 1;*/
+	bl_len = block_mode ? log2i(mrq->cmd->data->blksz) : 0;
+	host->dma_sts = 0;
+	if ((data_size & 0x3) && (host->sg_cnt > 1)) {
+		host->dma_sts = (1<<0); /*  */
+		pr_info("data:%d and sg_cnt:%d\n", data_size, host->sg_cnt);
+	}
+#ifdef CHOICE_DEBUG
+	pr_info("%s %d sg_cnt:%d, block_mode:%d,\n",
+			__func__, __LINE__, host->sg_cnt, block_mode);
+	pr_info("data_num:%d bl_len:%d, blocks:%d, blksz:%d\n",
+			data_num, bl_len, mrq->cmd->data->blocks,
+			mrq->cmd->data->blksz);
+#endif
+
+	/* prepare desc for data operation */
+	desc_cur = desc;
+
+	for_each_sg(data->sg, sg, data->sg_len, i) {
+		WARN_ON(sg->length & 0x3);
+
+		des_cmd_cur = (struct cmd_cfg *)&(desc_cur->cmd_info);
+		if (desc_cnt != 0) { /* for first desc, */
+			des_cmd_cur->no_resp = 1;
+			des_cmd_cur->no_cmd = 1;
+		}
+		des_cmd_cur->data_io = 1;
+
+		des_cmd_cur->owner = 1;
+		des_cmd_cur->timeout = 0xc;
+
+		des_cmd_cur->data_wr = data_rw;
+		des_cmd_cur->block_mode = block_mode;
+		des_cmd_cur->data_num = data_num;
+
+		data_len = block_mode ?
+			(sg_dma_len(sg)>>bl_len) : sg_dma_len(sg);
+
+		if ((data_len > 0x1ff) || (data_len == 0)) {
+			pr_info("Error block_mode:%d, data_len:%d, bl_len:%d\n",
+				block_mode, data_len, bl_len);
+			pr_info("mrq->cmd->data->blocks:%d, mrq->cmd->data->blksz:%d\n",
+				mrq->cmd->data->blocks, mrq->cmd->data->blksz);
+			WARN_ON(1);
+		}
+		des_cmd_cur->length = data_len;
+
+		sg_blocks += des_cmd_cur->length;
+		sg_addr = sg_dma_address(sg);
+
+		if (sg_addr & 0x7) { /* for no 64 bit addr alignment mode */
+			WARN_ON(host->sg_cnt > 1);
+
+			host->dma_sts |= (1<<1); /*  */
+
+			host->dma_sts |= (1<<3); /*  */
+			desc_cur->data_addr = host->bn_dma_buf;
+
+			if (data->flags & MMC_DATA_WRITE) {
+				buffer = aml_sd_emmc_kmap_atomic(sg, &flags);
+				memcpy(host->bn_buf, buffer, data_size);
+				aml_sd_emmc_kunmap_atomic(buffer, &flags);
+			}
+		} else{
+			desc_cur->data_addr = sg_addr;
+			/* desc_cur->data_addr &= ~(1<<0);   //DDR */
+		}
+#ifdef CHOICE_DEBUG
+	aml_sd_emmc_desc_print_info(desc_cur);
+	pr_info("%s %d desc_cur->data_addr : 0x%x\n",
+		"des_cmd_cur->length:%d, sg->length:%d\n",
+		"sg_dma_len(sg):%d, bl_len:%d\n",
+		__func__, __LINE__, desc_cur->data_addr,
+		des_cmd_cur->length, sg->length,
+		sg_dma_len(sg), bl_len);
+#endif
+		desc_cur++;
+		desc_cnt++;
+		memset(desc_cur, 0, sizeof(struct sd_emmc_desc_info));
+	}
+
+	WARN_ON(desc_cnt != host->sg_cnt);
+
+err_exit:
+	return host->sg_cnt;
+}
+
+/**
+ * aml_sg_copy_buffer - Copy data between
+ *a linear buffer and an SG list  for amlogic,
+ * We don't disable irq in this function
+ **/
+static int aml_sd_emmc_post_dma(struct amlsd_host *host,
+		struct mmc_request *mrq)
+{
+	struct mmc_data *data = NULL;
+	struct scatterlist *sg;
+	char *buffer = NULL;
+	unsigned long flags;
+	int i, ret = 0;
+
+
+	data = mrq->cmd->data;
+	if (data == NULL) {
+		WARN_ON(1);
+		ret = -1;
+		goto err_exit;
+	}
+
+	if ((data->flags & MMC_DATA_READ) && (host->dma_sts & (1<<1))) {
+		dma_sync_sg_for_cpu(mmc_dev(host->mmc), data->sg,
+			data->sg_len, DMA_FROM_DEVICE);
+
+		for_each_sg(data->sg, sg, host->sg_cnt, i) {
+			if (sg_dma_address(sg) & 0x7) {
+				WARN_ON(!(host->dma_sts & (0x3<<2)));
+
+				buffer = aml_sd_emmc_kmap_atomic(sg, &flags);
+				memcpy(buffer, host->bn_buf,
+				(mrq->data->blksz * mrq->data->blocks));
+				aml_sd_emmc_kunmap_atomic(buffer, &flags);
+			}
+		}
+	}
+
+	dma_unmap_sg(mmc_dev(host->mmc), data->sg, data->sg_len,
+		(data->flags & MMC_DATA_READ) ?
+			DMA_FROM_DEVICE : DMA_TO_DEVICE);
+
+err_exit:
+	return ret;
+}
+#endif
+
+static void aml_sd_emmc_check_sdio_irq(struct amlsd_host *host)
+{
+	u32 vstat = readl(host->base + SD_EMMC_STATUS);
+	struct sd_emmc_status *ista = (struct sd_emmc_status *)&vstat;
+
+	if (host->sdio_irqen) {
+		if ((ista->irq_sdio || !(ista->dat_i & 0x02)) &&
+			(host->mmc->sdio_irq_thread) &&
+			(!atomic_read(&host->mmc->sdio_irq_thread_abort))) {
+			/* pr_info("signalling irq 0x%x\n", vstat); */
+			mmc_signal_sdio_irq(host->mmc);
+		}
+	}
+}
+static int meson_mmc_request_done(struct mmc_host *mmc, struct mmc_request *mrq)
+{
+	struct amlsd_host *host = mmc_priv(mmc);
+	struct amlsd_platform *pdata = host->pdata;
+	unsigned long flags;
+
+	WARN_ON(host->mrq != mrq);
+
+	spin_lock_irqsave(&host->mrq_lock, flags);
+	host->xfer_step = XFER_FINISHED;
+	host->mrq = NULL;
+	host->status = HOST_INVALID;
+	spin_unlock_irqrestore(&host->mrq_lock, flags);
+	if (pdata->xfer_post)
+		pdata->xfer_post(mmc);
+
+	aml_sd_emmc_check_sdio_irq(host);
+	mmc_request_done(host->mmc, mrq);
+
+	return 0;
+}
+
+static void meson_mmc_start_cmd(struct mmc_host *mmc, struct mmc_request *mrq)
+{
+	struct amlsd_host *host = mmc_priv(mmc);
+	struct amlsd_platform *pdata = host->pdata;
+	struct sd_emmc_desc_info *desc_cur;
+	struct cmd_cfg *des_cmd_cur = NULL;
+	u32 conf_flag = 0;
+	u32 vconf;
+	struct sd_emmc_config *pconf = (struct sd_emmc_config *)&vconf;
+	u32 vstart;
+	struct sd_emmc_start *desc_start = (struct sd_emmc_start *)&vstart;
+#ifdef AML_CALIBRATION
+	u32 adjust;
+	struct sd_emmc_adjust *gadjust = (struct sd_emmc_adjust *)&adjust;
+#endif
+	u32 desc_cnt = 0;
+#ifdef SD_EMMC_REQ_DMA_SGMAP
+	u32 sg_len = 0;
+#else
+	u32 cfg;
+	u8 blk_len;
+	unsigned int xfer_bytes = 0;
+#endif
+
+	/* Stop execution */
+	vstart = readl(host->base + SD_EMMC_START);
+	desc_start->busy = 0;
+	writel(vstart, host->base + SD_EMMC_START);
+
+	/* Setup descriptors */
+	desc_cur = (struct sd_emmc_desc_info *)host->desc_buf;
+	desc_cnt++;
+
+	memset(desc_cur, 0, sizeof(struct sd_emmc_desc_info));
+
+	sd_emmc_dbg(AMLSD_DBG_REQ, "%s %d cmd:%d, flags:0x%x, args:0x%x\n",
+			__func__, __LINE__,	mrq->cmd->opcode,
+			mrq->cmd->flags, mrq->cmd->arg);
+
+	vconf = readl(host->base + SD_EMMC_CFG);
+	/*sd/sdio switch volatile cmd11  need clock 6ms base on sd spec. */
+	if (mrq->cmd->opcode == SD_SWITCH_VOLTAGE) {
+		conf_flag |= 1 << 0;
+		pconf->auto_clk = 0;
+		host->sd_sdio_switch_volat_done = 0;
+	}
+	if ((pconf->auto_clk) && (pdata->auto_clk_close)) {
+		conf_flag |= 1 << 1;
+		pconf->auto_clk = 0;
+	}
+
+	/*check package size*/
+	if (mrq->cmd->data) {
+		if (pconf->bl_len != log2i(mrq->data->blksz)) {
+			conf_flag |= 1 << 3;
+			pconf->bl_len = log2i(mrq->data->blksz);
+		}
+	}
+	if (conf_flag)
+		writel(vconf, host->base + SD_EMMC_CFG);
+
+	/*Add external CMD23 for multi-block operation*/
+#ifdef SD_EMMC_MANUAL_CMD23
+	if (((mrq->cmd->opcode == MMC_READ_MULTIPLE_BLOCK)
+		|| (mrq->cmd->opcode == MMC_WRITE_MULTIPLE_BLOCK))
+		&& (mrq->cmd->data) && (mrq->sbc)) {
+		des_cmd_cur = (struct cmd_cfg *)&(desc_cur->cmd_info);
+		/*Command Index*/
+		des_cmd_cur->cmd_index = MMC_SET_BLOCK_COUNT;
+		des_cmd_cur->no_resp = 0;
+		des_cmd_cur->r1b = 0;
+		des_cmd_cur->data_io = 0;
+		/* 10mS for only cmd timeout */
+		des_cmd_cur->timeout = 0xc;
+		des_cmd_cur->owner = 1;
+		des_cmd_cur->end_of_chain = 0;
+
+		desc_cur->cmd_arg = mrq->cmd->data->blocks;
+		/* response save into resp_addr itself */
+		des_cmd_cur->resp_num = 1;
+		desc_cur->resp_addr = 0;
+		desc_cnt++;
+		desc_cur++;
+		memset(desc_cur, 0, sizeof(struct sd_emmc_desc_info));
+
+	}
+#endif
+
+	des_cmd_cur = (struct cmd_cfg *)&(desc_cur->cmd_info);
+	des_cmd_cur->cmd_index = mrq->cmd->opcode;
+	des_cmd_cur->error = 0;
+	des_cmd_cur->owner = 1;
+	des_cmd_cur->end_of_chain = 0;
+
+	/* Response */
+	if (mrq->cmd->flags & MMC_RSP_PRESENT) {
+		des_cmd_cur->no_resp = 0;
+		if (mrq->cmd->flags & MMC_RSP_136) {
+			/* response save into sram*/
+			des_cmd_cur->resp_128 = 1;
+			des_cmd_cur->resp_num = 0;
+			desc_cur->resp_addr = 1;
+		} else {
+			/* response save into resp_addr itself */
+			des_cmd_cur->resp_num = 1;
+			desc_cur->resp_addr = 0;
+		}
+
+		if (mrq->cmd->flags & MMC_RSP_BUSY)
+			des_cmd_cur->r1b = 1;
+
+		if (!(mrq->cmd->flags & MMC_RSP_CRC))
+			des_cmd_cur->resp_nocrc = 1;
+	} else
+		des_cmd_cur->no_resp = 1;
+
+	desc_cur->cmd_arg = mrq->cmd->arg;
+	/* data? */
+	if (mrq->cmd->data) {
+#ifdef SD_EMMC_REQ_DMA_SGMAP
+		des_cmd_cur->timeout = 0xc;
+		sg_len = aml_sd_emmc_pre_dma(host, mrq, desc_cur);
+		WARN_ON(sg_len == 0);
+		desc_cnt += (sg_len - 1);
+		desc_cur += (sg_len - 1); /* last desc here */
+#else
+		desc_cur->cmd_info |= CMD_CFG_DATA_IO;
+		if (mrq->cmd->data->blocks > 1) {
+			desc_cur->cmd_info |= CMD_CFG_BLOCK_MODE;
+			desc_cur->cmd_info |=
+				(mrq->cmd->data->blocks & CMD_CFG_LENGTH_MASK)
+				<< CMD_CFG_LENGTH_SHIFT;
+
+			/* check if block-size matches, if not update */
+			cfg = readl(host->base + SD_EMMC_CFG);
+			blk_len = cfg & (CFG_BLK_LEN_MASK << CFG_BLK_LEN_SHIFT);
+			blk_len >>= CFG_BLK_LEN_SHIFT;
+			if (blk_len != ilog2(mrq->cmd->data->blksz)) {
+				dev_warn(host->dev, "%s: update blk_len %d -> %d\n",
+					__func__, blk_len,
+					 ilog2(mrq->cmd->data->blksz));
+				blk_len = ilog2(mrq->cmd->data->blksz);
+				cfg &= ~(CFG_BLK_LEN_MASK << CFG_BLK_LEN_SHIFT);
+				cfg |= blk_len << CFG_BLK_LEN_SHIFT;
+				writel(cfg, host->base + SD_EMMC_CFG);
+			}
+		} else {
+			desc_cur->cmd_info &= ~CMD_CFG_BLOCK_MODE;
+			desc_cur->cmd_info |=
+				(mrq->cmd->data->blksz & CMD_CFG_LENGTH_MASK)
+				<< CMD_CFG_LENGTH_SHIFT;
+		}
+
+		mrq->cmd->data->bytes_xfered = 0;
+		xfer_bytes = mrq->cmd->data->blksz * mrq->cmd->data->blocks;
+		if (mrq->cmd->data->flags & MMC_DATA_WRITE) {
+			desc_cur->cmd_info |= CMD_CFG_DATA_WR;
+			WARN_ON(xfer_bytes > SD_EMMC_BOUNCE_REQ_SIZE);
+			sg_copy_to_buffer(mrq->cmd->data->sg,
+					mrq->cmd->data->sg_len,
+					host->bn_buf, xfer_bytes);
+			mrq->cmd->data->bytes_xfered = xfer_bytes;
+			dma_wmb();
+		} else {
+			desc_cur->cmd_info &= ~CMD_CFG_DATA_WR;
+		}
+
+		if (xfer_bytes > 0) {
+			desc_cur->cmd_info &= ~CMD_CFG_DATA_NUM;
+			desc_cur->data_addr = host->bn_dma_buf & CMD_DATA_MASK;
+		} else {
+			/* write data to data_addr */
+			desc_cur->cmd_info |= CMD_CFG_DATA_NUM;
+			desc_cur->data_addr = 0;
+		}
+
+		cmd_cfg_timeout = 12;
+#endif
+
+#ifdef SD_EMMC_MANUAL_CMD23
+		if (((mrq->cmd->opcode == MMC_WRITE_MULTIPLE_BLOCK)
+			|| (mrq->cmd->opcode == MMC_READ_MULTIPLE_BLOCK))
+			&& (!host->cmd_is_stop) && (!mrq->sbc)
+			&& !(mrq->cmd->flags & (1 << 30))) {
+
+			/* pr_info("Send stop command here\n"); */
+
+			/* for stop command,
+			 * add another descriptor for stop command
+			 */
+			desc_cnt++;
+			desc_cur++;
+			memset(desc_cur, 0, sizeof(struct sd_emmc_desc_info));
+
+			des_cmd_cur = (struct cmd_cfg *)&(desc_cur->cmd_info);
+
+			/*Command Index*/
+			des_cmd_cur->cmd_index = MMC_STOP_TRANSMISSION;
+			des_cmd_cur->no_resp = 0;
+			des_cmd_cur->r1b = 1;
+			des_cmd_cur->data_io = 0;
+			/* 10mS for only cmd timeout */
+			des_cmd_cur->timeout = 0xc;
+			des_cmd_cur->owner = 1;
+
+			/* response save into resp_addr itself */
+			des_cmd_cur->resp_num = 1;
+			desc_cur->resp_addr = 0;
+		}
+#endif
+	} else {
+		des_cmd_cur->data_io = 0;
+		/* Current 10uS based. 2^10 = 10mS for only cmd timeout */
+		des_cmd_cur->timeout = 0xa;
+	}
+
+	if (mrq->cmd->opcode == MMC_SEND_STATUS)
+		des_cmd_cur->timeout = 0xb;
+	if (mrq->cmd->opcode == MMC_ERASE)
+		des_cmd_cur->timeout = 0xf;
+
+	host->cmd = mrq->cmd;
+
+	/* Last descriptor */
+	des_cmd_cur = (struct cmd_cfg *)&(desc_cur->cmd_info);
+	des_cmd_cur->end_of_chain = 1;
+	writel(SD_EMMC_IRQ_ALL, host->base + SD_EMMC_STATUS);
+
+	vstart = readl(host->base + SD_EMMC_START);
+	desc_start->init = 0;
+	desc_start->busy = 1;
+	desc_start->addr = host->desc_dma_addr >> 2;
+
+	dma_rmb();
+	wmb(); /* ensure descriptor is written before kicked */
+#ifdef AML_CALIBRATION
+	if ((mrq->cmd->opcode == 18) && (pdata->caling == 1)) {
+		adjust = readl(host->base + SD_EMMC_ADJUST);
+		gadjust->cali_rise = 0;
+		gadjust->cali_sel = pdata->c_ctrl.line_x;
+		gadjust->cali_enable = 1;
+		writel(adjust, host->base + SD_EMMC_ADJUST);
+	}
+#endif
+	writel(vstart, host->base + SD_EMMC_START);
+}
+
+static void meson_mmc_request(struct mmc_host *mmc, struct mmc_request *mrq)
+{
+	struct amlsd_host *host = mmc_priv(mmc);
+	struct amlsd_platform *pdata = host->pdata;
+	unsigned long flags;
+
+	WARN_ON(!mmc);
+	WARN_ON(!mrq);
+
+	if (aml_check_unsupport_cmd(mmc, mrq))
+		return;
+
+	sd_emmc_dbg(AMLSD_DBG_REQ, "%s: starting CMD%u arg %08x flags %08x\n",
+			mmc_hostname(mmc), mrq->cmd->opcode,
+			mrq->cmd->arg, mrq->cmd->flags);
+
+	if ((pdata->is_in) && (mrq->cmd->opcode == 0))
+		host->init_flag = 1;
+
+	/*clear error flag if last command retried failed */
+	if (host->error_flag & (1 << 30))
+		host->error_flag = 0;
+
+	/*clear pinmux & set pinmux*/
+	if (pdata->xfer_pre)
+		pdata->xfer_pre(mmc);
+
+	spin_lock_irqsave(&host->mrq_lock, flags);
+	host->mrq = mrq;
+	host->opcode = mrq->cmd->opcode;
+
+	meson_mmc_start_cmd(mmc, mrq);
+	host->xfer_step = XFER_START;
+	spin_unlock_irqrestore(&host->mrq_lock, flags);
+}
+
+static int meson_mmc_read_resp(struct mmc_host *mmc, struct mmc_command *cmd)
+{
+	struct amlsd_host *host = mmc_priv(mmc);
+	struct sd_emmc_desc_info *desc_info =
+		(struct sd_emmc_desc_info *)host->desc_buf;
+	struct cmd_cfg *des_cmd_cur = NULL;
+	int i;
+
+	for (i = 0; i < (SD_EMMC_MAX_DESC_MUN>>2); i++) {
+		des_cmd_cur = (struct cmd_cfg *)&(desc_info->cmd_info);
+		if (des_cmd_cur->cmd_index == cmd->opcode)
+			break;
+		desc_info++;
+	}
+	if (cmd->flags & MMC_RSP_136) {
+		cmd->resp[0] = readl(host->base + SD_EMMC_CMD_RSP3);
+		cmd->resp[1] = readl(host->base + SD_EMMC_CMD_RSP2);
+		cmd->resp[2] = readl(host->base + SD_EMMC_CMD_RSP1);
+		cmd->resp[3] = readl(host->base + SD_EMMC_CMD_RSP);
+	} else if (cmd->flags & MMC_RSP_PRESENT) {
+		cmd->resp[0] = desc_info->resp_addr;
+	}
+
+	return 0;
+}
+
+void aml_host_bus_fsm_show(struct amlsd_host *host, int fsm_val)
+{
+	switch (fsm_val) {
+	case BUS_FSM_IDLE:
+		sd_emmc_err("%s: err: idle, bus_fsm:0x%x\n",
+				mmc_hostname(host->mmc), fsm_val);
+		break;
+	case BUS_FSM_SND_CMD:
+		sd_emmc_err("%s: err: send cmd, bus_fsm:0x%x\n",
+				mmc_hostname(host->mmc), fsm_val);
+		break;
+	case BUS_FSM_CMD_DONE:
+		sd_emmc_err("%s: err: wait for cmd done, bus_fsm:0x%x\n",
+				mmc_hostname(host->mmc), fsm_val);
+		break;
+	case BUS_FSM_RESP_START:
+		sd_emmc_err("%s: err: resp start, bus_fsm:0x%x\n",
+				mmc_hostname(host->mmc), fsm_val);
+			break;
+	case BUS_FSM_RESP_DONE:
+		sd_emmc_err("%s: err: wait for resp done, bus_fsm:0x%x\n",
+				mmc_hostname(host->mmc), fsm_val);
+		break;
+	case BUS_FSM_DATA_START:
+		sd_emmc_err("%s: err: data start, bus_fsm:0x%x\n",
+				mmc_hostname(host->mmc), fsm_val);
+		break;
+	case BUS_FSM_DATA_DONE:
+		sd_emmc_err("%s: err: wait for data done, bus_fsm:0x%x\n",
+				mmc_hostname(host->mmc), fsm_val);
+		break;
+	case BUS_FSM_DESC_WRITE_BACK:
+		sd_emmc_err("%s: err: wait for desc write back, bus_fsm:0x%x\n",
+				mmc_hostname(host->mmc), fsm_val);
+		break;
+	case BUS_FSM_IRQ_SERVICE:
+		sd_emmc_err("%s: err: wait for irq service, bus_fsm:0x%x\n",
+				mmc_hostname(host->mmc), fsm_val);
+		break;
+	default:
+		sd_emmc_err("%s: err: unknown err, bus_fsm:0x%x\n",
+				mmc_hostname(host->mmc), fsm_val);
+		break;
+	}
+}
+
+void mmc_cmd_LBA_show(struct mmc_host *mmc, struct mmc_request *mrq)
+{
+	int i;
+	uint64_t offset, size;
+	struct partitions *pp;
+
+	if (!pt_fmt || !mrq->cmd->arg) /* no disk or no arg, nothing to do */
+		return;
+
+	for (i = 0; i < pt_fmt->part_num; i++) {
+		pp = &(pt_fmt->partitions[i]);
+		offset = pp->offset >> 9; /* unit:512 bytes */
+		size = pp->size >> 9; /* unit:512 bytes */
+
+		if ((mrq->cmd->arg >= offset)
+				&& (mrq->cmd->arg < (offset + size))) {
+			sd_emmc_err("%s: cmd %d, arg 0x%x, operation is in [%s] disk!\n",
+				mmc_hostname(mmc),
+				mrq->cmd->opcode, mrq->cmd->arg, pp->name);
+			break;
+		}
+	}
+	if (i == pt_fmt->part_num)
+		sd_emmc_err("%s: cmd %d, arg 0x%x, operation is in [unknown] disk!\n",
+			mmc_hostname(mmc),
+			mrq->cmd->opcode, mrq->cmd->arg);
+}
+
+static irqreturn_t meson_mmc_irq(int irq, void *dev_id)
+{
+	struct amlsd_host *host = dev_id;
+	struct mmc_request *mrq;
+	unsigned long flags;
+	struct amlsd_platform *pdata = host->pdata;
+	struct mmc_host *mmc;
+	u32 vstat = 0;
+	u32 virqc = 0;
+	u32 vstart = 0;
+	u32 err = 0;
+
+	struct sd_emmc_irq_en *irqc = (struct sd_emmc_irq_en *)&virqc;
+	struct sd_emmc_status *ista = (struct sd_emmc_status *)&vstat;
+	struct sd_emmc_start *desc_start = (struct sd_emmc_start *)&vstart;
+
+	if (WARN_ON(!host))
+		return IRQ_NONE;
+
+	virqc = readl(host->base + SD_EMMC_IRQ_EN) & 0xffff;
+	vstat = readl(host->base + SD_EMMC_STATUS) & 0xffffffff;
+	host->ista = vstat;
+
+	sd_emmc_dbg(AMLSD_DBG_REQ, "%s %d occurred, vstat:0x%x\n",
+			__func__, __LINE__, vstat);
+
+	if (irqc->irq_sdio && ista->irq_sdio) {
+		if ((host->mmc->sdio_irq_thread)
+			&& (!atomic_read(&host->mmc->sdio_irq_thread_abort))) {
+			mmc_signal_sdio_irq(host->mmc);
+			if (!(vstat & 0x3fff))
+				return IRQ_HANDLED;
+		}
+	} else if (!(vstat & 0x3fff))
+		return IRQ_HANDLED;
+
+	spin_lock_irqsave(&host->mrq_lock, flags);
+	mrq = host->mrq;
+	mmc = host->mmc;
+	vstart = readl(host->base + SD_EMMC_START);
+	if ((desc_start->busy == 1)
+		&& (aml_card_type_mmc(pdata) ||
+			(aml_card_type_non_sdio(pdata)))) {
+		desc_start->busy = 0;
+		writel(vstart, host->base + SD_EMMC_START);
+	}
+	if (!mmc) {
+		pr_info("sd_emmc_regs: irq_en = 0x%x at line %d\n",
+			readl(host->base + SD_EMMC_IRQ_EN), __LINE__);
+		pr_info("sd_emmc_regs: status = 0x%x at line %d\n",
+			readl(host->base + SD_EMMC_STATUS), __LINE__);
+		pr_info("sd_emmc_regs: cfg = 0x%x at line %d\n",
+			readl(host->base + SD_EMMC_CFG), __LINE__);
+		pr_info("sd_emmc_regs: clock = 0x%x at line %d\n",
+			readl(host->base + SD_EMMC_CLOCK), __LINE__);
+	}
+
+#ifdef CHOICE_DEBUG
+	pr_info("%s %d cmd:%d arg:0x%x ",
+		__func__, __LINE__, mrq->cmd->opcode, mrq->cmd->arg);
+	if (mrq->cmd->data)
+		pr_info("blksz:%d, blocks:%d\n",
+			mrq->data->blksz, mrq->data->blocks);
+#endif
+
+	if (!mrq && !irqc->irq_sdio) {
+		if (!ista->irq_sdio) {
+			sd_emmc_err("NULL mrq in aml_sd_emmc_irq step %d",
+				host->xfer_step);
+			sd_emmc_err("status:0x%x,irq_c:0x%0x\n",
+					readl(host->base + SD_EMMC_STATUS),
+					readl(host->base + SD_EMMC_IRQ_EN));
+		}
+		if (host->xfer_step == XFER_FINISHED ||
+			host->xfer_step == XFER_TIMER_TIMEOUT){
+			spin_unlock_irqrestore(&host->mrq_lock, flags);
+			return IRQ_HANDLED;
+		}
+#ifdef CHOICE_DEBUG
+/*	aml_sd_emmc_print_reg(host);*/
+#endif
+		spin_unlock_irqrestore(&host->mrq_lock, flags);
+		return IRQ_HANDLED;
+	}
+#ifdef CHOICE_DEBUG
+	if ((host->xfer_step != XFER_AFTER_START)
+		&& (!host->cmd_is_stop) && !irqc->irq_sdio) {
+		sd_emmc_err("%s: host->xfer_step=%d\n",
+			mmc_hostname(mmc), host->xfer_step);
+		pr_info("%%sd_emmc_regs: irq_en = 0x%x at line %d\n",
+			readl(host->base + SD_EMMC_IRQ_EN), __LINE__);
+		pr_info("%%sd_emmc_regs: status = 0x%x at line %d\n",
+			readl(host->base + SD_EMMC_STATUS), __LINE__);
+		pr_info("%%sd_emmc_regs: cfg = 0x%x at line %d\n",
+			readl(host->base + SD_EMMC_CFG), __LINE__);
+		pr_info("%%sd_emmc_regs: clock = 0x%x at line %d\n",
+			readl(host->base + SD_EMMC_CLOCK), __LINE__);
+	}
+#endif
+	if (mrq) {
+		if (host->cmd_is_stop)
+			host->xfer_step = XFER_IRQ_TASKLET_BUSY;
+		else
+			host->xfer_step = XFER_IRQ_OCCUR;
+	}
+
+	/* ack all (enabled) interrupts */
+	writel(0x7fff, host->base + SD_EMMC_STATUS);
+	spin_unlock_irqrestore(&host->mrq_lock, flags);
+
+	if (ista->end_of_chain || ista->desc_irq) {
+		if (mrq->data)
+			host->status = HOST_TASKLET_DATA;
+		else
+			host->status = HOST_TASKLET_CMD;
+		mrq->cmd->error = 0;
+	}
+
+	if ((vstat & 0x1FFF) && (!host->cmd_is_stop))
+		err = 1;
+
+	if (ista->rxd_err || ista->txd_err) {
+		host->status = HOST_DAT_CRC_ERR;
+		mrq->cmd->error = -EILSEQ;
+		if (host->is_tunning == 0) {
+			sd_emmc_err("%s: warning... data crc, vstat:0x%x, virqc:%x",
+					mmc_hostname(host->mmc),
+					vstat, virqc);
+			sd_emmc_err("@ cmd %d with %p; stop %d, status %d\n",
+					mrq->cmd->opcode, mrq->data,
+					host->cmd_is_stop,
+					host->status);
+		}
+	} else if (ista->desc_err) {
+		if (host->is_tunning == 0)
+			sd_emmc_err("%s: warning... desc err,vstat:0x%x,virqc:%x\n",
+					mmc_hostname(host->mmc),
+					vstat, virqc);
+		host->status = HOST_DAT_CRC_ERR;
+		mrq->cmd->error = -EILSEQ;
+	} else if (ista->resp_err) {
+		if (host->is_tunning == 0)
+			sd_emmc_err("%s: warning... response crc,vstat:0x%x,virqc:%x\n",
+					mmc_hostname(host->mmc),
+					vstat, virqc);
+		pr_info("%s %d cmd:%d arg:0x%x ",
+				__func__, __LINE__,
+				mrq->cmd->opcode, mrq->cmd->arg);
+		host->status = HOST_RSP_CRC_ERR;
+		mrq->cmd->error = -EILSEQ;
+	} else if (ista->resp_timeout) {
+		if (host->is_tunning == 0)
+			sd_emmc_err("%s: resp_timeout,vstat:0x%x,virqc:%x\n",
+					mmc_hostname(host->mmc),
+					vstat, virqc);
+		host->status = HOST_RSP_TIMEOUT_ERR;
+		mrq->cmd->error = -ETIMEDOUT;
+	} else if (ista->desc_timeout) {
+		if (host->is_tunning == 0)
+			sd_emmc_err("%s: desc_timeout,vstat:0x%x,virqc:%x\n",
+					mmc_hostname(host->mmc),
+					vstat, virqc);
+		host->status = HOST_DAT_TIMEOUT_ERR;
+		mrq->cmd->error = -ETIMEDOUT;
+	}
+
+	if (err) {
+		if (host->is_tunning == 0)
+			aml_host_bus_fsm_show(host, ista->bus_fsm);
+		if (aml_card_type_mmc(pdata))
+			mmc_cmd_LBA_show(mmc, mrq);
+	}
+
+	if (host->xfer_step == XFER_IRQ_UNKNOWN_IRQ)
+		return IRQ_HANDLED;
+	else
+		return IRQ_WAKE_THREAD;
+}
+
+struct mmc_command aml_sd_emmc_cmd = {
+	.opcode = MMC_STOP_TRANSMISSION,
+	.flags = MMC_RSP_SPI_R1B | MMC_RSP_R1B | MMC_CMD_AC,
+};
+struct mmc_request aml_sd_emmc_stop = {
+	.cmd = &aml_sd_emmc_cmd,
+};
+
+void aml_sd_emmc_send_stop(struct amlsd_host *host)
+{
+	unsigned long flags;
+
+	/*Already in mrq_lock*/
+	spin_lock_irqsave(&host->mrq_lock, flags);
+	host->error_bak = host->mrq->cmd->error;
+	host->mrq->cmd->error = 0;
+	host->cmd_is_stop = 1;
+	meson_mmc_start_cmd(host->mmc, &aml_sd_emmc_stop);
+	spin_unlock_irqrestore(&host->mrq_lock, flags);
+}
+
+static irqreturn_t meson_mmc_irq_thread(int irq, void *dev_id)
+{
+	struct amlsd_host *host = dev_id;
+	struct amlsd_platform *pdata = host->pdata;
+	unsigned long flags;
+	struct mmc_request *mrq;
+
+	u32 status, rx_phase, xfer_bytes = 0;
+	enum aml_mmc_waitfor xfer_step;
+	struct aml_emmc_adjust *emmc_adj = &host->emmc_adj;
+	struct aml_emmc_rxclk *emmc_rxclk = &host->emmc_rxclk;
+	u32 adjust;
+	struct sd_emmc_adjust *gadjust = (struct sd_emmc_adjust *)&adjust;
+	u32 vclk;
+	struct sd_emmc_clock *clkc = (struct sd_emmc_clock *)&(vclk);
+
+	spin_lock_irqsave(&host->mrq_lock, flags);
+	mrq = host->mrq;
+	xfer_step = host->xfer_step;
+	status = host->status;
+
+	if ((xfer_step == XFER_FINISHED) || (xfer_step == XFER_TIMER_TIMEOUT)) {
+		sd_emmc_err("Warning: %s xfer_step=%d, host->status=%d\n",
+			mmc_hostname(host->mmc), xfer_step, status);
+		spin_unlock_irqrestore(&host->mrq_lock, flags);
+		return IRQ_HANDLED;
+	}
+
+	WARN_ON((host->xfer_step != XFER_IRQ_OCCUR)
+		 && (host->xfer_step != XFER_IRQ_TASKLET_BUSY));
+
+	if (!mrq) {
+		sd_emmc_err("%s: !mrq xfer_step %d\n",
+			mmc_hostname(host->mmc), xfer_step);
+		if (xfer_step == XFER_FINISHED ||
+			xfer_step == XFER_TIMER_TIMEOUT){
+			spin_unlock_irqrestore(&host->mrq_lock, flags);
+			return IRQ_HANDLED;
+		}
+/*		aml_sd_emmc_print_err(host);*/
+	}
+
+	if (host->cmd_is_stop) {
+		/* --new irq enter, */
+		host->cmd_is_stop = 0;
+		mrq->cmd->error = host->error_bak;
+		spin_unlock_irqrestore(&host->mrq_lock, flags);
+		meson_mmc_request_done(host->mmc, host->mrq);
+
+		return IRQ_HANDLED;
+	}
+	spin_unlock_irqrestore(&host->mrq_lock, flags);
+
+	WARN_ON(!host->mrq->cmd);
+
+	switch (status) {
+	case HOST_TASKLET_DATA:
+	case HOST_TASKLET_CMD:
+		/* WARN_ON(aml_sd_emmc_desc_check(host)); */
+		sd_emmc_dbg(AMLSD_DBG_REQ, "%s %d cmd:%d\n",
+			__func__, __LINE__, mrq->cmd->opcode);
+		host->error_flag = 0;
+		if (mrq->cmd->data &&  mrq->cmd->opcode) {
+			xfer_bytes = mrq->data->blksz*mrq->data->blocks;
+			/* copy buffer from dma to data->sg in read cmd*/
+#ifdef SD_EMMC_REQ_DMA_SGMAP
+			WARN_ON(aml_sd_emmc_post_dma(host, mrq));
+#else
+			if (host->mrq->data->flags & MMC_DATA_READ) {
+				WARN_ON(xfer_bytes > SD_EMMC_BOUNCE_REQ_SIZE);
+				sg_copy_from_buffer(mrq->data->sg,
+						mrq->data->sg_len,
+						host->bn_buf, xfer_bytes);
+			}
+		}
+
+#endif
+			mrq->data->bytes_xfered = xfer_bytes;
+			host->xfer_step = XFER_TASKLET_DATA;
+		} else {
+			host->xfer_step = XFER_TASKLET_CMD;
+		}
+		spin_lock_irqsave(&host->mrq_lock, flags);
+		mrq->cmd->error = 0;
+		spin_unlock_irqrestore(&host->mrq_lock, flags);
+
+		/* check ready?? */
+		/*Wait command busy*/
+		meson_mmc_read_resp(host->mmc, mrq->cmd);
+		meson_mmc_request_done(host->mmc, mrq);
+
+		break;
+
+	case HOST_RSP_TIMEOUT_ERR:
+	case HOST_DAT_TIMEOUT_ERR:
+	case HOST_RSP_CRC_ERR:
+	case HOST_DAT_CRC_ERR:
+		if (host->is_tunning == 0)
+			pr_info("%s %d %s: cmd:%d\n", __func__, __LINE__,
+				mmc_hostname(host->mmc), mrq->cmd->opcode);
+		if (mrq->cmd->data) {
+			dma_unmap_sg(mmc_dev(host->mmc), mrq->cmd->data->sg,
+				mrq->cmd->data->sg_len,
+				(mrq->cmd->data->flags & MMC_DATA_READ) ?
+					DMA_FROM_DEVICE : DMA_TO_DEVICE);
+		}
+		meson_mmc_read_resp(host->mmc, mrq->cmd);
+
+		/* set retry @ 1st error happens! */
+		if ((host->error_flag == 0)
+			&& (aml_card_type_mmc(pdata)
+				|| aml_card_type_non_sdio(pdata))
+			&& (host->is_tunning == 0)) {
+
+			sd_emmc_err("%s() %d: set 1st retry!\n",
+				__func__, __LINE__);
+			host->error_flag |= (1<<0);
+			spin_lock_irqsave(&host->mrq_lock, flags);
+			mrq->cmd->retries = AML_ERROR_RETRY_COUNTER;
+			spin_unlock_irqrestore(&host->mrq_lock, flags);
+		}
+
+		if (aml_card_type_non_sdio(pdata)
+			&& (host->error_flag & (1<<0))
+			&& mrq->cmd->retries
+		/*	&& host->mmc->uhs_speed*/) {
+			sd_emmc_err("retry cmd %d the %d-th time(s)\n",
+					mrq->cmd->opcode, mrq->cmd->retries);
+			vclk = readl(host->base + SD_EMMC_CLOCK);
+			rx_phase = clkc->rx_phase;
+			rx_phase++;
+			rx_phase %= 4;
+			pr_err("sd, retry, rx_phase %d -> %d\n",
+					clkc->rx_phase, rx_phase);
+			clkc->rx_phase = rx_phase;
+			writel(vclk, host->base + SD_EMMC_CLOCK);
+			pdata->clkc = vclk;
+		}
+
+		if (aml_card_type_mmc(pdata) &&
+			(host->error_flag & (1<<0)) && mrq->cmd->retries) {
+			sd_emmc_err("retry cmd %d the %d-th time(s)\n",
+				mrq->cmd->opcode, mrq->cmd->retries);
+			/* change configs on current host */
+			switch (host->tuning_mode) {
+			case AUTO_TUNING_MODE:
+				if ((status == HOST_RSP_TIMEOUT_ERR)
+					|| (status == HOST_RSP_CRC_ERR)) {
+					adjust = readl(host->base
+							+ SD_EMMC_ADJUST);
+					if (gadjust->cmd_delay <= 13)
+						gadjust->cmd_delay += 2;
+					else if (gadjust->cmd_delay % 2)
+						gadjust->cmd_delay = 0;
+					else
+						gadjust->cmd_delay = 1;
+					writel(adjust, host->base
+							+ SD_EMMC_ADJUST);
+					sd_emmc_err("cmd_delay change to %d\n",
+							gadjust->cmd_delay);
+				}
+				break;
+			case ADJ_TUNING_MODE:
+				adjust = readl(host->base + SD_EMMC_ADJUST);
+				emmc_adj->adj_point++;
+				emmc_adj->adj_point	%= emmc_adj->clk_div;
+				pr_err("emmc, %d retry, adj %d -> %d\n",
+						mrq->cmd->retries,
+						gadjust->adj_delay,
+						emmc_adj->adj_point);
+
+				/*set new adjust!*/
+				gadjust->adj_delay = emmc_adj->adj_point;
+				gadjust->adj_enable = 1;
+				writel(adjust, host->base + SD_EMMC_ADJUST);
+				break;
+			case RX_PHASE_DELAY_TUNING_MODE:
+				vclk = readl(host->base + SD_EMMC_CLOCK);
+				emmc_rxclk->rxclk_point++;
+				emmc_rxclk->rxclk_point %= 25;
+				if (emmc_rxclk->rxclk_point < 10) {
+					emmc_rxclk->rxclk_rx_phase = 0;
+					emmc_rxclk->rxclk_rx_delay
+						= emmc_rxclk->rxclk_point;
+				} else {
+					emmc_rxclk->rxclk_rx_phase = 2;
+					emmc_rxclk->rxclk_rx_delay
+					= emmc_rxclk->rxclk_point - 10;
+				}
+				pr_err("emmc, %d retry, rx_phase %d -> %d, rx_delay %d -> %d\n",
+						mrq->cmd->retries,
+						clkc->rx_phase,
+						emmc_rxclk->rxclk_rx_phase,
+						clkc->rx_delay,
+						emmc_rxclk->rxclk_rx_delay);
+				clkc->rx_phase = emmc_rxclk->rxclk_rx_phase;
+				clkc->rx_delay = emmc_rxclk->rxclk_rx_delay;
+				writel(vclk, host->base + SD_EMMC_CLOCK);
+				pdata->clkc = vclk;
+				break;
+			case NONE_TUNING:
+			default:
+				vclk = readl(host->base + SD_EMMC_CLOCK);
+				rx_phase = clkc->rx_phase;
+				rx_phase++;
+				rx_phase %= 4;
+				pr_err("emmc: retry, rx_phase %d -> %d\n",
+						clkc->rx_phase, rx_phase);
+				clkc->rx_phase = rx_phase;
+				writel(vclk, host->base + SD_EMMC_CLOCK);
+				pdata->clkc = vclk;
+				break;
+			}
+		}
+		/* last retry effort! */
+		if ((aml_card_type_mmc(pdata) || aml_card_type_non_sdio(pdata))
+			&& host->error_flag && (mrq->cmd->retries == 0)) {
+			host->error_flag |= (1<<30);
+			sd_emmc_err("Command retried failed line:%d, cmd:%d\n",
+				__LINE__, mrq->cmd->opcode);
+		}
+		/* retry need send a stop 2 emmc... */
+		/* do not send stop for sdio wifi case */
+		if (host->mrq->stop
+			&& (aml_card_type_mmc(pdata)
+				|| aml_card_type_non_sdio(pdata))
+			&& pdata->is_in
+			&& (host->mrq->cmd->opcode != MMC_SEND_TUNING_BLOCK)
+			&& (host->mrq->cmd->opcode !=
+					MMC_SEND_TUNING_BLOCK_HS200))
+			aml_sd_emmc_send_stop(host);
+		else
+			meson_mmc_request_done(host->mmc, host->mrq);
+		break;
+
+	default:
+		sd_emmc_err("BUG %s: xfer_step=%d, host->status=%d\n",
+			mmc_hostname(host->mmc),  xfer_step, status);
+/*		aml_sd_emmc_print_err(host);*/
+	}
+
+	return IRQ_HANDLED;
+}
+
+static void aml_sd_emmc_enable_sdio_irq(struct mmc_host *mmc, int enable)
+{
+	struct amlsd_host *host = mmc_priv(mmc);
+	struct amlsd_platform *pdata = host->pdata;
+	unsigned long flags;
+	/* u32 vstat = 0; */
+	u32 vclkc = 0;
+	struct sd_emmc_clock *pclock = (struct sd_emmc_clock *)&vclkc;
+	u32 vconf = 0;
+	struct sd_emmc_config *pconf = (struct sd_emmc_config *)&vconf;
+	u32 virqc = 0;
+	struct sd_emmc_irq_en *irqc = (struct sd_emmc_irq_en *)&virqc;
+
+	host->sdio_irqen = enable;
+	spin_lock_irqsave(&host->mrq_lock, flags);
+	vclkc = readl(host->base + SD_EMMC_CLOCK);
+	vconf = readl(host->base + SD_EMMC_CFG);
+	virqc = readl(host->base + SD_EMMC_IRQ_EN);
+
+	pclock->irq_sdio_sleep = 1;
+	pclock->irq_sdio_sleep_ds = 0;
+	pconf->irq_ds = 0;
+
+	/* vstat = sd_emmc_regs->gstatus&SD_EMMC_IRQ_ALL; */
+	if (enable)
+		irqc->irq_sdio = 1;
+	else
+		irqc->irq_sdio = 0;
+
+	writel(virqc, host->base + SD_EMMC_IRQ_EN);
+	writel(vclkc, host->base + SD_EMMC_CLOCK);
+	writel(vconf, host->base + SD_EMMC_CFG);
+	pdata->clkc = vclkc;
+
+	spin_unlock_irqrestore(&host->mrq_lock, flags);
+
+	/* check if irq already occurred */
+	aml_sd_emmc_check_sdio_irq(host);
+}
+
+/*get readonly: 0 for rw, 1 for ro*/
+static int aml_sd_emmc_get_ro(struct mmc_host *mmc)
+{
+	struct amlsd_host *host = mmc_priv(mmc);
+	struct amlsd_platform *pdata = host->pdata;
+	u32 ro = 0;
+
+	if (pdata->ro)
+		ro = pdata->ro(pdata);
+	return ro;
+}
+
+/*
+ * NOTE: we only need this until the GPIO/pinctrl driver can handle
+ * interrupts.  For now, the MMC core will use this for polling.
+ */
+static int meson_mmc_get_cd(struct mmc_host *mmc)
+{
+	struct amlsd_host *host = mmc_priv(mmc);
+	struct amlsd_platform *pdata = host->pdata;
+
+	return pdata->is_in;
+}
+
+int aml_signal_voltage_switch(struct mmc_host *mmc, struct mmc_ios *ios)
+{
+	return aml_sd_voltage_switch(mmc, ios->signal_voltage);
+}
+
+/* Check if the card is pulling dat[0:3] low */
+static int aml_sd_emmc_card_busy(struct mmc_host *mmc)
+{
+	struct amlsd_host *host = mmc_priv(mmc);
+	struct amlsd_platform *pdata = host->pdata;
+	unsigned int status = 0;
+	/* only check data3_0 gpio level?? */
+	u32 vstat;
+	struct sd_emmc_status *ista = (struct sd_emmc_status *)&vstat;
+	u32 vconf;
+	struct sd_emmc_config *pconf = (struct sd_emmc_config *)&vconf;
+
+	vstat = readl(host->base + SD_EMMC_STATUS);
+	status = ista->dat_i & 0xf;
+
+	/*must open auto_clk after sd/sdio switch volatile base on sd spec.*/
+	if ((!aml_card_type_mmc(pdata))
+			&& (host->sd_sdio_switch_volat_done)) {
+		vconf = readl(host->base + SD_EMMC_CFG);
+		pconf->auto_clk = 1;
+		writel(vconf, host->base + SD_EMMC_CFG);
+	}
+	return !status;
+}
+
+/*this function tells wifi is using sd(sdiob) or sdio(sdioa)*/
+const char *get_wifi_inf(void)
+{
+	if (sdio_host != NULL)
+		return mmc_hostname(sdio_host);
+	else
+		return "sdio";
+
+}
+EXPORT_SYMBOL(get_wifi_inf);
+
+static const struct mmc_host_ops meson_mmc_ops = {
+	.request = meson_mmc_request,
+	.set_ios = meson_mmc_set_ios,
+	.enable_sdio_irq = aml_sd_emmc_enable_sdio_irq,
+	.get_cd = meson_mmc_get_cd,
+	.get_ro = aml_sd_emmc_get_ro,
+	.start_signal_voltage_switch = aml_signal_voltage_switch,
+	.card_busy = aml_sd_emmc_card_busy,
+	.execute_tuning = aml_mmc_execute_tuning,
+	.hw_reset = aml_emmc_hw_reset,
+};
+
+static void aml_reg_print(struct amlsd_host *host)
+{
+	struct amlsd_platform *pdata = host->pdata;
+
+	pr_info("%s reg val:\n", pdata->pinname);
+	pr_info("SD_EMMC_CLOCK = 0x%x\n", readl(host->base + SD_EMMC_CLOCK));
+	pr_info("SD_EMMC_CFG = 0x%x\n", readl(host->base + SD_EMMC_CFG));
+	pr_info("SD_EMMC_STATUS = 0x%x\n", readl(host->base + SD_EMMC_STATUS));
+	pr_info("SD_EMMC_IRQ_EN = 0x%x\n", readl(host->base + SD_EMMC_IRQ_EN));
+};
+
+static int meson_mmc_probe(struct platform_device *pdev)
+{
+	struct resource *res_mem;
+	struct amlsd_host *host;
+	struct amlsd_platform *pdata = NULL;
+	struct mmc_host *mmc;
+	int ret;
+
+	aml_mmc_ver_msg_show();
+
+	pdata = kzalloc(sizeof(struct amlsd_platform), GFP_KERNEL);
+	if (!pdata)
+		ret = -ENOMEM;
+
+	mmc = mmc_alloc_host(sizeof(struct amlsd_host), &pdev->dev);
+	if (!mmc)
+		return -ENOMEM;
+
+	host = mmc_priv(mmc);
+	host->mmc = mmc;
+	host->pdev = pdev;
+	host->dev = &pdev->dev;
+	dev_set_drvdata(&pdev->dev, host);
+
+	host->pinmux_base = ioremap(0xc8834400, 0x200);
+	res_mem = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	host->base = devm_ioremap_resource(&pdev->dev, res_mem);
+	if (IS_ERR(host->base)) {
+		ret = PTR_ERR(host->base);
+		goto free_host;
+	}
+
+	host->irq = platform_get_irq(pdev, 0);
+	if (host->irq == 0) {
+		dev_err(&pdev->dev, "failed to get interrupt resource.\n");
+		ret = -EINVAL;
+		goto free_host;
+	}
+
+	ret = devm_request_threaded_irq(&pdev->dev, host->irq,
+					meson_mmc_irq, meson_mmc_irq_thread,
+					IRQF_SHARED, "meson-aml-mmc", host);
+	if (ret)
+		goto free_host;
+
+	/* data desc buffer */
+	host->desc_buf =
+		dma_alloc_coherent(host->dev,
+				SD_EMMC_MAX_DESC_MUN
+				* (sizeof(struct sd_emmc_desc_info)),
+				&host->desc_dma_addr, GFP_KERNEL);
+	if (host->desc_buf == NULL) {
+		dev_err(host->dev, "Unable to map allocate DMA desc buffer.\n");
+		ret = -ENOMEM;
+		goto free_host;
+	}
+
+	/* data bounce buffer */
+	host->bn_buf =
+		dma_alloc_coherent(host->dev, SD_EMMC_BOUNCE_REQ_SIZE,
+				   &host->bn_dma_buf, GFP_KERNEL);
+	if (host->bn_buf == NULL) {
+		dev_err(host->dev, "Unable to map allocate DMA bounce buffer.\n");
+		ret = -ENOMEM;
+		goto free_host;
+	}
+
+	host->pdata = pdata;
+	spin_lock_init(&host->mrq_lock);
+	mutex_init(&host->pinmux_lock);
+	host->xfer_step = XFER_INIT;
+	host->init_flag = 1;
+	host->is_gated = false;
+
+	ret = meson_mmc_clk_init(host);
+	if (ret)
+		goto free_host;
+
+	ret = mmc_of_parse(mmc);
+	if (ret) {
+		dev_warn(&pdev->dev, "error parsing DT: %d\n", ret);
+		goto free_host;
+	}
+
+	if (amlsd_get_platform_data(pdev, pdata, mmc, 0))
+		mmc_free_host(mmc);
+
+	if (aml_card_type_mmc(pdata))
+		/**set emmc tx_phase regs here base on dts**/
+		aml_sd_emmc_tx_phase_set(host);
+
+	dev_set_name(&mmc->class_dev, "%s", pdata->pinname);
+
+	if (pdata->caps & MMC_PM_KEEP_POWER)
+		mmc->pm_caps |= MMC_PM_KEEP_POWER;
+	host->init_flag = 1;
+	host->version = AML_MMC_VERSION;
+	host->pinctrl = NULL;
+	host->status = HOST_INVALID;
+	host->is_tunning = 0;
+	mmc->ios.clock = 400000;
+	mmc->ios.bus_width = MMC_BUS_WIDTH_1;
+	mmc->max_blk_count = 4095;
+	mmc->max_blk_size = 4095;
+	mmc->max_req_size = pdata->max_req_size;
+	mmc->max_seg_size = mmc->max_req_size;
+	mmc->max_segs = 1024;
+	mmc->ocr_avail = pdata->ocr_avail;
+	mmc->caps |= pdata->caps;
+	mmc->caps2 |= pdata->caps2;
+	mmc->f_min = pdata->f_min;
+	mmc->f_max = pdata->f_max;
+	mmc->max_current_180 = 300; /* 300 mA in 1.8V */
+	mmc->max_current_330 = 300; /* 300 mA in 3.3V */
+
+	if (mmc->caps & MMC_CAP_NONREMOVABLE)
+		pdata->is_in = 1;
+
+	if (aml_card_type_sdio(pdata)) { /* if sdio_wifi */
+		/*	mmc->host_rescan_disable = true;*/
+		/* do NOT run mmc_rescan for the first time */
+		mmc->rescan_entered = 1;
+	} else {
+	/*	mmc->host_rescan_disable = false;*/
+		mmc->rescan_entered = 0;
+	}
+
+	if (aml_card_type_mmc(pdata)) {
+		/* Poll down BOOT_15 in case hardward not pull down */
+		u32 boot_poll_en, boot_poll_down;
+
+		boot_poll_down = readl(host->pinmux_base + BOOT_POLL_UP_DOWN);
+		boot_poll_down &= (~(1 << 15));
+		boot_poll_en = readl(host->pinmux_base + BOOT_POLL_UP_DOWN_EN);
+		boot_poll_en |= (1 << 15);
+		writel(boot_poll_down, host->pinmux_base + BOOT_POLL_UP_DOWN);
+		writel(boot_poll_en, host->pinmux_base + BOOT_POLL_UP_DOWN_EN);
+	}
+
+	if (pdata->port_init)
+		pdata->port_init(pdata);
+	mmc->ops = &meson_mmc_ops;
+	aml_reg_print(host);
+	ret = mmc_add_host(mmc);
+	if (ret) { /* error */
+		sd_emmc_err("Failed to add mmc host.\n");
+		goto free_host;
+	}
+	if (aml_card_type_sdio(pdata)) /* if sdio_wifi */
+		sdio_host = mmc;
+
+	/*Register card detect irq : plug in & unplug*/
+	if (aml_card_type_non_sdio(pdata)) {
+		pdata->irq_init(pdata);
+		mutex_init(&pdata->in_out_lock);
+		ret = devm_request_threaded_irq(&pdev->dev, pdata->irq_cd,
+				aml_sd_irq_cd, aml_irq_cd_thread,
+				IRQF_TRIGGER_RISING
+				| IRQF_TRIGGER_FALLING
+				| IRQF_ONESHOT,
+				"amlsd_cd", host);
+		if (ret) {
+			sd_emmc_err("Failed to request SD IN detect\n");
+			goto free_host;
+		}
+	}
+	pr_info("%s() : success!\n", __func__);
+	return 0;
+
+free_host:
+	mmc_free_host(mmc);
+	kfree(pdata);
+	pr_err("%s() fail!\n", __func__);
+	return ret;
+}
+
+static int meson_mmc_remove(struct platform_device *pdev)
+{
+	struct amlsd_host *host = dev_get_drvdata(&pdev->dev);
+	struct amlsd_platform *pdata = host->pdata;
+
+	if (WARN_ON(!host))
+		return 0;
+
+	if (host->bn_buf)
+		dma_free_coherent(host->dev, SD_EMMC_BOUNCE_REQ_SIZE,
+				host->bn_buf, host->bn_dma_buf);
+
+	devm_free_irq(&pdev->dev, host->irq, host);
+	iounmap(host->pinmux_base);
+
+	if (host->cfg_div_clk)
+		clk_disable_unprepare(host->cfg_div_clk);
+	if (host->core_clk)
+		clk_disable_unprepare(host->core_clk);
+
+	mmc_free_host(host->mmc);
+	kfree(pdata);
+	return 0;
+}
+
+static const struct of_device_id meson_mmc_of_match[] = {
+	{
+		.compatible = "amlogic, meson-aml-mmc",
+	},
+	{}
+};
+MODULE_DEVICE_TABLE(of, meson_mmc_of_match);
+
+static struct platform_driver meson_mmc_driver = {
+	.probe		= meson_mmc_probe,
+	.remove		= meson_mmc_remove,
+	.driver		= {
+		.name = "meson-aml-mmc",
+		.owner = THIS_MODULE,
+		.of_match_table = of_match_ptr(meson_mmc_of_match),
+	},
+};
+
+static int __init meson_mmc_init(void)
+{
+	return platform_driver_register(&meson_mmc_driver);
+}
+
+static void __exit meson_mmc_cleanup(void)
+{
+	platform_driver_unregister(&meson_mmc_driver);
+}
+
+module_init(meson_mmc_init);
+module_exit(meson_mmc_cleanup);
+
+MODULE_DESCRIPTION("Amlogic S912/GXM SD/eMMC driver");
+MODULE_AUTHOR("Kevin Hilman <khilman@baylibre.com>");
+MODULE_LICENSE("GPL");
+
diff --git a/drivers/amlogic/mmc/aml_sdhc_m8.c b/drivers/amlogic/mmc/aml_sdhc_m8.c
new file mode 100644
index 0000000..36c1077
--- /dev/null
+++ b/drivers/amlogic/mmc/aml_sdhc_m8.c
@@ -0,0 +1,2477 @@
+/*
+ * drivers/amlogic/mmc/aml_sdhc_m8.c
+ *
+ * Copyright (C) 2017 Amlogic, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/debugfs.h>
+#include <linux/interrupt.h>
+#include <linux/delay.h>
+#include <linux/dma-mapping.h>
+#include <linux/platform_device.h>
+#include <linux/timer.h>
+#include <linux/clk.h>
+#include <linux/clk-provider.h>
+#include <linux/mmc/host.h>
+#include <linux/mmc/card.h>
+#include <linux/io.h>
+#include <linux/of_irq.h>
+#include <linux/mmc/mmc.h>
+#include <linux/mmc/sdio.h>
+#include <linux/highmem.h>
+#include <linux/slab.h>
+#include <linux/dma-mapping.h>
+#include <linux/amlogic/iomap.h>
+#include <linux/amlogic/cpu_version.h>
+#include <linux/irq.h>
+#include <linux/amlogic/sd.h>
+#include <linux/reset.h>
+#include <linux/amlogic/amlsd.h>
+#include <linux/amlogic/gpio-amlogic.h>
+
+/* #define DMC_URGENT_PERIPH */
+unsigned int rx_clk_phase_set = 1;
+unsigned int sd_clk_phase_set = 1;
+unsigned int rx_endian = 7;
+unsigned int tx_endian = 7;
+unsigned int val1;
+unsigned int cmd25_cnt;
+unsigned int fifo_empty_cnt;
+unsigned int fifo_full_cnt;
+unsigned int timeout_cnt;
+static unsigned int sdhc_error_flag;
+static unsigned int sdhc_debug_flag;
+static int sdhc_err_bak;
+static struct semaphore sdhc_sema;
+
+static void aml_sdhc_send_stop(struct amlsd_host *host);
+static void aml_sdhc_emmc_clock_switch_on(struct amlsd_platform *pdata);
+static void aml_sdhc_clk_switch_off(struct amlsd_host *host);
+static void aml_sdhc_clk_switch(struct amlsd_platform *pdata,
+		int clk_div, int clk_src_sel);
+static int aml_sdhc_status(struct amlsd_host *host);
+
+static void  __attribute__((unused))sdhc_debug_status(struct amlsd_host *host)
+{
+	switch (sdhc_debug_flag) {
+	case 1:
+		host->status = HOST_TX_FIFO_EMPTY;
+		sdhc_err("Force host->status:%d here\n", host->status);
+		break;
+	case 2:
+		host->status = HOST_RX_FIFO_FULL;
+		sdhc_err("Force host->status:%d here\n", host->status);
+		break;
+	case 3:
+		host->status = HOST_RSP_CRC_ERR;
+		sdhc_err("Force host->status:%d here\n", host->status);
+		break;
+	case 4:
+		host->status = HOST_DAT_CRC_ERR;
+		sdhc_err("Force host->status:%d here\n", host->status);
+		break;
+	case 5:
+		host->status = HOST_DAT_TIMEOUT_ERR;
+		sdhc_err("Force host->status:%d here\n", host->status);
+		break;
+	case 6:
+		host->status = HOST_RSP_TIMEOUT_ERR;
+		sdhc_err("Force host->status:%d here\n", host->status);
+		break;
+	default:
+		break;
+	}
+
+	/* only enable once for debug */
+	sdhc_debug_flag = 0;
+}
+
+void aml_debug_print_buf(char *buf, int size)
+{
+	int i;
+
+	if (size > 512)
+		size = 512;
+
+	pr_info("%8s : ", "Address");
+	for (i = 0; i < 16; i++)
+		pr_info("%02x ", i);
+
+	pr_info("\n");
+	pr_info("==========================================================\n");
+
+	for (i = 0; i < size; i++) {
+		if ((i % 16) == 0)
+			pr_info("%08x : ", i);
+
+		pr_info("%02x ", buf[i]);
+
+		if ((i % 16) == 15)
+			pr_info("\n");
+	}
+	pr_info("\n");
+}
+
+int aml_buf_verify(int *buf, int blocks, int lba)
+{
+	int block_size;
+	int i, j;
+	int lba_bak = lba;
+
+	sdhc_err("Enter\n");
+	for (i = 0; i < blocks; i++) {
+		for (j = 0; j < 128; j++) {
+			if (buf[j] != (lba*512 + j)) {
+				sdhc_err(
+						"buf error, lba_bak=%#x,lba=%#x,offset=%#x,blocks=%d\n",
+						lba_bak, lba, j, blocks);
+
+				sdhc_err("buf[j]=%#x, target=%#x\n",
+						buf[j], (lba*512 + j));
+
+				block_size = (lba - lba_bak)*512;
+				aml_debug_print_buf((char *)(buf+block_size),
+						512);
+
+				return -1;
+			}
+		}
+		lba++;
+		buf += 128;
+	}
+
+	return 0;
+}
+
+static int aml_sdhc_execute_tuning_(struct mmc_host *mmc, u32 opcode,
+		struct aml_tuning_data *tuning_data)
+{
+	struct amlsd_platform *pdata = mmc_priv(mmc);
+	struct amlsd_host *host = pdata->host;
+	struct sdhc_clkc *clkc = (struct sdhc_clkc *)&(pdata->clkc);
+	u32 vclk2, vclk2_bak;
+	struct sdhc_clk2 *clk2 = (struct sdhc_clk2 *)&vclk2;
+	const u8 *blk_pattern = tuning_data->blk_pattern;
+	u8 *blk_test;
+	unsigned int blksz = tuning_data->blksz;
+	int ret = 0;
+	unsigned long flags;
+
+	int n, nmatch, ntries = 10;
+	int rx_phase = 0;
+	int wrap_win_start = -1, wrap_win_size = 0;
+	int best_win_start = -1, best_win_size = -1;
+	int curr_win_start = -1, curr_win_size = 0;
+
+	u8 rx_tuning_result[20] = { 0 };
+
+	spin_lock_irqsave(&host->mrq_lock, flags);
+	pdata->need_retuning = false;
+	spin_unlock_irqrestore(&host->mrq_lock, flags);
+
+	vclk2_bak = readl(host->base + SDHC_CLK2);
+
+	blk_test = kmalloc(blksz, GFP_KERNEL);
+	if (!blk_test)
+		return -ENOMEM;
+
+	for (rx_phase = 0; rx_phase <= clkc->clk_div; rx_phase++) {
+		/* Perform tuning ntries times per clk_div increment */
+		for (n = 0, nmatch = 0; n < ntries; n++) {
+			struct mmc_request mrq = {NULL};
+			struct mmc_command cmd = {0};
+			struct mmc_command stop = {0};
+			struct mmc_data data = {0};
+			struct scatterlist sg;
+
+			cmd.opcode = opcode;
+			cmd.arg = 0;
+			cmd.flags = MMC_RSP_R1 | MMC_CMD_ADTC;
+
+			stop.opcode = MMC_STOP_TRANSMISSION;
+			stop.arg = 0;
+			stop.flags = MMC_RSP_R1B | MMC_CMD_AC;
+
+			data.blksz = blksz;
+			data.blocks = 1;
+			data.flags = MMC_DATA_READ;
+			data.sg = &sg;
+			data.sg_len = 1;
+
+			memset(blk_test, 0, blksz);
+			sg_init_one(&sg, blk_test, blksz);
+
+			mrq.cmd = &cmd;
+			mrq.stop = &stop;
+			mrq.data = &data;
+			host->mrq = &mrq;
+
+			vclk2 = readl(host->base + SDHC_CLK2);
+			clk2->rx_clk_phase = rx_phase;
+			writel(vclk2, host->base + SDHC_CLK2);
+			pdata->clk2 = vclk2;
+
+			mmc_wait_for_req(mmc, &mrq);
+
+			if (!cmd.error && !data.error) {
+				if (!memcmp(blk_pattern, blk_test, blksz))
+					nmatch++;
+				else {
+					sdhc_dbg(AMLSD_DBG_TUNING,
+						"Tuning pattern mismatch: rx_phase=%d nmatch=%d\n",
+						rx_phase, nmatch);
+				}
+			} else {
+				sdhc_dbg(AMLSD_DBG_TUNING, "Tuning transfer error:");
+				sdhc_dbg(AMLSD_DBG_TUNING,
+					"rx_phase=%d nmatch=%d cmd.error=%d data.error=%d\n",
+					rx_phase, nmatch,
+					cmd.error, data.error);
+			}
+		}
+
+		if (rx_phase < sizeof(rx_tuning_result)
+				/sizeof(rx_tuning_result[0]))
+			rx_tuning_result[rx_phase] = nmatch;
+
+		if (nmatch == ntries) {
+			if (rx_phase == 0)
+				wrap_win_start = rx_phase;
+
+			if (wrap_win_start >= 0)
+				wrap_win_size++;
+
+			if (curr_win_start < 0)
+				curr_win_start = rx_phase;
+
+			curr_win_size++;
+		} else {
+			if (curr_win_start >= 0) {
+				if (best_win_start < 0) {
+					best_win_start = curr_win_start;
+					best_win_size = curr_win_size;
+				} else {
+					if (best_win_size < curr_win_size) {
+						best_win_start = curr_win_start;
+						best_win_size = curr_win_size;
+					}
+				}
+
+				wrap_win_start = -1;
+				curr_win_start = -1;
+				curr_win_size = 0;
+			}
+		}
+	}
+	sdhc_dbg(AMLSD_DBG_TUNING, "RX Tuning Result\n");
+	for (n = 0; n <= clkc->clk_div; n++) {
+		if (n < ARRAY_SIZE(rx_tuning_result))
+			sdhc_dbg(AMLSD_DBG_TUNING,
+					"RX[%d]=%d\n", n, rx_tuning_result[n]);
+	}
+
+	sdhc_dbg(AMLSD_DBG_TUNING, "curr_win_start=%d\n", curr_win_start);
+	sdhc_dbg(AMLSD_DBG_TUNING, "curr_win_size=%d\n", curr_win_size);
+	sdhc_dbg(AMLSD_DBG_TUNING, "best_win_start=%d\n", best_win_start);
+	sdhc_dbg(AMLSD_DBG_TUNING, "best_win_size=%d\n", best_win_size);
+	sdhc_dbg(AMLSD_DBG_TUNING, "wrap_win_start=%d\n", wrap_win_start);
+	sdhc_dbg(AMLSD_DBG_TUNING, "wrap_win_size=%d\n", wrap_win_size);
+	if (curr_win_start >= 0) {
+		if (best_win_start < 0) {
+			best_win_start = curr_win_start;
+			best_win_size = curr_win_size;
+		} else if (wrap_win_size > 0) {
+			/* Wrap around case */
+			if (curr_win_size + wrap_win_size > best_win_size) {
+				best_win_start = curr_win_start;
+				best_win_size = curr_win_size + wrap_win_size;
+			}
+		} else if (best_win_size < curr_win_size) {
+			best_win_start = curr_win_start;
+			best_win_size = curr_win_size;
+		}
+
+		curr_win_start = -1;
+		curr_win_size = 0;
+	}
+
+	if (best_win_start < 0) {
+		sdhc_err("Tuning failed to find a valid window, using default rx phase\n");
+		ret = -EIO;
+		writel(vclk2_bak, host->base + SDHC_CLK2);
+		pdata->clk2 = vclk2_bak;
+		/* rx_phase = rx_clk_phase_set; */
+	} else {
+		pdata->is_tuned = true;
+
+		rx_phase = best_win_start + (best_win_size / 2);
+
+		if (rx_phase > clkc->clk_div)
+			rx_phase -= (clkc->clk_div + 1);
+
+		vclk2 = readl(host->base + SDHC_CLK2);
+		clk2->rx_clk_phase = rx_phase;
+		writel(vclk2, host->base + SDHC_CLK2);
+		pdata->clk2 = vclk2;
+		pdata->tune_phase = vclk2;
+
+		sdhc_dbg(AMLSD_DBG_TUNING,
+				"Tuning result: rx_phase=%d\n", rx_phase);
+	}
+	sdhc_dbg(AMLSD_DBG_TUNING, "Final Result\n");
+	sdhc_dbg(AMLSD_DBG_TUNING, "curr_win_start=%d\n", curr_win_start);
+	sdhc_dbg(AMLSD_DBG_TUNING, "curr_win_size=%d\n", curr_win_size);
+	sdhc_dbg(AMLSD_DBG_TUNING, "best_win_start=%d\n", best_win_start);
+	sdhc_dbg(AMLSD_DBG_TUNING, "best_win_size=%d\n", best_win_size);
+	sdhc_dbg(AMLSD_DBG_TUNING, "wrap_win_start=%d\n", wrap_win_start);
+	sdhc_dbg(AMLSD_DBG_TUNING, "wrap_win_size=%d\n", wrap_win_size);
+	kfree(blk_test);
+
+	/* do not dynamical tuning for eMMC */
+	if ((pdata->is_in) && !aml_card_type_mmc(pdata))
+		schedule_delayed_work(&pdata->retuning, 15*HZ);
+	return ret;
+}
+
+static int aml_sdhc_execute_tuning(struct mmc_host *mmc, u32 opcode)
+{
+	struct aml_tuning_data tuning_data;
+	int err = 0;
+
+	if (opcode == MMC_SEND_TUNING_BLOCK_HS200) {
+		if (mmc->ios.bus_width == MMC_BUS_WIDTH_8) {
+			tuning_data.blk_pattern = tuning_blk_pattern_8bit;
+			tuning_data.blksz = sizeof(tuning_blk_pattern_8bit);
+		} else if (mmc->ios.bus_width == MMC_BUS_WIDTH_4) {
+			tuning_data.blk_pattern = tuning_blk_pattern_4bit;
+			tuning_data.blksz = sizeof(tuning_blk_pattern_4bit);
+		} else
+			return -EINVAL;
+	} else if (opcode == MMC_SEND_TUNING_BLOCK) {
+		tuning_data.blk_pattern = tuning_blk_pattern_4bit;
+		tuning_data.blksz = sizeof(tuning_blk_pattern_4bit);
+	} else {
+		sdhc_err("Undefined command(%d) for tuning\n", opcode);
+		return -EINVAL;
+	}
+
+	err = aml_sdhc_execute_tuning_(mmc, opcode, &tuning_data);
+
+	return err;
+}
+
+/*soft reset after errors*/
+void aml_sdhc_host_reset(struct amlsd_host *host)
+{
+	writel(SDHC_SRST_ALL, host->base+SDHC_SRST);
+	udelay(5);
+
+	writel(0, host->base+SDHC_SRST);
+	udelay(10);
+}
+
+static int aml_sdhc_clktree_init(struct amlsd_host *host)
+{
+	int ret = 0;
+
+	host->core_clk = devm_clk_get(host->dev, "core");
+	if (IS_ERR(host->core_clk)) {
+		ret = PTR_ERR(host->core_clk);
+		pr_err("devm_clk_get core_clk fail %d\n", ret);
+		return ret;
+	}
+	ret = clk_prepare_enable(host->core_clk);
+	if (ret) {
+		pr_err("clk_prepare_enable core_clk fail %d\n", ret);
+		return ret;
+	}
+
+	host->div3_clk = devm_clk_get(host->dev, "div3");
+	if (IS_ERR(host->div3_clk)) {
+		ret = PTR_ERR(host->div3_clk);
+		pr_err("devm_clk_get div3_clk fail %d\n", ret);
+		return ret;
+	}
+	ret = clk_prepare_enable(host->div3_clk);
+	if (ret) {
+		pr_err("clk_prepare_enable div3_clk fail %d\n", ret);
+		return ret;
+	}
+
+	pr_info("aml_sdhc_clktree_init ok\n");
+	return 0;
+}
+
+/*setup reg initial value*/
+static void aml_sdhc_reg_init(struct amlsd_host *host)
+{
+	struct sdhc_ctrl ctrl = {0};
+	/* struct sdhc_pdma pdma = {0}; */
+	u32 vpdma = readl(host->base+SDHC_PDMA);
+	struct sdhc_pdma *pdma = (struct sdhc_pdma *)&vpdma;
+	struct sdhc_misc misc = {0};
+	u32 vclkc;
+	struct sdhc_clkc *clkc = (struct sdhc_clkc *)&vclkc;
+	/* struct sdhc_clk2 clk2 = {0}; */
+	u32 venhc;
+	struct sdhc_enhc *enhc = (struct sdhc_enhc *)&venhc;
+	/* u32 val; */
+#ifdef DMC_URGENT_PERIPH
+	u32 dmc_ctl;
+#endif
+	/*switch_mod_gate_by_type(MOD_SDHC, 1);*/
+	/* print_dbg("HHI_GCLK_MPEG0=%#x\n", READ_CBUS_REG(HHI_GCLK_MPEG0)); */
+
+	aml_sdhc_host_reset(host);
+
+#ifdef DMC_URGENT_PERIPH
+	dmc_ctl = readl(P_DMC_AM7_CHAN_CTRL);
+	dmc_ctl |= (1<<18);
+	writel(dmc_ctl, P_DMC_AM7_CHAN_CTRL);
+#endif
+
+	aml_sdhc_clktree_init(host);
+
+	ctrl.rx_period = 0xf;/* 0x08; // 0xf; */
+	ctrl.rx_timeout = 0x7f;/* 0x40; // 0x7f; */
+
+	/*R/W endian 7*/
+	ctrl.rx_endian = 0x7;
+	ctrl.tx_endian = 0x7;
+	writel(*(u32 *)&ctrl, host->base + SDHC_CTRL);
+
+	vclkc = readl(host->base+SDHC_CLKC);
+	clkc->mem_pwr_off = 0;
+	writel(vclkc, host->base+SDHC_CLKC);
+
+	pdma->dma_mode = 0;
+	pdma->dma_urgent = 1;
+	pdma->wr_burst = 7;/* 3; // means 4 */
+
+
+	pdma->txfifo_th = 49; /* means 49 */
+	pdma->rd_burst = 15; /* means 8 */
+	pdma->rxfifo_th = 7; /* means 8 */
+	writel(vpdma, host->base+SDHC_PDMA);
+
+	/*Send Stop Cmd automatically*/
+	misc.txstart_thres = 7; /* [29:31] = 7 */
+
+	misc.manual_stop = 0;
+	misc.wcrc_err_patt = 5;
+	misc.wcrc_ok_patt = 2;
+	writel(*(u32 *)&misc, host->base + SDHC_MISC);
+
+	venhc = readl(host->base+SDHC_ENHC);
+
+	enhc->reg.meson.rxfifo_th = 63;
+	enhc->reg.meson.dma_rd_resp = 0;
+	enhc->reg.meson.dma_wr_resp = 1;
+	enhc->reg.meson.sdio_irq_period = 12;
+	enhc->reg.meson.rx_timeout = 255;
+
+	writel(venhc, host->base + SDHC_ENHC);
+
+	/*Disable All Irq*/
+	writel(0, host->base + SDHC_ICTL);
+
+	/*Write 1 Clear all irq status*/
+	writel(SDHC_ISTA_W1C_ALL, host->base + SDHC_ISTA);
+}
+
+/*wait sdhc controller cmd send*/
+int aml_sdhc_wait_ready(struct amlsd_host *host, u32 timeout)
+{
+	u32 i, vstat = 0;
+	struct sdhc_stat *stat;
+	u32 esta;
+
+	for (i = 0; i < timeout; i++) {
+		vstat = readl(host->base + SDHC_STAT);
+		stat = (struct sdhc_stat *)&vstat;
+
+		esta = readl(host->base + SDHC_ESTA);
+		if (!stat->cmd_busy && (!((esta >> 11) & 7)))
+			/* if(!stat->cmd_busy) */
+			return 0;
+		udelay(1);
+	}
+
+	sdhc_err("SDHC_STAT=%#x, sdhc controller is busy.\n", vstat);
+	/* aml_sdhc_print_reg(host); */
+	aml_sdhc_host_reset(host);
+	/* WARN_ON(1); */
+	return -1;
+}
+
+/*
+ * read response from REG0_ARGU(136bit or 48bit)
+ */
+int aml_sdhc_read_response(struct mmc_host *mmc, struct mmc_command *cmd)
+{
+	u32 i = 0, j = 0;
+	struct amlsd_platform *pdata = mmc_priv(mmc);
+	struct amlsd_host *host = pdata->host;
+	u32 vpdma = readl(host->base+SDHC_PDMA);
+	struct sdhc_pdma *pdma = (struct sdhc_pdma *)&vpdma;
+	u32 *presp = (u32 *)cmd->resp;
+
+	pdma->dma_mode = 0;
+	if (cmd->flags & MMC_RSP_136) { /*136 bit*/
+		for (i = MMC_RSP_136_NUM, j = 0; i >= 1; i--, j++) {
+			pdma->pio_rdresp = i;
+			writel(vpdma, host->base+SDHC_PDMA);
+			presp[j] = readl(host->base+SDHC_ARGU);
+			sdhc_dbg(AMLSD_DBG_RESP,
+					"Cmd %d ,Resp[%d] 0x%x\n",
+					cmd->opcode, j, presp[j]);
+		}
+	} else { /*48 bit*/
+		pdma->pio_rdresp = i;
+		writel(vpdma, host->base+SDHC_PDMA);
+		presp[0] = readl(host->base+SDHC_ARGU);
+		sdhc_dbg(AMLSD_DBG_RESP,
+				"Cmd %d ,Resp 0x%x\n", cmd->opcode, presp[0]);
+	}
+	return 0;
+}
+
+/*clear fifo after transfer data*/
+void aml_sdhc_clear_fifo(struct amlsd_host *host)
+{
+	struct sdhc_srst srst;
+
+	srst.rxfifo = 1;
+	srst.txfifo = 1;
+	writel(*(u32 *)&srst, host->base+SDHC_SRST);
+	udelay(1);
+}
+
+/*enable irq bit in reg SDHC_ICTL*/
+void aml_sdhc_enable_imask(struct amlsd_host *host, u32 irq)
+{
+	u32 ictl = readl(host->base+SDHC_ICTL);
+
+	ictl |= irq;
+	writel(ictl, host->base+SDHC_ICTL);
+}
+
+/*disable irq bit in reg SDHC_ICTL*/
+void aml_sdhc_disable_imask(struct amlsd_host *host, u32 irq)
+{
+	u32 ictl = readl(host->base+SDHC_ICTL);
+
+	ictl &= ~irq;
+	writel(ictl, host->base+SDHC_ICTL);
+}
+
+void aml_sdhc_set_pdma(struct amlsd_platform *pdata, struct mmc_request *mrq)
+{
+	struct amlsd_host *host = pdata->host;
+	u32 vpdma = readl(host->base+SDHC_PDMA);
+	struct sdhc_pdma *pdma = (struct sdhc_pdma *)&vpdma;
+
+	WARN_ON(!mrq->data);
+	pdma->dma_mode = 1;
+
+	if (mrq->data->flags & MMC_DATA_WRITE) {
+		/* self-clear-fill, recommend to write before sd send
+		 * init sets rd_burst to 15
+		 */
+		pdma->rd_burst = 31;
+		pdma->txfifo_fill = 1;
+		writel(*(u32 *)pdma, host->base+SDHC_PDMA);
+		pdma->txfifo_fill = 1;
+	} else {
+		if (aml_card_type_sdio(pdata))
+			pdma->rxfifo_manual_flush = 0;
+		else
+			pdma->rxfifo_manual_flush = 1;
+	}
+
+	writel(*(u32 *)pdma, host->base+SDHC_PDMA);
+	if (mrq->data->flags & MMC_DATA_WRITE) {
+		/* init sets rd_burst to 15 */
+		/* change back to 15 after fill */
+		pdma->rd_burst = 15;
+		writel(*(u32 *)pdma, host->base+SDHC_PDMA);
+	}
+}
+
+/*copy buffer from data->sg to dma buffer, set dma addr to reg*/
+void aml_sdhc_prepare_dma(struct amlsd_host *host, struct mmc_request *mrq)
+{
+	struct mmc_data *data = mrq->data;
+
+	/* for temp write test */
+	if (data->flags & MMC_DATA_WRITE) {
+		aml_sg_copy_buffer(data->sg, data->sg_len,
+				host->bn_buf, data->blksz*data->blocks, 1);
+		sdhc_dbg(AMLSD_DBG_WR_DATA, "W Cmd %d, %x-%x-%x-%x\n",
+				mrq->cmd->opcode,
+				host->bn_buf[0], host->bn_buf[1],
+				host->bn_buf[2], host->bn_buf[3]);
+	}
+}
+
+/*
+ * set host->clkc_w for 8bit emmc write cmd as it would fail on TXFIFO EMPTY,
+ * we decrease the clock for write cmd, and set host->clkc for other cmd
+ */
+void aml_sdhc_set_clkc(struct amlsd_platform *pdata)
+{
+	struct amlsd_host *host = pdata->host;
+	u32 vclkc = readl(host->base + SDHC_CLKC);
+	u32 clk2 = readl(host->base+SDHC_CLK2);
+
+	if (!host->is_gated && (pdata->clkc == vclkc) && (pdata->clk2 == clk2))
+		return;
+
+	if (host->is_gated) { /* if clock is switch off, we need turn on */
+		struct sdhc_clkc *clkc = (struct sdhc_clkc *)&(pdata->clkc);
+
+		aml_sdhc_clk_switch(pdata, clkc->clk_div, clkc->clk_src_sel);
+	} else {
+		writel(pdata->clkc, host->base+SDHC_CLKC);
+	}
+
+	writel(pdata->clk2, host->base+SDHC_CLK2);
+}
+
+void aml_sdhc_start_cmd(struct amlsd_platform *pdata, struct mmc_request *mrq)
+{
+	struct amlsd_host *host = pdata->host;
+	struct sdhc_send send = {0};
+	struct sdhc_ictl ictl = {0};
+	u32 vctrl = readl(host->base + SDHC_CTRL);
+	struct sdhc_ctrl *ctrl = (struct sdhc_ctrl *)&vctrl;
+	u32 vstat;
+	struct sdhc_stat *stat = (struct sdhc_stat *)&vstat;
+	u32 vsrst;
+	struct sdhc_srst *srst = (struct sdhc_srst *)&vsrst;
+	u32 vmisc = readl(host->base + SDHC_MISC);
+	struct sdhc_misc *misc = (struct sdhc_misc *)&vmisc;
+	int i;
+	int loop_limit;
+	u32 vesta;
+
+	/*Set clock for each port, change clock before wait ready*/
+	aml_sdhc_set_clkc(pdata);
+
+	/*Set Irq Control*/
+	ictl.data_timeout = 1;
+	ictl.data_err_crc = 1;
+	ictl.rxfifo_full = 1;
+	ictl.txfifo_empty = 1;
+	ictl.resp_timeout = 1; /* try */
+	ictl.resp_err_crc = 1; /* try */
+
+	sdhc_dbg(AMLSD_DBG_REQ,
+			"%s %d %s: cmd:%d, flags:0x%x, args:0x%x\n",
+			__func__, __LINE__,
+			pdata->pinname, mrq->cmd->opcode,
+			mrq->cmd->flags, mrq->cmd->arg);
+	if (mrq->data) {
+		if (((mrq->cmd->opcode == SD_IO_RW_DIRECT) ||
+					(mrq->cmd->opcode == SD_IO_RW_EXTENDED))
+				&& (mrq->data->blocks > 1)) {
+			misc->manual_stop = 1;
+		} else{
+			if (mmc_host_cmd23(host->mmc))
+				misc->manual_stop = 1;
+			else
+				misc->manual_stop = 0;
+		}
+		writel(vmisc, host->base + SDHC_MISC);
+
+		vstat = readl(host->base + SDHC_STAT);
+		if (stat->txfifo_cnt || stat->rxfifo_cnt) {
+#ifdef CONFIG_MMC_AML_DEBUG
+			sdhc_err("cmd%d: txfifo_cnt:%d, rxfifo_cnt:%d\n",
+					mrq->cmd->opcode, stat->txfifo_cnt,
+					stat->rxfifo_cnt);
+#endif
+			if (aml_sdhc_wait_ready(host, STAT_POLL_TIMEOUT)) {
+				/*Wait command busy*/
+				sdhc_err("aml_sdhc_wait_ready error before start cmd fifo\n");
+			}
+			vsrst = readl(host->base + SDHC_SRST);
+			srst->rxfifo = 1;
+			srst->txfifo = 1;
+			srst->main_ctrl = 1;
+			writel(vsrst, host->base+SDHC_SRST);
+			udelay(5);
+			writel(vsrst, host->base+SDHC_SRST);
+		}
+		vstat = readl(host->base + SDHC_STAT);
+		if (stat->txfifo_cnt || stat->rxfifo_cnt) {
+			sdhc_err("FAIL to clear FIFO, cmd%d: txfifo_cnt:%d, rxfifo_cnt:%d\n",
+				mrq->cmd->opcode,
+				stat->txfifo_cnt, stat->rxfifo_cnt);
+		}
+
+		/*Command has data*/
+		send.cmd_has_data = 1;
+
+		/*Read/Write data direction*/
+		if (mrq->data->flags & MMC_DATA_WRITE)
+			send.data_dir = 1;
+
+		/*Set package size*/
+		if (mrq->data->blksz < 512)
+			ctrl->pack_len = mrq->data->blksz;
+		else
+			ctrl->pack_len = 0;
+
+		/*Set blocks in package*/
+		send.total_pack = mrq->data->blocks - 1;
+
+		/*
+		 * If command with no data, just wait response done
+		 * interrupt(int[0]), and if command with data transfer, just
+		 * wait dma done interrupt(int[11]), don't need care about
+		 * dat0 busy or not.
+		 */
+		if ((mrq->data->flags & MMC_DATA_WRITE)
+				|| aml_card_type_sdio(pdata))
+			ictl.dma_done = 1; /* for hardware automatical flush */
+		else
+			ictl.data_xfer_ok = 1; /* for software flush */
+	} else
+		ictl.resp_ok = 1;
+
+	if (mrq->cmd->opcode == MMC_STOP_TRANSMISSION)
+		send.data_stop = 1;
+
+	/*Set Bus Width*/
+	ctrl->dat_type = pdata->width;
+
+	if (mrq->cmd->flags & MMC_RSP_136)
+		send.resp_len = 1;
+	if (mrq->cmd->flags & MMC_RSP_PRESENT)
+		send.cmd_has_resp = 1;
+	if (!(mrq->cmd->flags & MMC_RSP_CRC) || mrq->cmd->flags & MMC_RSP_136)
+		send.resp_no_crc = 1;
+
+	/*Command Index*/
+	send.cmd_index = mrq->cmd->opcode;
+
+	writel(*(u32 *)&ictl, host->base+SDHC_ICTL);
+
+	/*Set irq status: write 1 clear*/
+	writel(SDHC_ISTA_W1C_ALL, host->base+SDHC_ISTA);
+
+	writel(mrq->cmd->arg, host->base+SDHC_ARGU);
+	writel(vctrl, host->base+SDHC_CTRL);
+	writel(host->bn_dma_buf, host->base+SDHC_ADDR);
+	if (aml_sdhc_wait_ready(host, STAT_POLL_TIMEOUT)) {
+		/*Wait command busy*/
+		sdhc_err("aml_sdhc_wait_ready error before start cmd\n");
+	}
+	if (mrq->data)
+		aml_sdhc_set_pdma(pdata, mrq);/*Start dma transfer*/
+
+#ifdef CONFIG_MMC_AML_DEBUG
+	if (0) {
+		memcpy_fromio(host->reg_buf, host->base, 0x3C);
+		host->reg_buf[SDHC_SEND/4] = *(u32 *)&send;
+	}
+#endif
+
+	loop_limit = 100;
+	for (i = 0; i < loop_limit; i++) {
+		vesta = readl(host->base + SDHC_ESTA);
+		if (vesta == 0) {
+#ifdef CONFIG_MMC_AML_DEBUG
+			sdhc_err("ok: %s: cmd%d, SDHC_ESTA=%#x, i=%d\n",
+					mmc_hostname(host->mmc),
+					mrq->cmd->opcode, vesta, i);
+#endif
+			break;
+		}
+		if (i > 50) {
+			sdhc_err("udelay\n");
+			udelay(1);
+		}
+	}
+	if (i >= loop_limit) {
+		sdhc_err("Warning: %s: cmd%d, SDHC_ESTA=%#x\n",
+				mmc_hostname(host->mmc),
+				mrq->cmd->opcode, vesta);
+	}
+
+	if (mrq->data && (mrq->data->flags & MMC_DATA_WRITE)) {
+		for (i = 0; i < loop_limit; i++) {
+			vstat = readl(host->base + SDHC_STAT);
+			if (stat->txfifo_cnt != 0) {
+#ifdef CONFIG_MMC_AML_DEBUG
+				sdhc_err("OK: %s: cmd%d, txfifo_cnt=%d, i=%d\n",
+						mmc_hostname(host->mmc),
+						mrq->cmd->opcode,
+						stat->txfifo_cnt, i);
+#endif
+				break;
+			}
+			udelay(1);
+		}
+		if (i >= loop_limit) {
+			sdhc_err("Warning: %s: cmd%d, txfifo_cnt=%d\n",
+					mmc_hostname(host->mmc),
+					mrq->cmd->opcode, stat->txfifo_cnt);
+		}
+	}
+	writel(*(u32 *)&send, host->base+SDHC_SEND); /*Command send*/
+}
+
+/*mmc_request_done & do nothing in xfer_post*/
+void aml_sdhc_request_done(struct mmc_host *mmc, struct mmc_request *mrq)
+{
+	struct amlsd_platform *pdata = mmc_priv(mmc);
+	struct amlsd_host *host = pdata->host;
+	unsigned long flags;
+
+	spin_lock_irqsave(&host->mrq_lock, flags);
+	host->xfer_step = XFER_FINISHED;
+	host->mrq = NULL;
+	host->status = HOST_INVALID;
+	spin_unlock_irqrestore(&host->mrq_lock, flags);
+
+#ifdef CONFIG_MMC_AML_DEBUG
+	host->req_cnt--;
+
+	aml_dbg_verify_pinmux(pdata);
+	aml_dbg_verify_pull_up(pdata);
+
+	if (0) {
+		sdhc_err("%s: cmd%d, start sdhc reg:\n",
+				mmc_hostname(host->mmc), mrq->cmd->opcode);
+		aml_sdhc_print_reg_(host->reg_buf);
+		sdhc_err("done reg:\n");
+		aml_sdhc_print_reg(host);
+	}
+#endif
+
+	if (pdata->xfer_post)
+		pdata->xfer_post(mmc);
+
+	aml_sdhc_disable_imask(host, SDHC_ICTL_ALL);
+	/*Set irq status: write 1 clear*/
+	writel(SDHC_ISTA_W1C_ALL, host->base+SDHC_ISTA);
+	if (aml_sdhc_wait_ready(host, STAT_POLL_TIMEOUT)) {
+		/*Wait command busy*/
+		sdhc_err("aml_sdhc_wait_ready request done\n");
+	}
+	aml_sdhc_clk_switch_off(host);
+	mmc_request_done(host->mmc, mrq);
+}
+
+char *msg_err[] = {
+	"invalid",		  /* 0 */
+	"rxfifo full",	  /* 1 */
+	"txfifo empty",	 /* 2 */
+	"rsp CRC",		  /* 3 */
+	"data CRC",		 /* 4 */
+	"rsp timeout",	  /* 5 */
+	"data timeout",	 /* 6 */
+};
+
+static void aml_sdhc_print_err(struct amlsd_host *host)
+{
+	char *msg, *msg_timer = "";
+	char *p;
+	u32 tmp_reg, xfer_step, xfer_step_prev, status;
+	int left_size;
+
+	int clk18_clk_rate = clk_get_rate(host->core_clk);
+	struct amlsd_platform *pdata = mmc_priv(host->mmc);
+	u32 vista = readl(host->base + SDHC_ISTA);
+	u32 vstat = readl(host->base + SDHC_STAT);
+	u32 vclkc = readl(host->base+SDHC_CLKC);
+	struct sdhc_clkc *clkc = (struct sdhc_clkc *)&vclkc;
+	u32 vctrl = readl(host->base + SDHC_CTRL);
+	struct sdhc_ctrl *ctrl = (struct sdhc_ctrl *)&vctrl;
+	u32 clk_rate;
+	unsigned long flags;
+
+	if ((host->mrq->cmd->opcode == MMC_SEND_TUNING_BLOCK)
+		|| (host->mrq->cmd->opcode == MMC_SEND_TUNING_BLOCK_HS200))
+		/* not print err msg for tuning cmd */
+		return;
+
+	spin_lock_irqsave(&host->mrq_lock, flags);
+	xfer_step = host->xfer_step;
+	xfer_step_prev = host->xfer_step_prev;
+	status = host->status;
+	spin_unlock_irqrestore(&host->mrq_lock, flags);
+
+	clk_rate = clk_get_rate(host->div3_clk); // for SDHC_CLOCK_SRC_FCLK_DIV3
+
+	p = host->msg_buf;
+	left_size = MESSAGE_BUF_SIZE;
+
+	if (((status < HOST_ERR_END) && (status > HOST_INVALID))
+		&& (status < ARRAY_SIZE(msg_err))) /* valid sdhc errors */
+		msg = msg_err[status];
+	else
+		msg = "status is invalid";
+
+	if (xfer_step == XFER_TIMER_TIMEOUT) { /* by aml_sdhc_timeout() */
+		if (((status < HOST_ERR_END) && (status > HOST_INVALID))
+				&& (status < ARRAY_SIZE(msg_err)))
+			/* valid sdhc errors */
+			msg_timer = "timer timeout WITH sdhc ";
+		else {
+			msg_timer = "timer timeout";
+			msg = "";
+		}
+	}
+
+	aml_snprint(&p, &left_size, "%s: %s%s error, port=%d, Cmd%d Arg %08x, ",
+			mmc_hostname(host->mmc),
+			msg_timer,
+			msg,
+			pdata->port,
+			host->mrq->cmd->opcode,
+			host->mrq->cmd->arg);
+	aml_snprint(&p, &left_size, "xfer_step=%d, status=%d, cmd25=%d, ",
+			xfer_step,
+			status,
+			cmd25_cnt);
+	aml_snprint(&p, &left_size, "fifo_empty=%d, fifo_full=%d, timeout=%d, ",
+			fifo_empty_cnt,
+			fifo_full_cnt,
+			timeout_cnt);
+
+	switch (status) {
+	case HOST_RX_FIFO_FULL:
+	case HOST_TX_FIFO_EMPTY:
+		aml_snprint(&p, &left_size, "clk81=%d, clock=%d, ",
+			clk18_clk_rate,
+			clk_rate/(clkc->clk_div+1));
+		break;
+	}
+
+	if (xfer_step == XFER_TIMER_TIMEOUT) {
+		/* by aml_sdhc_timeout() */
+		aml_snprint(&p, &left_size,
+				"xfer_step_prev=%d, ", xfer_step_prev);
+	}
+
+	if (host->mrq->data) {
+		int byte = host->mrq->data->blksz*host->mrq->data->blocks;
+
+		aml_snprint(&p, &left_size, "Xfer %d Bytes, ", byte);
+		if (byte > 512) /* multi-block mode */
+			aml_snprint(&p, &left_size, "SEND=%#x, ",
+					readl(host->base+SDHC_SEND));
+
+		if (pdata->width != ctrl->dat_type) {
+			/* error: bus width is different */
+			aml_snprint(&p, &left_size,
+					"pdata->width=%d, ctrl->dat_type=%d, ",
+					pdata->width, ctrl->dat_type);
+		}
+
+		if (pdata->clkc != vclkc) {
+			/* error: clock setting is different */
+			aml_snprint(&p, &left_size,
+					"pdata->clkc=%d, vclkc=%#x, ",
+					pdata->clkc, vclkc);
+		}
+	}
+	aml_snprint(&p, &left_size, "iSTA=%#x, STAT=%#x", vista, vstat);
+	sdhc_err("%s\n", host->msg_buf);
+
+	tmp_reg = aml_read_cbus(HHI_GCLK_MPEG0);
+	if (!(tmp_reg & 0x00004000)) {
+		sdhc_err(
+				"Error: SDHC is gated clock,HHI_GCLK_MPEG0=%#x, bit14 is 0\n",
+				tmp_reg);
+	}
+	/*	aml_dbg_print_pinmux();*/
+
+#ifdef CONFIG_MMC_AML_DEBUG
+	if (xfer_step == XFER_TIMER_TIMEOUT) { /* by aml_sdhc_timeout() */
+		sdhc_err("old sdhc reg:\n");
+		aml_sdhc_print_reg_(host->reg_buf);
+	}
+#endif
+	/*	aml_sdhc_print_reg(host);*/
+}
+
+/*error handler*/
+static void aml_sdhc_timeout(struct work_struct *work)
+{
+	static int timeout_cnt;
+	struct amlsd_host *host =
+		container_of(work, struct amlsd_host, timeout.work);
+	struct mmc_request *mrq;
+	struct amlsd_platform *pdata = mmc_priv(host->mmc);
+	unsigned long flags;
+	/* struct timeval ts_current; */
+	unsigned long time_start_cnt = aml_read_cbus(ISA_TIMERE);
+
+	time_start_cnt = (time_start_cnt - host->time_req_sta) / 1000;
+
+	WARN_ON(!host->mrq || !host->mrq->cmd);
+
+	spin_lock_irqsave(&host->mrq_lock, flags);
+	if (host->xfer_step == XFER_FINISHED) {
+		spin_unlock_irqrestore(&host->mrq_lock, flags);
+		sdhc_err("timeout after xfer finished\n");
+		return;
+	}
+
+	if ((host->xfer_step == XFER_IRQ_TASKLET_DATA)
+			|| (host->xfer_step == XFER_IRQ_TASKLET_CMD)) {
+		schedule_delayed_work(&host->timeout, 50);
+		host->time_req_sta = aml_read_cbus(ISA_TIMERE);
+
+		timeout_cnt++;
+		if (timeout_cnt > 30)
+			goto timeout_handle;
+
+		spin_unlock_irqrestore(&host->mrq_lock, flags);
+		sdhc_err(
+				"%s:cmd%d, xfer_step=%d,time_start_cnt=%ldmS,timeout_cnt=%d\n",
+				mmc_hostname(host->mmc),
+				host->mrq->cmd->opcode, host->xfer_step,
+				time_start_cnt, timeout_cnt);
+		up(&sdhc_sema);
+		return;
+	}
+timeout_handle:
+	timeout_cnt = 0;
+
+	mrq = host->mrq;
+	host->xfer_step_prev = host->xfer_step;
+	host->xfer_step = XFER_TIMER_TIMEOUT;
+	mrq->cmd->error = -ETIMEDOUT;
+
+	/* do not retry for sdcard & sdio wifi */
+	if (!aml_card_type_mmc(pdata)) {
+		sdhc_error_flag = 0;
+		mrq->cmd->retries = 0;
+	} else if (((sdhc_error_flag & (1<<3)) == 0)
+			&& (mrq->data != NULL)
+			&& pdata->is_in) {
+		/* set cmd retry cnt when first error. */
+		sdhc_error_flag |= (1<<3);
+		mrq->cmd->retries = AML_TIMEOUT_RETRY_COUNTER;
+	}
+
+	if (sdhc_error_flag && (mrq->cmd->retries == 0)) {
+		sdhc_error_flag |= (1<<30);
+		sdhc_err("Command retried failed\n");
+	}
+
+	aml_sdhc_status(host);
+
+	spin_unlock_irqrestore(&host->mrq_lock, flags);
+	aml_sdhc_read_response(host->mmc, mrq->cmd);
+	sdhc_err("time_start_cnt:%ld\n", time_start_cnt);
+
+	aml_sdhc_print_err(host);
+
+	aml_sdhc_host_reset(host);
+
+	/* do not send stop for sdio wifi case */
+	if (host->mrq->stop && aml_card_type_mmc(pdata)
+			&& !host->cmd_is_stop
+			&& (host->mrq->cmd->opcode != MMC_SEND_TUNING_BLOCK)
+			&& (host->mrq->cmd->opcode !=
+				MMC_SEND_TUNING_BLOCK_HS200)) {
+		aml_sdhc_send_stop(host);
+	} else{
+		spin_lock_irqsave(&host->mrq_lock, flags);
+		if (host->cmd_is_stop)
+			host->cmd_is_stop = 0;
+		spin_unlock_irqrestore(&host->mrq_lock, flags);
+
+		aml_sdhc_request_done(host->mmc, mrq);
+	}
+}
+
+static void aml_sdhc_tuning_timer(struct work_struct *work)
+{
+	struct amlsd_platform *pdata =
+		container_of(work, struct amlsd_platform, retuning.work);
+	struct amlsd_host *host = (void *)pdata->host;
+	unsigned long flags;
+
+	spin_lock_irqsave(&host->mrq_lock, flags);
+	pdata->need_retuning = true;
+	spin_unlock_irqrestore(&host->mrq_lock, flags);
+}
+
+/*cmd request interface*/
+void aml_sdhc_request(struct mmc_host *mmc, struct mmc_request *mrq)
+{
+	struct amlsd_platform *pdata;
+	struct amlsd_host *host;
+	/* u32 vista; */
+	unsigned long flags;
+	unsigned int timeout;
+	u32 tuning_opcode;
+
+	WARN_ON(!mmc);
+	WARN_ON(!mrq);
+
+	pdata = mmc_priv(mmc);
+	host = (void *)pdata->host;
+
+	if (aml_check_unsupport_cmd(mmc, mrq))
+		return;
+	aml_sdhc_emmc_clock_switch_on(pdata);
+	/* only for SDCARD */
+	if (!pdata->is_in || (!host->init_flag && aml_card_type_sd(pdata))) {
+		spin_lock_irqsave(&host->mrq_lock, flags);
+		mrq->cmd->error = -ENOMEDIUM;
+		mrq->cmd->retries = 0;
+		spin_unlock_irqrestore(&host->mrq_lock, flags);
+		mmc_request_done(mmc, mrq);
+		return;
+	}
+
+	if (pdata->need_retuning && mmc->card) {
+		/* eMMC uses cmd21 but sd and sdio use cmd19 */
+		tuning_opcode = (mmc->card->type == MMC_TYPE_MMC) ?
+			MMC_SEND_TUNING_BLOCK_HS200 : MMC_SEND_TUNING_BLOCK;
+		aml_sdhc_execute_tuning(mmc, tuning_opcode);
+	}
+
+	aml_sdhc_disable_imask(host, SDHC_ICTL_ALL);
+
+	sdhc_dbg(AMLSD_DBG_REQ, "%s: starting CMD%u arg %08x flags %08x\n",
+		mmc_hostname(mmc), mrq->cmd->opcode,
+		mrq->cmd->arg, mrq->cmd->flags);
+
+#ifdef CONFIG_AML_MMC_DEBUG_FORCE_SINGLE_BLOCK_RW
+	if ((mrq->cmd->opcode == 18) ||
+			(mrq->cmd->opcode == 25)) { /* for debug */
+		sdhc_err("cmd%d\n", mrq->cmd->opcode);
+	}
+#endif
+
+	if (mrq->cmd->opcode == 0) {
+		cmd25_cnt = 0;
+		fifo_empty_cnt = 0;
+		fifo_full_cnt = 0;
+		timeout_cnt = 0;
+		host->init_flag = 1;
+	}
+
+	if (mrq->cmd->opcode == 25)
+		cmd25_cnt++;
+
+	/* clear error flag if last command retried failed here */
+	if (sdhc_error_flag & (1<<30))
+		sdhc_error_flag = 0;
+
+	/*setup reg  especially for cmd with transferring data*/
+	if (mrq->data) {
+		/*Copy data to dma buffer for write request*/
+		aml_sdhc_prepare_dma(host, mrq);
+
+		sdhc_dbg(AMLSD_DBG_REQ,
+			"%s: blksz %d blocks %d flags %08x tsac %d ms nsac %d\n",
+			mmc_hostname(mmc), mrq->data->blksz,
+			mrq->data->blocks, mrq->data->flags,
+			mrq->data->timeout_ns / 1000000,
+			mrq->data->timeout_clks);
+	}
+
+	/*clear pinmux & set pinmux*/
+	if (pdata->xfer_pre)
+		pdata->xfer_pre(mmc);
+
+#ifdef CONFIG_MMC_AML_DEBUG
+	aml_dbg_verify_pull_up(pdata);
+	aml_dbg_verify_pinmux(pdata);
+#endif
+
+	if (!mrq->data)
+		timeout = 100; /* 1s */
+	else
+		timeout = 500;
+
+	if (mrq->cmd->opcode == MMC_SEND_STATUS)
+		timeout = 300;
+
+	/* about 30S for erase cmd. */
+	if (mrq->cmd->opcode == MMC_ERASE)
+		timeout = 3000;
+	schedule_delayed_work(&host->timeout, timeout);
+
+	spin_lock_irqsave(&host->mrq_lock, flags);
+	if (host->xfer_step != XFER_FINISHED && host->xfer_step != XFER_INIT)
+		sdhc_err("host->xfer_step %d\n", host->xfer_step);
+
+	/*host->mrq, used in irq & tasklet*/
+	host->mrq = mrq;
+	host->mmc = mmc;
+	host->xfer_step = XFER_START;
+	host->opcode = mrq->cmd->opcode;
+	host->arg = mrq->cmd->arg;
+	host->time_req_sta = aml_read_cbus(ISA_TIMERE);
+
+	/*setup reg for all cmd*/
+	aml_sdhc_start_cmd(pdata, mrq);
+	host->xfer_step = XFER_AFTER_START;
+	spin_unlock_irqrestore(&host->mrq_lock, flags);
+}
+
+static int aml_sdhc_status(struct amlsd_host *host)
+{
+	int ret = -1;
+	u32 victl = readl(host->base + SDHC_ICTL);
+	u32 vista = readl(host->base + SDHC_ISTA);
+	struct sdhc_ista *ista = (struct sdhc_ista *)&vista;
+	struct mmc_request *mrq = host->mrq;
+
+	if (!mrq) {
+		sdhc_err("NULL mrq\n");
+		return ret;
+	}
+
+	if (victl & vista) {
+		if (ista->rxfifo_full) {
+			host->status = HOST_RX_FIFO_FULL;
+			goto _status_exit;
+		}
+		if (ista->txfifo_empty) {
+			host->status = HOST_TX_FIFO_EMPTY;
+			goto _status_exit;
+		}
+		if (ista->resp_err_crc) {
+			host->status = HOST_RSP_CRC_ERR;
+			goto _status_exit;
+		}
+		if (ista->data_err_crc) {
+			host->status = HOST_DAT_CRC_ERR;
+			goto _status_exit;
+		}
+		if (ista->resp_timeout) {
+			host->status = HOST_RSP_TIMEOUT_ERR;
+			goto _status_exit;
+		}
+		if (ista->data_timeout) {
+			host->status = HOST_DAT_TIMEOUT_ERR;
+			goto _status_exit;
+		}
+		if (ista->dma_done) {
+			host->status = HOST_TASKLET_DATA;
+			ret = 0; /* ok */
+			goto _status_exit;
+		}
+		if (ista->data_xfer_ok) {
+			host->status = HOST_TASKLET_DATA;
+			ret = 0; /* ok */
+			goto _status_exit;
+		}
+		if (ista->resp_ok_noclear) {
+			host->status = HOST_TASKLET_CMD;
+			ret = 0; /* ok */
+			goto _status_exit;
+		}
+	}
+	ret = 0; /* ok */
+_status_exit:
+	return ret;
+}
+
+/*sdhc controller irq*/
+static irqreturn_t aml_sdhc_irq(int irq, void *dev_id)
+{
+	struct amlsd_host *host = dev_id;
+	struct mmc_host *mmc;
+	struct amlsd_platform *pdata;
+	struct mmc_request *mrq;
+	unsigned long flags;
+	bool exception_flag = false;
+	u32 victl;
+	u32 vista;
+
+	spin_lock_irqsave(&host->mrq_lock, flags);
+	victl = readl(host->base + SDHC_ICTL);
+	vista = readl(host->base + SDHC_ISTA);
+
+	mrq = host->mrq;
+	mmc = host->mmc;
+	pdata = mmc_priv(mmc);
+
+	sdhc_dbg(AMLSD_DBG_IRQ,
+			"%s %d %s  occurred, vstat:0x%x\n",
+			__func__, __LINE__, pdata->pinname, vista);
+	if (!mrq) {
+		sdhc_err("NULL mrq in aml_sdhc_irq step %d\n", host->xfer_step);
+		if (host->xfer_step == XFER_FINISHED ||
+				host->xfer_step == XFER_TIMER_TIMEOUT){
+			spin_unlock_irqrestore(&host->mrq_lock, flags);
+			return IRQ_HANDLED;
+		}
+		WARN_ON(!mrq);
+		/*	aml_sdhc_print_reg(host);*/
+		spin_unlock_irqrestore(&host->mrq_lock, flags);
+		return IRQ_HANDLED;
+	}
+
+	if ((host->xfer_step != XFER_AFTER_START) && (!host->cmd_is_stop)) {
+		sdhc_err("host->xfer_step=%d\n", host->xfer_step);
+		exception_flag = true;
+	}
+
+	if (host->cmd_is_stop)
+		host->xfer_step = XFER_IRQ_TASKLET_BUSY;
+	else
+		host->xfer_step = XFER_IRQ_OCCUR;
+
+	if (victl & vista) {
+		aml_sdhc_status(host);
+		if (exception_flag)
+			sdhc_err("victl=%#x, vista=%#x,status=%#x\n",
+					victl, vista, host->status);
+		switch (host->status) {
+		case HOST_RX_FIFO_FULL:
+			mrq->cmd->error = -HOST_RX_FIFO_FULL;
+			fifo_full_cnt++;
+			break;
+		case HOST_TX_FIFO_EMPTY:
+			mrq->cmd->error = -HOST_TX_FIFO_EMPTY;
+			fifo_empty_cnt++;
+			break;
+		case HOST_RSP_CRC_ERR:
+		case HOST_DAT_CRC_ERR:
+			mrq->cmd->error = -EILSEQ;
+			break;
+		case HOST_RSP_TIMEOUT_ERR:
+		case HOST_DAT_TIMEOUT_ERR:
+			if (!host->cmd_is_stop)
+				timeout_cnt++;
+			mrq->cmd->error = -ETIMEDOUT;
+			break;
+		case HOST_TASKLET_DATA:
+		case HOST_TASKLET_CMD:
+			writel(vista, host->base+SDHC_ISTA);
+			break;
+		default:
+			sdhc_err(
+				"Unknown irq status, victl=%#x, vista=%#x,status=%#x\n",
+				victl, vista, host->status);
+			break;
+		}
+
+		spin_unlock_irqrestore(&host->mrq_lock, flags);
+		return IRQ_WAKE_THREAD;
+
+	}
+	host->xfer_step = XFER_IRQ_UNKNOWN_IRQ;
+	sdhc_err(
+			"%s Unknown Irq Ictl 0x%x, Ista 0x%x, cmd %d,xfer %d bytes\n",
+			pdata->pinname, victl, vista, mrq->cmd->opcode,
+			mrq->data?mrq->data->blksz*mrq->data->blocks:0);
+	spin_unlock_irqrestore(&host->mrq_lock, flags);
+	return IRQ_HANDLED;
+}
+
+static void aml_sdhc_com_err_handler (struct amlsd_host *host)
+{
+	if (delayed_work_pending(&host->timeout))
+		cancel_delayed_work_sync(&host->timeout);
+	aml_sdhc_read_response(host->mmc, host->mrq->cmd);
+	aml_sdhc_print_err(host);
+	aml_sdhc_host_reset(host);
+	aml_sdhc_request_done(host->mmc, host->mrq);
+}
+
+static void aml_sdhc_not_timeout_err_handler (struct amlsd_host *host)
+{
+	if (aml_sdhc_wait_ready(host, (STAT_POLL_TIMEOUT<<2))) {
+		/*Wait command busy*/
+		sdhc_err("aml_sdhc_wait_ready error not timeout error handler\n");
+	}
+	aml_sdhc_com_err_handler(host);
+}
+
+struct mmc_command aml_sdhc_cmd = {
+	.opcode = MMC_STOP_TRANSMISSION,
+	.flags = MMC_RSP_SPI_R1B | MMC_RSP_R1B | MMC_CMD_AC,
+};
+struct mmc_request aml_sdhc_stop = {
+	.cmd = &aml_sdhc_cmd,
+};
+
+static void aml_sdhc_send_stop(struct amlsd_host *host)
+{
+	struct amlsd_platform *pdata = mmc_priv(host->mmc);
+	unsigned long flags;
+
+	/*Already in mrq_lock*/
+	schedule_delayed_work(&host->timeout, 50);
+	spin_lock_irqsave(&host->mrq_lock, flags);
+	sdhc_err_bak = host->mrq->cmd->error;
+	host->mrq->cmd->error = 0;
+	host->cmd_is_stop = 1;
+	aml_sdhc_start_cmd(pdata, &aml_sdhc_stop);
+	spin_unlock_irqrestore(&host->mrq_lock, flags);
+}
+
+static unsigned int clock[] = {90000000,
+	80000000, 75000000, 70000000, 65000000, 60000000, 50000000};
+static void aml_sdhc_set_clk_rate(struct mmc_host *mmc, unsigned int clk_ios);
+irqreturn_t aml_sdhc_data_thread(int irq, void *data)
+{
+	struct amlsd_host *host = data;
+	u32 xfer_bytes;
+	struct mmc_request *mrq;
+	enum aml_mmc_waitfor xfer_step;
+	unsigned long flags;
+	u32 vstat, status;
+	struct sdhc_stat *stat = (struct sdhc_stat *)&vstat;
+	struct amlsd_platform *pdata = mmc_priv(host->mmc);
+	int cnt = 0;
+
+	u32 esta = readl(host->base + SDHC_ESTA);
+	int i;
+	/*	u32 dmc_sts = 0;*/
+	u32 vpdma = readl(host->base+SDHC_PDMA);
+	struct sdhc_pdma *pdma = (struct sdhc_pdma *)&vpdma;
+
+	spin_lock_irqsave(&host->mrq_lock, flags);
+	mrq = host->mrq;
+	xfer_step = host->xfer_step;
+	status = host->status;
+
+	if ((xfer_step == XFER_FINISHED) || (xfer_step == XFER_TIMER_TIMEOUT)) {
+		sdhc_err(
+				"Warning: xfer_step=%d,host->status=%d\n",
+				xfer_step, status);
+		spin_unlock_irqrestore(&host->mrq_lock, flags);
+		return IRQ_HANDLED;
+	}
+
+	WARN_ON((host->xfer_step != XFER_IRQ_OCCUR)
+			&& (host->xfer_step != XFER_IRQ_TASKLET_BUSY));
+
+	if (!mrq) {
+		sdhc_err("!mrq xfer_step %d\n", xfer_step);
+		if (xfer_step == XFER_FINISHED ||
+				xfer_step == XFER_TIMER_TIMEOUT){
+			spin_unlock_irqrestore(&host->mrq_lock, flags);
+			return IRQ_HANDLED;
+		}
+		/* BUG(); */
+		aml_sdhc_print_err(host);
+	}
+	if (host->cmd_is_stop) {
+		int delay = 1;
+
+		if (mrq->cmd->error)
+			sdhc_err("cmd12 error %d\n", mrq->cmd->error);
+		host->cmd_is_stop = 0;
+		mrq->cmd->error = sdhc_err_bak;
+		spin_unlock_irqrestore(&host->mrq_lock, flags);
+		if (delayed_work_pending(&host->timeout))
+			cancel_delayed_work_sync(&host->timeout);
+		msleep(delay);
+		sdhc_err("delay %dms\n", delay);
+		aml_sdhc_request_done(host->mmc, host->mrq);
+		return IRQ_HANDLED;
+	}
+	spin_unlock_irqrestore(&host->mrq_lock, flags);
+
+	WARN_ON(!host->mrq->cmd);
+	switch (status) {
+	case HOST_TASKLET_DATA:
+		sdhc_error_flag = 0;
+		WARN_ON(!mrq->data);
+		if (delayed_work_pending(&host->timeout))
+			cancel_delayed_work_sync(&host->timeout);
+
+		xfer_bytes = mrq->data->blksz*mrq->data->blocks;
+		/* copy buffer from dma to data->sg in read cmd*/
+		if (host->mrq->data->flags & MMC_DATA_READ) {
+			if (!aml_card_type_sdio(pdata)) {
+				for (i = 0; i < STAT_POLL_TIMEOUT; i++) {
+
+					esta = readl(host->base + SDHC_ESTA);
+					esta = readl(host->base + SDHC_ESTA);
+					/* read twice, we just
+					 * focus on the second result
+					 */
+					/* REGC_ESTA[13:11]=0? then OK */
+					if (((esta >> 11) & 0x7) == 0)
+						break;
+					else if (i == 10)
+						sdhc_err("SDHC_ESTA=0x%x\n",
+								esta);
+				}
+
+				if (i == STAT_POLL_TIMEOUT) { /* error */
+					sdhc_err("Warning:DMA state is wrong!");
+					sdhc_err(" SDHC_ESTA=0x%x\n", esta);
+				}
+
+				pdma->rxfifo_manual_flush |= 0x02;
+				/* bit[30] */
+				writel(vpdma, host->base+SDHC_PDMA);
+				/* check ddr dma status after
+				 * controller dma status OK
+				 */
+#if 0
+				for (i = 0; i < STAT_POLL_TIMEOUT; i++) {
+					dmc_sts =
+						aml_read_reg32(P_DMC_CHAN_STS);
+					dmc_sts = (dmc_sts >> 15)&1;
+					if (dmc_sts)
+						break;
+					else if (i == 10)
+						sdhc_err("SDHC_ESTA=0x%x\n",
+								esta);
+				}
+
+				if (i == STAT_POLL_TIMEOUT) /* error */
+					sdhc_err(
+							"DMA wrong!SDHC_ESTA=0x%x dmc_sts:%d\n",
+							esta, dmc_sts);
+#endif
+			}
+			aml_sg_copy_buffer(mrq->data->sg,
+					mrq->data->sg_len,
+					host->bn_buf, xfer_bytes, 0);
+			sdhc_dbg(AMLSD_DBG_RD_DATA, "R Cmd%d, arg %x, size=%d\n",
+					mrq->cmd->opcode,
+					mrq->cmd->arg, xfer_bytes);
+			sdhc_dbg(AMLSD_DBG_RD_DATA, "R Cmd %d, %x-%x-%x-%x-%x-%x-%x-%x\n",
+					host->mrq->cmd->opcode,
+					host->bn_buf[0], host->bn_buf[1],
+					host->bn_buf[2], host->bn_buf[3],
+					host->bn_buf[4], host->bn_buf[5],
+					host->bn_buf[6], host->bn_buf[7]);
+			/* aml_debug_print_buf(host->bn_buf, xfer_bytes); */
+		}
+
+		vstat = readl(host->base + SDHC_STAT);
+		if (stat->rxfifo_cnt) {
+			sdhc_err("cmd%d, rxfifo_cnt=%d\n",
+					mrq->cmd->opcode, stat->rxfifo_cnt);
+		}
+
+		spin_lock_irqsave(&host->mrq_lock, flags);
+		mrq->cmd->error = 0;
+		mrq->data->bytes_xfered = xfer_bytes;
+		host->xfer_step = XFER_TASKLET_DATA;
+		spin_unlock_irqrestore(&host->mrq_lock, flags);
+		/* do not check device ready status here */
+		if (aml_sdhc_wait_ready(host,
+				(STAT_POLL_TIMEOUT<<2))) { /*Wait command busy*/
+			sdhc_err("aml_sdhc_wait_ready error after data thread\n");
+		}
+		aml_sdhc_read_response(host->mmc, mrq->cmd);
+		aml_sdhc_request_done(host->mmc, mrq);
+		break;
+	case HOST_TASKLET_CMD:
+		sdhc_error_flag = 0;
+		if (!host->mrq->data) {
+			if (delayed_work_pending(&host->timeout))
+				cancel_delayed_work_sync(&host->timeout);
+			spin_lock_irqsave(&host->mrq_lock, flags);
+			host->mrq->cmd->error = 0;
+			host->xfer_step = XFER_TASKLET_CMD;
+			spin_unlock_irqrestore(&host->mrq_lock, flags);
+			if (aml_sdhc_wait_ready(host, STAT_POLL_TIMEOUT)) {
+				/*Wait command busy*/
+				sdhc_err("aml_sdhc_wait_ready error cmd thread\n");
+			}
+			aml_sdhc_read_response(host->mmc, host->mrq->cmd);
+			aml_sdhc_request_done(host->mmc, mrq);
+		} else {
+			sdhc_err(
+				"xfer_step is HOST_TASKLET_CMD, while host->mrq->data is not NULL\n");
+		}
+		break;
+	case HOST_TX_FIFO_EMPTY:
+	case HOST_RX_FIFO_FULL:
+	case HOST_RSP_TIMEOUT_ERR:
+	case HOST_DAT_TIMEOUT_ERR:
+		if (delayed_work_pending(&host->timeout))
+			cancel_delayed_work_sync(&host->timeout);
+		if (aml_sdhc_wait_ready(host,
+				(STAT_POLL_TIMEOUT<<2))) { /*Wait command busy*/
+			sdhc_err("aml_sdhc_wait_ready error fifo or timeout thread\n");
+		}
+		aml_sdhc_read_response(host->mmc, host->mrq->cmd);
+		aml_sdhc_print_err(host);
+		aml_sdhc_host_reset(host);
+		writel(SDHC_ISTA_W1C_ALL, host->base+SDHC_ISTA);
+		spin_lock_irqsave(&host->mrq_lock, flags);
+		if ((sdhc_error_flag == 0) &&
+				(host->mrq->cmd->opcode
+				 != MMC_SEND_TUNING_BLOCK)
+				&& (host->mrq->cmd->opcode
+					!= MMC_SEND_TUNING_BLOCK_HS200)
+				&& host->mrq->data){
+			/* set cmd retry cnt when first error. */
+			sdhc_error_flag |= (1<<0);
+			if ((status == HOST_RSP_TIMEOUT_ERR) ||
+					(status == HOST_DAT_TIMEOUT_ERR)) {
+				if (aml_card_type_mmc(pdata))
+					mrq->cmd->retries
+						= AML_TIMEOUT_RETRY_COUNTER;
+				else {
+					sdhc_error_flag = 0;
+					mrq->cmd->retries = 0;
+				}
+			} else
+				mrq->cmd->retries = AML_ERROR_RETRY_COUNTER;
+		}
+
+		if (sdhc_error_flag && (mrq->cmd->retries == 0)) {
+			sdhc_error_flag |= (1<<30);
+			sdhc_err(
+				"Command retried failed line:%d, status:%d\n",
+				__LINE__, status);
+		}
+		spin_unlock_irqrestore(&host->mrq_lock, flags);
+
+		/* do not send stop for sdio wifi case */
+		if (host->mrq->stop && aml_card_type_mmc(pdata)
+				&& pdata->is_in
+				&& (host->mrq->cmd->opcode !=
+					MMC_SEND_TUNING_BLOCK)
+				&& (host->mrq->cmd->opcode
+					!= MMC_SEND_TUNING_BLOCK_HS200))
+			aml_sdhc_send_stop(host);
+		else
+			aml_sdhc_request_done(host->mmc, mrq);
+		break;
+	case HOST_RSP_CRC_ERR:
+	case HOST_DAT_CRC_ERR:
+		pdata = mmc_priv(host->mmc);
+		if (aml_card_type_sdio(pdata) /* sdio_wifi */
+				&& (host->mrq->cmd->opcode
+					!= MMC_SEND_TUNING_BLOCK)
+				&& (host->mrq->cmd->opcode
+					!= MMC_SEND_TUNING_BLOCK_HS200)) {
+			sdhc_err("host->mmc->ios.clock:%d\n",
+					host->mmc->ios.clock);
+			while (host->mmc->ios.clock <= clock[cnt]) {
+				cnt++;
+				if (cnt >= (ARRAY_SIZE(clock) - 1))
+					break;
+			}
+			spin_lock_irqsave(&host->mrq_lock, flags);
+
+			host->mmc->ios.clock = clock[cnt];
+			pdata->need_retuning = true;
+			/* retuing will be done in the next request */
+			mrq->cmd->retries = (ARRAY_SIZE(clock) - 1) - cnt;
+			spin_unlock_irqrestore(&host->mrq_lock, flags);
+			aml_sdhc_set_clk_rate(host->mmc, host->mmc->ios.clock);
+		} else if (aml_card_type_mmc(pdata)
+				&& (host->mrq->cmd->opcode
+					!= MMC_SEND_TUNING_BLOCK)
+				&& (host->mrq->cmd->opcode
+					!= MMC_SEND_TUNING_BLOCK_HS200)) {
+			spin_lock_irqsave(&host->mrq_lock, flags);
+
+			if (sdhc_error_flag == 0) {
+				/* set cmd retry cnt when first error. */
+				sdhc_error_flag |= (1<<1);
+				mrq->cmd->retries = AML_ERROR_RETRY_COUNTER;
+			}
+			spin_unlock_irqrestore(&host->mrq_lock, flags);
+		}
+		if (sdhc_error_flag && (mrq->cmd->retries == 0)) {
+			sdhc_error_flag |= (1<<30);
+			/* sdhc_err("Command retried failed\n"); */
+		}
+
+		aml_sdhc_not_timeout_err_handler(host);
+		break;
+	default:
+		sdhc_err("BUG xfer_step=%d, host->status=%d\n",
+			xfer_step, status);
+		aml_sdhc_print_err(host);
+		break;
+	}
+
+	return IRQ_HANDLED;
+}
+
+static void aml_sdhc_clk_switch_off(struct amlsd_host *host)
+{
+	u32 vclkc = readl(host->base+SDHC_CLKC);
+	struct sdhc_clkc *clkc = (struct sdhc_clkc *)&vclkc;
+
+	if (host->is_gated) {
+		/*sdhc_err("direct return\n");*/
+		return;
+	}
+
+	/*Turn off Clock*/
+	clkc->tx_clk_on = 0;
+	clkc->rx_clk_on = 0;
+	clkc->sd_clk_on = 0;
+	writel(vclkc, host->base+SDHC_CLKC);
+	clkc->mod_clk_on = 0;
+	writel(vclkc, host->base+SDHC_CLKC);
+
+	host->is_gated = true;
+	/*sdhc_err("clock off\n");*/
+}
+
+static void aml_sdhc_emmc_clock_switch_on(struct amlsd_platform *pdata)
+{
+	struct amlsd_host *host = (void *)pdata->host;
+	u32 vclkc = readl(host->base+SDHC_CLKC);
+	struct sdhc_clkc *clkc = (struct sdhc_clkc *)&vclkc;
+
+	/*Turn on Clock*/
+	clkc->mod_clk_on = 1;
+	writel(vclkc, host->base+SDHC_CLKC);
+
+	clkc->tx_clk_on = 1;
+	clkc->rx_clk_on = 1;
+	clkc->sd_clk_on = 1;
+	writel(vclkc, host->base+SDHC_CLKC);
+
+	host->is_gated = false;
+}
+
+static void aml_sdhc_clk_switch_on(struct amlsd_platform *pdata,
+		int clk_div, int clk_src_sel)
+{
+	struct amlsd_host *host = (void *)pdata->host;
+	u32 vclkc = readl(host->base+SDHC_CLKC);
+	struct sdhc_clkc *clkc = (struct sdhc_clkc *)&vclkc;
+
+	/*Set clock divide*/
+	clkc->clk_div = clk_div;
+	clkc->clk_src_sel = clk_src_sel;
+
+	writel(vclkc, host->base+SDHC_CLKC);
+
+	/*Turn on Clock*/
+	clkc->mod_clk_on = 1;
+	writel(vclkc, host->base+SDHC_CLKC);
+
+	clkc->tx_clk_on = 1;
+	clkc->rx_clk_on = 1;
+	clkc->sd_clk_on = 1;
+	writel(vclkc, host->base+SDHC_CLKC);
+
+	host->is_gated = false;
+}
+
+static void aml_sdhc_clk_switch(struct amlsd_platform *pdata,
+		int clk_div, int clk_src_sel)
+{
+	struct amlsd_host *host = (void *)pdata->host;
+	u32 vclkc = readl(host->base + SDHC_CLKC);
+	struct sdhc_clkc *clkc = (struct sdhc_clkc *)&vclkc;
+
+	if (!host->is_gated && (clkc->clk_div == clk_div)
+			&& (clkc->clk_src_sel == clk_src_sel)) {
+		/*sdhc_err("direct return\n");*/
+		return; /* if the same, return directly */
+	}
+
+	aml_sdhc_clk_switch_off(host);
+	/* mdelay(1); */
+	aml_sdhc_clk_switch_on(pdata, clk_div, clk_src_sel);
+}
+
+/*
+ * 1. clock valid range
+ * 2. clk config enable
+ * 3. select clock source
+ * 4. set clock divide
+ */
+static void aml_sdhc_set_clk_rate(struct mmc_host *mmc, unsigned int clk_ios)
+{
+	u32 clk_rate, clk_div, clk_src_sel, clk_src_div;
+	unsigned long flags;
+	struct amlsd_platform *pdata = mmc_priv(mmc);
+	struct amlsd_host *host = (void *)pdata->host;
+	u32 vclk2;
+	struct sdhc_clk2 *clk2 = (struct sdhc_clk2 *)&vclk2;
+
+	if (clk_ios == 0) {
+		aml_sdhc_clk_switch_off(host);
+		return;
+	}
+
+	if ((clk_ios > 100000000) && (val1 > 100000000)) /* for debug, 100M */
+		clk_ios = val1;
+	clk_src_div = -1;
+	clk_src_sel = SDHC_CLOCK_SRC_FCLK_DIV3;
+	switch (clk_src_sel) {
+	case SDHC_CLOCK_SRC_FCLK_DIV3:
+		clk_src_div = 3;
+		break;
+	case SDHC_CLOCK_SRC_FCLK_DIV4:
+		clk_src_div = 4;
+		break;
+	case SDHC_CLOCK_SRC_FCLK_DIV5:
+		clk_src_div = 5;
+		break;
+	case SDHC_CLOCK_SRC_OSC:
+		clk_src_div = 0;
+		break;
+	default:
+		sdhc_err("Clock source error: %d\n", clk_src_sel);
+		return; /* clk_src_div = -1; */
+	}
+
+	if (clk_src_sel != SDHC_CLOCK_SRC_OSC)
+		clk_rate = clk_get_rate(host->div3_clk); /* 850000000 */
+	else /* OSC, 24MHz */
+		clk_rate = 24000000;
+
+	spin_lock_irqsave(&host->mrq_lock, flags);
+
+	if (clk_ios > pdata->f_max)
+		clk_ios = pdata->f_max;
+	if (clk_ios < pdata->f_min)
+		clk_ios = pdata->f_min;
+
+	/*0: dont set it, 1:div2, 2:div3, 3:div4...*/
+	clk_div = clk_rate / clk_ios - !(clk_rate%clk_ios);
+	if (!(clk_div & 0x01)) /* if even number, turn it to an odd one */
+		clk_div++;
+
+	aml_sdhc_clk_switch(pdata, clk_div, clk_src_sel);
+	pdata->clkc = readl(host->base+SDHC_CLKC);
+
+	pdata->mmc->actual_clock = clk_rate / (clk_div + 1);
+
+	vclk2 = readl(host->base+SDHC_CLK2);
+	clk2->sd_clk_phase = 1; /* 1 */
+	if (pdata->mmc->actual_clock > 100000000) { /* if > 100M */
+		clk2->rx_clk_phase = rx_clk_phase_set;
+		/* clk2->sd_clk_phase = sd_clk_phase_set; // 1 */
+	} else if (pdata->mmc->actual_clock > 45000000) { /* if > 45M */
+		if (mmc->ios.signal_voltage
+				== MMC_SIGNAL_VOLTAGE_330) /* 3.3V */
+			clk2->rx_clk_phase = 15;
+		else
+			clk2->rx_clk_phase = 11;
+	} else if (pdata->mmc->actual_clock >= 25000000) { /* if >= 25M */
+		clk2->rx_clk_phase = 15; /* 10 */
+	} else if (pdata->mmc->actual_clock > 5000000) { /* if > 5M */
+		clk2->rx_clk_phase = 23;
+	} else if (pdata->mmc->actual_clock > 1000000) { /* if > 1M */
+		clk2->rx_clk_phase = 55;
+	} else {
+		clk2->rx_clk_phase = 1061; /* 63; // 24; */
+	}
+	writel(vclk2, host->base+SDHC_CLK2);
+	pdata->clk2 = vclk2;
+
+	/*Disable All Irq*/
+	writel(0, host->base+SDHC_ICTL);
+
+	/*Wait for a while after clock setting*/
+	/* udelay(100); */
+
+	spin_unlock_irqrestore(&host->mrq_lock, flags);
+	sdhc_dbg(AMLSD_DBG_IOS, "Clk IOS %d, Clk Src %d, Host Max Clk %d,",
+			clk_ios, clk_rate, pdata->f_max);
+	sdhc_dbg(AMLSD_DBG_IOS, " vclkc=%#x, clk2=%#x, actual_clock=%d,",
+			readl(host->base+SDHC_CLKC),
+			readl(host->base+SDHC_CLK2),
+			pdata->mmc->actual_clock);
+	sdhc_dbg(AMLSD_DBG_IOS, " rx_clk_phase=%d, sd_clk_phase=%d\n",
+			clk2->rx_clk_phase, clk2->sd_clk_phase);
+}
+
+/*setup bus width, 1bit, 4bits, 8bits*/
+static void aml_sdhc_set_bus_width(struct amlsd_platform *pdata, u32 busw_ios)
+{
+	struct amlsd_host *host = (void *)pdata->host;
+	u32 vctrl = readl(host->base + SDHC_CTRL);
+	struct sdhc_ctrl *ctrl = (struct sdhc_ctrl *)&vctrl;
+	u32 width = 0;
+
+	switch (busw_ios) {
+	case MMC_BUS_WIDTH_1:
+		width = 0;
+		break;
+	case MMC_BUS_WIDTH_4:
+		width = 1;
+		break;
+	case MMC_BUS_WIDTH_8:
+		width = 2;
+		break;
+	default:
+		sdhc_err("Error Data Bus\n");
+		break;
+	}
+
+	ctrl->dat_type = width;
+	pdata->width = width;
+	writel(vctrl, host->base+SDHC_CTRL);
+	sdhc_dbg(AMLSD_DBG_COMMON, "Bus Width Ios %d\n", busw_ios);
+}
+
+/*call by mmc, power on, power off ...*/
+static void aml_sdhc_set_power(struct amlsd_platform *pdata, u32 power_mode)
+{
+	switch (power_mode) {
+	case MMC_POWER_ON:
+		if (pdata->pwr_pre)
+			pdata->pwr_pre(pdata);
+		if (pdata->pwr_on)
+			pdata->pwr_on(pdata);
+		break;
+	case MMC_POWER_UP:
+		break;
+	case MMC_POWER_OFF:
+	default:
+		if (pdata->pwr_pre)
+			pdata->pwr_pre(pdata);
+		if (pdata->pwr_off)
+			pdata->pwr_off(pdata);
+		break;
+	}
+}
+
+/*call by mmc, set ios: power, clk, bus width*/
+static void aml_sdhc_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
+{
+	struct amlsd_platform *pdata = mmc_priv(mmc);
+
+	if (!pdata->is_in)
+		return;
+
+	/*Set Power*/
+	aml_sdhc_set_power(pdata, ios->power_mode);
+
+	/*Set Clock*/
+	aml_sdhc_set_clk_rate(mmc, ios->clock);
+
+	/*Set Bus Width*/
+	aml_sdhc_set_bus_width(pdata, ios->bus_width);
+#if 1
+	if (ios->chip_select == MMC_CS_HIGH)
+		aml_cs_high(mmc);
+	else if (ios->chip_select == MMC_CS_DONTCARE)
+		aml_cs_dont_care(mmc);
+#endif
+}
+
+/*get readonly: 0 for rw, 1 for ro*/
+static int aml_sdhc_get_ro(struct mmc_host *mmc)
+{
+	struct amlsd_platform *pdata = mmc_priv(mmc);
+	u32 ro = 0;
+
+	if (pdata->ro)
+		ro = pdata->ro(pdata);
+	return ro;
+}
+
+/*get card detect: 1 for insert, 0 for removed*/
+int aml_sdhc_get_cd(struct mmc_host *mmc)
+{
+	struct amlsd_platform *pdata = mmc_priv(mmc);
+
+	return pdata->is_in; /* 0: no inserted  1: inserted */
+}
+
+int aml_sdhc_signal_voltage_switch(struct mmc_host *mmc, struct mmc_ios *ios)
+{
+	return aml_sd_voltage_switch(mmc, ios->signal_voltage);
+}
+
+/* Check if the card is pulling dat[0:3] low */
+static int aml_sdhc_card_busy(struct mmc_host *mmc)
+{
+	struct amlsd_platform *pdata = mmc_priv(mmc);
+	struct amlsd_host *host = pdata->host;
+	u32 vstat;
+	struct sdhc_stat *stat = (struct sdhc_stat *)&vstat;
+
+	vstat = readl(host->base + SDHC_STAT);
+	sdhc_dbg(AMLSD_DBG_COMMON, "dat[0:3]=%#x\n", stat->dat3_0);
+
+	/* return (stat->dat3_0 == 0); */
+	if (stat->dat3_0 == 0)
+		return 1;
+	else
+		return 0;
+}
+
+#if 0/* def CONFIG_PM */
+static int aml_sdhc_suspend(struct platform_device *pdev, pm_message_t state)
+{
+	int ret = 0;
+	int i;
+	struct amlsd_host *host = platform_get_drvdata(pdev);
+	struct mmc_host *mmc;
+	struct amlsd_platform *pdata;
+
+	pr_info("***Entered %s:%s\n", __FILE__, __func__);
+	i = 0;
+	list_for_each_entry(pdata, &host->sibling, sibling) {
+		cancel_delayed_work_sync(&pdata->retuning);
+		pdata->need_retuning = false;
+
+		mmc = pdata->mmc;
+		/* mmc_power_save_host(mmc); */
+		ret = mmc_suspend_host(mmc);
+		if (ret)
+			break;
+		i++;
+	}
+
+	if (ret) {
+		list_for_each_entry(pdata, &host->sibling, sibling) {
+			i--;
+			if (i < 0)
+				break;
+
+			mmc = pdata->mmc;
+			mmc_resume_host(mmc);
+		}
+	}
+	pr_info("***Exited %s:%s\n", __FILE__, __func__);
+
+	return ret;
+}
+
+static int aml_sdhc_resume(struct platform_device *pdev)
+{
+	int ret = 0;
+	struct amlsd_host *host = platform_get_drvdata(pdev);
+	struct mmc_host *mmc;
+	struct amlsd_platform *pdata;
+
+	pr_info("***Entered %s:%s\n", __FILE__, __func__);
+	list_for_each_entry(pdata, &host->sibling, sibling) {
+		/* detect if a card is exist or not if it is removable */
+		if (!(pdata->caps & MMC_CAP_NONREMOVABLE))
+			aml_sd_uart_detect(pdata);
+
+		mmc = pdata->mmc;
+		/* mmc_power_restore_host(mmc); */
+		ret = mmc_resume_host(mmc);
+		if (ret)
+			break;
+	}
+	pr_info("***Exited %s:%s\n", __FILE__, __func__);
+	return ret;
+}
+#else
+#define aml_sdhc_suspend	NULL
+#define aml_sdhc_resume		NULL
+#endif
+
+static const struct mmc_host_ops aml_sdhc_ops = {
+	.request = aml_sdhc_request,
+	.set_ios = aml_sdhc_set_ios,
+	.get_cd = aml_sdhc_get_cd,
+	.get_ro = aml_sdhc_get_ro,
+	.start_signal_voltage_switch = aml_sdhc_signal_voltage_switch,
+	.card_busy = aml_sdhc_card_busy,
+	.execute_tuning = aml_sdhc_execute_tuning,
+	.hw_reset = aml_emmc_hw_reset,
+};
+
+/*for multi host claim host*/
+/* static struct mmc_claim aml_sdhc_claim;*/
+
+static ssize_t sdhc_debug_func(struct class *class,
+		struct class_attribute *attr,
+		const char *buf, size_t count)
+{
+	int i;
+
+	i = kstrtoint(buf, 0, &sdhc_debug_flag);
+	pr_info("sdhc_debug_flag: %d\n", sdhc_debug_flag);
+	return count;
+}
+
+static ssize_t show_sdhc_debug(struct class *class,
+		struct class_attribute *attr,	char *buf)
+{
+	pr_info("sdhc_debug_flag: %d\n", sdhc_debug_flag);
+	pr_info("1 : Force sdhc HOST_TX_FIFO_EMPTY error\n");
+	pr_info("2 : Force sdhc HOST_RX_FIFO_FULL error\n");
+	pr_info("3 : Force sdhc HOST_RSP_CRC_ERR error\n");
+	pr_info("4 : Force sdhc HOST_DAT_CRC_ERR error\n");
+	pr_info("5 : Force sdhc HOST_DAT_TIMEOUT_ERR error\n");
+	pr_info("6 : Force sdhc HOST_RSP_TIMEOUT_ERR error\n");
+	pr_info("9 : Force sdhc irq timeout error\n");
+
+	return 0;
+}
+
+static struct class_attribute sdhc_class_attrs[] = {
+	__ATTR(debug, 0644, show_sdhc_debug, sdhc_debug_func),
+	__ATTR_NULL
+};
+
+static struct amlsd_host *aml_sdhc_init_host(struct amlsd_host *host)
+{
+	/*	spin_lock_init(&aml_sdhc_claim.lock);
+	 *	init_waitqueue_head(&aml_sdhc_claim.wq);
+	 */
+	if (request_threaded_irq(host->irq, aml_sdhc_irq,
+				aml_sdhc_data_thread,
+				IRQF_SHARED, "sdhc", (void *)host)) {
+		sdhc_err("Request SDHC Irq Error!\n");
+		return NULL;
+	}
+
+	host->bn_buf = dma_alloc_coherent(NULL, SDHC_BOUNCE_REQ_SIZE,
+			&host->bn_dma_buf, GFP_KERNEL);
+	if (host->bn_buf == NULL) {
+		sdhc_err("Dma alloc Fail!\n");
+		return NULL;
+	}
+	INIT_DELAYED_WORK(&host->timeout, aml_sdhc_timeout);
+
+	spin_lock_init(&host->mrq_lock);
+	mutex_init(&host->pinmux_lock);
+	host->xfer_step = XFER_INIT;
+
+	INIT_LIST_HEAD(&host->sibling);
+
+	host->init_flag = 1;
+
+	host->version = AML_MMC_VERSION;
+	/*	host->storage_flag = storage_flag;*/
+	host->pinctrl = NULL;
+	host->is_gated = false;
+	host->status = HOST_INVALID;
+	host->msg_buf = kmalloc(MESSAGE_BUF_SIZE, GFP_KERNEL);
+	if (!host->msg_buf)
+		pr_info("malloc message buffer fail\n");
+
+#ifdef CONFIG_MMC_AML_DEBUG
+	host->req_cnt = 0;
+	sdhc_err("CONFIG_MMC_AML_DEBUG is on!\n");
+#endif
+
+#ifdef CONFIG_AML_MMC_DEBUG_FORCE_SINGLE_BLOCK_RW
+	sdhc_err("CONFIG_AML_MMC_DEBUG_FORCE_SINGLE_BLOCK_RW is on!\n");
+#endif
+
+	host->debug.name =
+		kzalloc(strlen((const char *)AML_SDHC_MAGIC)+1, GFP_KERNEL);
+	strcpy((char *)(host->debug.name), (const char *)AML_SDHC_MAGIC);
+	host->debug.class_attrs = sdhc_class_attrs;
+	if (class_register(&host->debug))
+		pr_info(" class register nand_class fail!\n");
+
+	return host;
+}
+
+static int aml_sdhc_probe(struct platform_device *pdev)
+{
+	struct mmc_host *mmc = NULL;
+	struct amlsd_host *host = NULL;
+	struct amlsd_platform *pdata;
+	struct resource *res_mem;
+	/*	struct reset_control *sdhc_reset;*/
+	int size;
+	int ret = 0, i;
+	u32 gate_clk;
+
+	host = kzalloc(sizeof(struct amlsd_host), GFP_KERNEL);
+	if (!host)
+		return -ENODEV;
+
+	aml_mmc_ver_msg_show();
+
+	res_mem = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!res_mem) {
+		pr_info("error to get IORESOURCE\n");
+		goto fail_init_host;
+	}
+	size = resource_size(res_mem);
+
+	gate_clk = aml_read_cbus(HHI_GCLK_MPEG0);
+	gate_clk |= 0x4000;
+	aml_write_cbus(HHI_GCLK_MPEG0, gate_clk);
+
+	/*	sdhc_reset = devm_reset_control_get(&pdev->dev, "sdhc_gate");
+	 *	reset_control_deassert(sdhc_reset);
+	 */
+
+	host->irq = irq_of_parse_and_map(pdev->dev.of_node, 0);
+	pr_info("host->irq = %d\n", host->irq);
+
+	host->pinmux_base = ioremap(0xc1108000, 0x200);
+	host->base = devm_ioremap_nocache(&pdev->dev, res_mem->start, size);
+	aml_sdhc_init_host(host);
+
+	/* if(amlsd_get_reg_base(pdev, host))
+	 *   goto fail_init_host;
+	 */
+
+	host->pdev = pdev;
+	host->dev = &pdev->dev;
+	platform_set_drvdata(pdev, host);
+	aml_sdhc_reg_init(host);
+
+	/*	for (i = 0; i < MMC_MAX_DEVICE; i++) {*/
+	for (i = 0; i < 2; i++) {
+		/*malloc extra amlsd_platform*/
+		mmc = mmc_alloc_host(sizeof(struct amlsd_platform), &pdev->dev);
+		if (!mmc) {
+			ret = -ENOMEM;
+			goto probe_free_host;
+		}
+
+		pdata = mmc_priv(mmc);
+		memset(pdata, 0, sizeof(struct amlsd_platform));
+		if (amlsd_get_platform_data(pdev, pdata, mmc, i)) {
+			mmc_free_host(mmc);
+			break;
+		}
+
+#if 0
+		if (pdata->port == PORT_SDHC_C) {
+			if (is_emmc_exist(host)) {
+				mmc->is_emmc_port = 1;
+			} else { /* there is not eMMC/tsd */
+				pr_info(
+						"[%s]: there is not eMMC/tsd,skip sdhc_c dts config!\n",
+						__func__);
+
+				/* skip the port written in the dts */
+				i++;
+				memset(pdata, 0, sizeof(struct amlsd_platform));
+				if (amlsd_get_platform_data(pdev,
+							pdata, mmc, i)) {
+					mmc_free_host(mmc);
+					break;
+				}
+			}
+		}
+#endif
+
+		dev_set_name(&mmc->class_dev, "%s", pdata->pinname);
+		INIT_DELAYED_WORK(&pdata->retuning, aml_sdhc_tuning_timer);
+		if (pdata->caps & MMC_CAP_NONREMOVABLE)
+			pdata->is_in = true;
+
+		if (pdata->caps & MMC_PM_KEEP_POWER)
+			mmc->pm_caps |= MMC_PM_KEEP_POWER;
+		pdata->host = host;
+		pdata->mmc = mmc;
+		pdata->is_fir_init = true;
+		pdata->is_tuned = false;
+		pdata->need_retuning = false;
+		pdata->signal_voltage = 0xff;
+
+		/*mmc->index = i;*/
+		mmc->ops = &aml_sdhc_ops;
+		/*mmc->alldev_claim = &aml_sdhc_claim;*/
+		mmc->ios.clock = 400000;
+		mmc->ios.bus_width = MMC_BUS_WIDTH_1;
+		mmc->max_blk_count = 4095;
+		mmc->max_blk_size = 4095;
+		mmc->max_req_size = pdata->max_req_size;
+		mmc->max_seg_size = mmc->max_req_size;
+		mmc->max_segs = 1024;
+		mmc->ocr_avail = pdata->ocr_avail;
+		/*mmc->ocr = pdata->ocr_avail;*/
+		mmc->caps = pdata->caps;
+		mmc->caps2 = pdata->caps2;
+		mmc->f_min = pdata->f_min;
+		mmc->f_max = pdata->f_max;
+		mmc->max_current_180 = 300; /* 300 mA in 1.8V */
+		mmc->max_current_330 = 300; /* 300 mA in 3.3V */
+
+		if (aml_card_type_sdio(pdata)) /* if sdio_wifi */
+			mmc->rescan_entered = 1;
+		/* do NOT run mmc_rescan for the first time */
+		else
+			mmc->rescan_entered = 0;
+
+		if (pdata->port_init)
+			pdata->port_init(pdata);
+		/*	aml_sduart_pre(pdata);*/
+
+		ret = mmc_add_host(mmc);
+		if (ret) { /* error */
+			sdhc_err("Failed to add mmc host.\n");
+			goto probe_free_host;
+		} else { /* ok */
+			if (aml_card_type_sdio(pdata)) { /* if sdio_wifi */
+				sdio_host = mmc;
+				/* mmc->rescan_entered = 1; // do NOT
+				 *   run mmc_rescan for the first time
+				 */
+			}
+		}
+
+		/*aml_sdhc_init_debugfs(mmc);*/
+		/*Add each mmc host pdata to this controller host list*/
+		INIT_LIST_HEAD(&pdata->sibling);
+		list_add_tail(&pdata->sibling, &host->sibling);
+
+		/*Register card detect irq : plug in & unplug*/
+		if (pdata->gpio_cd
+				&& aml_card_type_non_sdio(pdata)) {
+			pdata->irq_init(pdata);
+			mutex_init(&pdata->in_out_lock);
+			ret = request_threaded_irq(pdata->irq_cd,
+					aml_sd_irq_cd, aml_irq_cd_thread,
+					IRQF_TRIGGER_RISING
+					| IRQF_TRIGGER_FALLING
+					| IRQF_ONESHOT,
+					"sdhc_mmc_cd", pdata);
+			if (ret) {
+				sd_emmc_err("Failed to request SD IN detect\n");
+				goto probe_free_host;
+			}
+		}
+	}
+
+	print_tmp("%s() success!\n", __func__);
+	return 0;
+
+probe_free_host:
+	list_for_each_entry(pdata, &host->sibling, sibling) {
+		mmc = pdata->mmc;
+		mmc_remove_host(mmc);
+		mmc_free_host(mmc);
+	}
+fail_init_host:
+	iounmap(host->base);
+	free_irq(host->irq, host);
+	dma_free_coherent(NULL, SDHC_BOUNCE_REQ_SIZE, host->bn_buf,
+			(dma_addr_t)host->bn_dma_buf);
+	kfree(host);
+	print_tmp("aml_sdhc_probe() fail!\n");
+	return ret;
+}
+
+int aml_sdhc_remove(struct platform_device *pdev)
+{
+	struct amlsd_host *host  = platform_get_drvdata(pdev);
+	struct mmc_host *mmc;
+	struct amlsd_platform *pdata;
+
+	dma_free_coherent(NULL, SDHC_BOUNCE_REQ_SIZE, host->bn_buf,
+			(dma_addr_t)host->bn_dma_buf);
+
+	free_irq(host->irq, host);
+	iounmap(host->base);
+
+	list_for_each_entry(pdata, &host->sibling, sibling) {
+		mmc = pdata->mmc;
+		mmc_remove_host(mmc);
+		mmc_free_host(mmc);
+	}
+	/*	aml_devm_pinctrl_put(host);*/
+
+	kfree(host->msg_buf);
+	kfree(host);
+
+	/* switch_mod_gate_by_type(MOD_SDHC, 0); // gate clock of SDHC */
+	return 0;
+}
+
+static const struct of_device_id aml_sdhc_dt_match[] = {
+	{
+		.compatible = "amlogic, aml_sdhc",
+	},
+	{},
+};
+MODULE_DEVICE_TABLE(of, aml_sdhc_dt_match);
+
+static struct platform_driver aml_sdhc_driver = {
+	.probe		 = aml_sdhc_probe,
+	.remove		= aml_sdhc_remove,
+	.suspend	= aml_sdhc_suspend,
+	.resume		= aml_sdhc_resume,
+	.driver		= {
+		.name = "aml_sdhc",
+		.owner = THIS_MODULE,
+		.of_match_table = aml_sdhc_dt_match,
+	},
+};
+
+static int __init aml_sdhc_init(void)
+{
+	return platform_driver_register(&aml_sdhc_driver);
+}
+
+static void __exit aml_sdhc_cleanup(void)
+{
+	platform_driver_unregister(&aml_sdhc_driver);
+}
+
+module_init(aml_sdhc_init);
+module_exit(aml_sdhc_cleanup);
+
+MODULE_DESCRIPTION("Amlogic Multimedia Card driver");
+MODULE_LICENSE("GPL");
+
+static int __init rx_clk_phase_setup(char *str)
+{
+	int ret;
+
+	ret = kstrtol(str, 0, (long *)&rx_clk_phase_set);
+	print_dbg("rx_clk_phase=%d\n", rx_clk_phase_set);
+	return ret;
+}
+__setup("rx_clk_phase=", rx_clk_phase_setup);
+
+static int __init sd_clk_phase_setup(char *str)
+{
+	int ret;
+
+	ret = kstrtol(str, 0, (long *)&sd_clk_phase_set);
+	print_dbg("sd_clk_phase_set=%d\n", sd_clk_phase_set);
+	return ret;
+}
+__setup("sd_clk_phase=", sd_clk_phase_setup);
+
+static int __init rx_endian_setup(char *str)
+{
+	int ret;
+
+	ret = kstrtol(str, 0, (long *)&rx_endian);
+	print_dbg("rx_endian=%#x\n", rx_endian);
+	return ret;
+}
+__setup("rx_endian=", rx_endian_setup);
+
+static int __init tx_endian_setup(char *str)
+{
+	int ret;
+
+	ret = kstrtol(str, 0, (long *)&tx_endian);
+	print_dbg("tx_endian=%#x\n", tx_endian);
+	return ret;
+}
+__setup("tx_endian=", tx_endian_setup);
+
+static int __init val1_setup(char *str)
+{
+	int ret;
+
+	ret = kstrtol(str, 0, (long *)&val1);
+	print_dbg("val1=%d\n", val1);
+	return ret;
+}
+__setup("val1=", val1_setup);
diff --git a/drivers/amlogic/mmc/aml_sdio.c b/drivers/amlogic/mmc/aml_sdio.c
new file mode 100644
index 0000000..59d9fc8
--- /dev/null
+++ b/drivers/amlogic/mmc/aml_sdio.c
@@ -0,0 +1,1367 @@
+/*
+ * drivers/amlogic/mmc/aml_sdio.c
+ *
+ * Copyright (C) 2017 Amlogic, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/debugfs.h>
+#include <linux/interrupt.h>
+#include <linux/delay.h>
+#include <linux/dma-mapping.h>
+#include <linux/platform_device.h>
+#include <linux/timer.h>
+#include <linux/clk.h>
+#include <linux/clk-provider.h>
+#include <linux/mmc/host.h>
+#include <linux/io.h>
+#include <linux/of_irq.h>
+#include <linux/mmc/mmc.h>
+#include <linux/mmc/sd.h>
+#include <linux/mmc/sdio.h>
+#include <linux/highmem.h>
+#include <linux/slab.h>
+#include <linux/dma-mapping.h>
+#include <linux/amlogic/iomap.h>
+#include <linux/amlogic/cpu_version.h>
+#include <linux/irq.h>
+#include <linux/amlogic/sd.h>
+#include <linux/amlogic/amlsd.h>
+#include <linux/mmc/emmc_partitions.h>
+#include <linux/amlogic/gpio-amlogic.h>
+
+/* static struct mmc_claim aml_sdio_claim; */
+#define	 sdio_cmd_busy_bit 4
+int CMD_PROCESS_JIT;
+int SDIO_IRQ_SUPPORT;
+static void aml_sdio_send_stop(struct amlsd_host *host);
+static unsigned int sdio_error_flag;
+static unsigned int sdio_debug_flag;
+static unsigned int sdio_err_bak;
+static unsigned int timeout_cmd_cnt;
+
+void sdio_debug_irqstatus(struct sdio_status_irq *irqs, struct cmd_send *send)
+{
+	switch (sdio_debug_flag) {
+	case 1:
+		irqs->sdio_response_crc7_ok = 0;
+		send->response_do_not_have_crc7 = 0;
+		sdhc_err("Force sdio cmd response crc error here\n");
+		break;
+	case 2:
+		irqs->sdio_data_read_crc16_ok = 0;
+		irqs->sdio_data_write_crc16_ok = 0;
+		sdhc_err("Force sdio data crc here\n");
+		break;
+	default:
+		break;
+	}
+	/* only enable once for debug */
+	sdio_debug_flag = 0;
+}
+
+static void aml_sdio_soft_reset(struct amlsd_host *host)
+{
+	struct sdio_irq_config irqc = {0};
+
+	/*soft reset*/
+	irqc.soft_reset = 1;
+	writel(*(u32 *)&irqc, host->base + SDIO_IRQC);
+	udelay(2);
+}
+
+static int aml_sdio_clktree_init(struct amlsd_host *host)
+{
+	int ret = 0;
+
+	host->core_clk = devm_clk_get(host->dev, "core");
+	if (IS_ERR(host->core_clk)) {
+		ret = PTR_ERR(host->core_clk);
+		pr_err("devm_clk_get core_clk fail %d\n", ret);
+		return ret;
+	}
+	ret = clk_prepare_enable(host->core_clk);
+	if (ret) {
+		pr_err("clk_prepare_enable core_clk fail %d\n", ret);
+		return ret;
+	}
+
+	pr_info("aml_sdio_clktree_init ok\n");
+	return 0;
+}
+
+/*
+ * init sdio reg
+ */
+static void aml_sdio_init_param(struct amlsd_host *host)
+{
+	struct sdio_status_irq irqs = {0};
+	struct sdio_config conf = {0};
+
+	aml_sdio_clktree_init(host);
+
+	/* write 1 clear bit8,9 */
+	irqs.sdio_if_int = 1;
+	irqs.sdio_cmd_int = 1;
+	writel(*(u32 *)&irqs, host->base + SDIO_IRQS);
+
+	/* setup config */
+	conf.sdio_write_crc_ok_status = 2;
+	conf.sdio_write_nwr = 2;
+	conf.m_endian = 3;
+	conf.cmd_argument_bits = 39;
+	conf.cmd_out_at_posedge = 0;
+	conf.cmd_disable_crc = 0;
+	conf.data_latch_at_negedge = 0;
+	conf.cmd_clk_divide = CLK_DIV;
+	writel(*(u32 *)&conf, host->base + SDIO_CONF);
+}
+
+static bool is_card_last_block(struct amlsd_platform *pdata, u32 lba, u32 cnt)
+{
+	if (!pdata->card_capacity)
+		pdata->card_capacity = mmc_capacity(pdata->mmc->card);
+
+	return (lba + cnt) == pdata->card_capacity;
+}
+
+/*
+ * read response from REG0_ARGU(136bit or 48bit)
+ */
+void aml_sdio_read_response(struct amlsd_platform *pdata,
+		struct mmc_request *mrq)
+{
+	int i, resp[4];
+	struct amlsd_host *host = pdata->host;
+	u32 vmult = readl(host->base + SDIO_MULT);
+	struct sdio_mult_config *mult = (void *)&vmult;
+	struct mmc_command *cmd = mrq->cmd;
+
+	mult->write_read_out_index = 1;
+	mult->response_read_index = 0;
+	writel(vmult, host->base + SDIO_MULT);
+
+	if (cmd->flags & MMC_RSP_136) {
+		for (i = 0; i <= 3; i++)
+			resp[3-i] = readl(host->base + SDIO_ARGU);
+		cmd->resp[0] = (resp[0]<<8)|((resp[1]>>24)&0xff);
+		cmd->resp[1] = (resp[1]<<8)|((resp[2]>>24)&0xff);
+		cmd->resp[2] = (resp[2]<<8)|((resp[3]>>24)&0xff);
+		cmd->resp[3] = (resp[3]<<8);
+		sdio_dbg(AMLSD_DBG_RESP, "Cmd %d ,Resp %x-%x-%x-%x\n",
+				cmd->opcode, cmd->resp[0], cmd->resp[1],
+				cmd->resp[2], cmd->resp[3]);
+	} else if (cmd->flags & MMC_RSP_PRESENT) {
+		cmd->resp[0] = readl(host->base + SDIO_ARGU);
+		sdio_dbg(AMLSD_DBG_RESP, "Cmd %d, Resp 0x%x\n",
+				cmd->opcode, cmd->resp[0]);
+
+		/* Now in sdio controller, something is wrong.
+		 * When we read last block in multi-blocks-mode,
+		 * it will cause "ADDRESS_OUT_OF_RANGE" error in
+		 * card status, we must clear it.
+		 */
+		/* status error: address out of range */
+		if ((cmd->resp[0] & R1_OUT_OF_RANGE)
+				&& (mrq->data) &&
+				(is_card_last_block(pdata, cmd->arg,
+					mrq->data->blocks))) {
+			cmd->resp[0] &= (~R1_OUT_OF_RANGE);
+			/* clear the error */
+		}
+	}
+}
+
+/*copy buffer from data->sg to dma buffer, set dma addr to reg*/
+void aml_sdio_prepare_dma(struct amlsd_host *host, struct mmc_request *mrq)
+{
+	struct mmc_data *data = mrq->data;
+
+	if (data->flags & MMC_DATA_WRITE) {
+		aml_sg_copy_buffer(data->sg, data->sg_len,
+				host->bn_buf, data->blksz*data->blocks, 1);
+		sdio_dbg(AMLSD_DBG_WR_DATA, "W Cmd %d, %x-%x-%x-%x\n",
+				mrq->cmd->opcode,
+				host->bn_buf[0], host->bn_buf[1],
+				host->bn_buf[2], host->bn_buf[3]);
+	}
+	/* host->dma_addr = host->bn_dma_buf; */
+}
+
+void aml_sdio_set_port_ios(struct mmc_host *mmc)
+{
+	struct amlsd_platform *pdata = mmc_priv(mmc);
+	struct amlsd_host *host = pdata->host;
+	u32 vconf = readl(host->base + SDIO_CONF);
+	struct sdio_config *conf = (void *)&vconf;
+
+	if (aml_card_type_sdio(pdata)
+			&& (pdata->mmc->actual_clock > 50000000)) {
+		/* if > 50MHz */
+		conf->data_latch_at_negedge = 1; /* [19] //0 */
+		conf->do_not_delay_data = 1; /* [18] */
+		conf->cmd_out_at_posedge = 0;
+	} else {
+		conf->data_latch_at_negedge = 0; /* [19] //0 */
+		conf->do_not_delay_data = 0; /* [18] */
+		conf->cmd_out_at_posedge = 0;
+	}
+	writel(vconf, host->base+SDIO_CONF);
+	if ((conf->cmd_clk_divide == pdata->clkc)
+			&& (conf->bus_width == pdata->width))
+		return;
+
+	/*Setup Clock*/
+	conf->cmd_clk_divide = pdata->clkc;
+	/*Setup Bus Width*/
+	conf->bus_width = pdata->width;
+	writel(vconf, host->base+SDIO_CONF);
+}
+
+static void aml_sdio_enable_irq(struct mmc_host *mmc, int enable)
+{
+	struct amlsd_platform *pdata = mmc_priv(mmc);
+	struct amlsd_host *host = pdata->host;
+	u32 virqc;
+	struct sdio_irq_config *irqc;
+	u32 virqs;
+	struct sdio_status_irq *irqs;
+	u32 vmult;
+	struct sdio_mult_config *mult;
+	unsigned long flags;
+
+	if (host->xfer_step == XFER_START
+			|| host->xfer_step == XFER_AFTER_START) {
+		return;
+
+	}
+	if (enable) {
+		spin_lock_irqsave(&host->mrq_lock, flags);
+		if (host->xfer_step == XFER_START
+				|| host->xfer_step == XFER_AFTER_START) {
+			/* pr_info("cmd irq is running
+			 * when aml_sdio_enable_irq()
+			 * enable = %d\n", enable);
+			 */
+			/* pr_info("irqs->sdio_cmd_int = %d\n",
+			 * irqs->sdio_cmd_int );
+			 */
+			spin_unlock_irqrestore(&host->mrq_lock, flags);
+			return;
+		}
+		virqc = readl(host->base + SDIO_IRQC);
+		irqc = (void *)&virqc;
+		virqs = readl(host->base + SDIO_IRQS);
+		irqs = (void *)&virqs;
+		vmult = readl(host->base + SDIO_MULT);
+		mult = (void *)&vmult;
+
+		/* u32 vmult = readl(host->base + SDIO_MULT); */
+		/* struct sdio_mult_config* mult = (void*)&vmult; */
+
+		/* enable if int irq */
+		irqc->arc_if_int_en = 1;
+		irqs->sdio_if_int = 1;
+
+		mult->sdio_port_sel = pdata->port;
+		writel(vmult, host->base + SDIO_MULT);
+		writel(virqs, host->base + SDIO_IRQS);
+		writel(virqc, host->base + SDIO_IRQC);
+		spin_unlock_irqrestore(&host->mrq_lock, flags);
+	} else {
+
+		virqc = readl(host->base + SDIO_IRQC);
+		irqc = (void *)&virqc;
+		virqs = readl(host->base + SDIO_IRQS);
+
+		irqs = (void *)&virqs;
+		vmult = readl(host->base + SDIO_MULT);
+		mult = (void *)&vmult;
+
+		irqc->arc_if_int_en = 0;
+		irqs->sdio_if_int = 1;
+
+		mult->sdio_port_sel = pdata->port;
+		writel(vmult, host->base + SDIO_MULT);
+
+		writel(virqs, host->base + SDIO_IRQS);
+		writel(virqc, host->base + SDIO_IRQC);
+	}
+}
+
+/*set to register, start xfer*/
+void aml_sdio_start_cmd(struct mmc_host *mmc, struct mmc_request *mrq)
+{
+	u32 pack_size;
+	struct amlsd_platform *pdata = mmc_priv(mmc);
+	struct amlsd_host *host = pdata->host;
+	struct cmd_send send = {0};
+	struct sdio_extension ext = {0};
+	u32 virqc = readl(host->base + SDIO_IRQC);
+	struct sdio_irq_config *irqc = (void *)&virqc;
+	u32 virqs = readl(host->base + SDIO_IRQS);
+	struct sdio_status_irq *irqs = (void *)&virqs;
+	u32 vmult = readl(host->base + SDIO_MULT);
+	struct sdio_mult_config *mult = (void *)&vmult;
+
+	switch (mmc_resp_type(mrq->cmd)) {
+	case MMC_RSP_R1:
+	case MMC_RSP_R1B:
+	case MMC_RSP_R3:
+		/*7(cmd)+32(respnse)+7(crc)-1 data*/
+		send.cmd_response_bits = 45;
+		break;
+	case MMC_RSP_R2:
+		/* 7(cmd)+120(respnse)+7(crc)-1 data */
+		send.cmd_response_bits = 133;
+		send.response_crc7_from_8 = 1;
+		break;
+	default:
+		/*no response*/
+		break;
+	}
+
+	if (!(mrq->cmd->flags & MMC_RSP_CRC))
+		send.response_do_not_have_crc7 = 1;
+
+	if (mrq->cmd->flags & MMC_RSP_BUSY)
+		send.check_busy_on_dat0 = 1;
+
+	/* clear here */
+	timeout_cmd_cnt = 0;
+
+	if (mrq->data) {
+		/*total package num*/
+		send.repeat_package_times = mrq->data->blocks - 1;
+		WARN_ON(mrq->data->blocks > 256);
+		/*package size*/
+		if (pdata->width) /*0: 1bit, 1: 4bit*/
+			pack_size = mrq->data->blksz*8 + (16-1)*4;
+		else
+			pack_size = mrq->data->blksz*8 + (16-1);
+		ext.data_rw_number = pack_size;
+		if (mrq->data->flags & MMC_DATA_WRITE)
+			send.cmd_send_data = 1;
+		else
+			send.response_have_data = 1;
+	}
+	/*cmd index*/
+	send.cmd_command = 0x40|mrq->cmd->opcode;
+
+	aml_sdio_soft_reset(host);
+
+	/*enable cmd irq*/
+	irqc->arc_cmd_int_en = 1;
+
+	/*clear pending*/
+	irqs->sdio_cmd_int = 1;
+
+	aml_sdio_set_port_ios(host->mmc);
+
+	mult->sdio_port_sel = pdata->port;
+	vmult |= (1<<31);
+	writel(vmult, host->base + SDIO_MULT);
+	writel(virqs, host->base + SDIO_IRQS);
+	writel(virqc, host->base + SDIO_IRQC);
+	/* setup all reg to send cmd */
+	writel(mrq->cmd->arg, host->base + SDIO_ARGU);
+	writel(*(u32 *)&ext, host->base + SDIO_EXT);
+	writel(*(u32 *)&send, host->base + SDIO_SEND);
+}
+
+/*
+ * clear struct & call mmc_request_done
+ */
+void aml_sdio_request_done(struct mmc_host *mmc, struct mmc_request *mrq)
+{
+	struct amlsd_platform *pdata = mmc_priv(mmc);
+	struct amlsd_host *host = pdata->host;
+	unsigned long flags;
+	struct mmc_command *cmd;
+
+	if (delayed_work_pending(&host->timeout))
+		cancel_delayed_work_sync(&host->timeout);
+
+	spin_lock_irqsave(&host->mrq_lock, flags);
+	WARN_ON(!host->mrq->cmd);
+	WARN_ON(host->xfer_step == XFER_FINISHED);
+	aml_sdio_read_response(pdata, host->mrq);
+
+	cmd = host->mrq->cmd; /* for debug */
+	host->mrq = NULL;
+	host->xfer_step = XFER_FINISHED;
+	spin_unlock_irqrestore(&host->mrq_lock, flags);
+
+	if (cmd->flags & MMC_RSP_136) {
+		sdio_dbg(AMLSD_DBG_RESP, "Cmd %d ,Resp %x-%x-%x-%x\n",
+				cmd->opcode, cmd->resp[0], cmd->resp[1],
+				cmd->resp[2], cmd->resp[3]);
+	} else if (cmd->flags & MMC_RSP_PRESENT) {
+		sdio_dbg(AMLSD_DBG_RESP, "Cmd %d ,Resp 0x%x\n",
+				cmd->opcode, cmd->resp[0]);
+	}
+
+#ifdef CONFIG_MMC_AML_DEBUG
+	host->req_cnt--;
+
+	aml_dbg_verify_pinmux(pdata);
+	aml_dbg_verify_pull_up(pdata);
+#endif
+
+	if (pdata->xfer_post)
+		pdata->xfer_post(mmc);
+
+	mmc_request_done(host->mmc, mrq);
+}
+
+static void aml_sdio_print_err(struct amlsd_host *host, char *msg)
+{
+	struct amlsd_platform *pdata = mmc_priv(host->mmc);
+	u32 virqs = readl(host->base + SDIO_IRQS);
+	u32 virqc = readl(host->base + SDIO_IRQC);
+	u32 vconf = readl(host->base + SDIO_CONF);
+	struct sdio_config *conf = (void *)&vconf;
+	u32 clk_rate = clk_get_rate(host->core_clk) / 2;
+
+	sdio_err("%s: %s,", mmc_hostname(host->mmc), msg);
+	pr_info("Cmd%d arg %#x,", host->mrq->cmd->opcode, host->mrq->cmd->arg);
+	pr_info("Xfer %d Bytes,", host->mrq->data?host->mrq->data->blksz
+			*host->mrq->data->blocks:0);
+	pr_info("host->xfer_step=%d,", host->xfer_step);
+	pr_info("host->cmd_is_stop=%d,", host->cmd_is_stop);
+	pr_info("pdata->port=%d,", pdata->port);
+	pr_info("virqs=%#0x, virqc=%#0x,", virqs, virqc);
+	pr_info("conf->cmd_clk_divide=%d,", conf->cmd_clk_divide);
+	pr_info("pdata->clkc=%d,", pdata->clkc);
+	pr_info("conf->bus_width=%d,", conf->bus_width);
+	pr_info("pdata->width=%d,", pdata->width);
+	pr_info("conf=%#x, clock=%d\n", vconf,
+			clk_rate / (conf->cmd_clk_divide + 1));
+}
+
+/*setup delayed workstruct in aml_sdio_request*/
+static void aml_sdio_timeout(struct work_struct *work)
+{
+	static int timeout_cnt;
+	struct amlsd_host *host =
+		container_of(work, struct amlsd_host, timeout.work);
+	u32 virqs;
+	struct sdio_status_irq *irqs;
+	u32 virqc;
+	struct sdio_irq_config *irqc;
+	unsigned long flags;
+	struct amlsd_platform *pdata = mmc_priv(host->mmc);
+	int is_mmc_stop = 0;
+	unsigned long time_start_cnt = aml_read_cbus(ISA_TIMERE);
+
+
+	time_start_cnt = (time_start_cnt - host->time_req_sta) / 1000;
+
+	virqs = readl(host->base + SDIO_IRQS);
+	irqs = (void *)&virqs;
+	virqc = readl(host->base + SDIO_IRQC);
+	irqc = (void *)&virqc;
+
+	spin_lock_irqsave(&host->mrq_lock, flags);
+	if (host->xfer_step == XFER_FINISHED) {
+		spin_unlock_irqrestore(&host->mrq_lock, flags);
+		sdio_err("timeout after xfer finished\n");
+		return;
+	}
+	if ((irqs->sdio_cmd_int) /* irq have been occurred */
+			|| (host->xfer_step == XFER_IRQ_OCCUR)) {
+		/* isr have been run */
+		spin_unlock_irqrestore(&host->mrq_lock, flags);
+		schedule_delayed_work(&host->timeout, msecs_to_jiffies(500));
+		host->time_req_sta = aml_read_cbus(ISA_TIMERE);
+
+		if (irqs->sdio_cmd_int) {
+			timeout_cnt++;
+			if (timeout_cnt > 30)
+				goto timeout_handle;
+			sdio_err("%s: cmd%d,", mmc_hostname(host->mmc),
+					host->mrq->cmd->opcode);
+			pr_info("ISR have been run,");
+			pr_info("xfer_step=%d,", host->xfer_step);
+			pr_info("time_start_cnt=%ldmS,", time_start_cnt);
+			pr_info("timeout_cnt=%d\n", timeout_cnt);
+		} else
+			sdio_err("%s: isr have been run\n",
+					mmc_hostname(host->mmc));
+		return;
+	}
+	spin_unlock_irqrestore(&host->mrq_lock, flags);
+timeout_handle:
+	timeout_cnt = 0;
+
+	if (!(irqc->arc_cmd_int_en)) {
+		sdio_err("%s: arc_cmd_int_en is not enable\n",
+				mmc_hostname(host->mmc));
+	}
+
+	/* Disable Command-Done-Interrupt to avoid irq occurs
+	 * It will be enabled again in the next cmd.
+	 */
+	irqc->arc_cmd_int_en = 0;   /* disable cmd irq */
+	writel(virqc, host->base + SDIO_IRQC);
+
+	spin_lock_irqsave(&host->mrq_lock, flags);
+
+	/* do not retry for sdcard */
+	if (!aml_card_type_mmc(pdata)) {
+		sdio_error_flag |= (1<<30);
+		host->mrq->cmd->retries = 0;
+	} else if (((sdio_error_flag & (1<<3)) == 0)
+			&& (host->mrq->data != NULL)
+			&& pdata->is_in) {
+		/* set cmd retry cnt when first error. */
+		sdio_error_flag |= (1<<3);
+		host->mrq->cmd->retries = AML_TIMEOUT_RETRY_COUNTER;
+	}
+
+	/* here clear error flags after error retried */
+	if (sdio_error_flag && (host->mrq->cmd->retries == 0))
+		sdio_error_flag |= (1<<30);
+
+	host->xfer_step = XFER_TIMEDOUT;
+	host->mrq->cmd->error = -ETIMEDOUT;
+	spin_unlock_irqrestore(&host->mrq_lock, flags);
+
+	sdio_err("time_start_cnt:%ld\n", time_start_cnt);
+	aml_sdio_print_err(host, "Timeout error");
+
+#ifdef CONFIG_MMC_AML_DEBUG
+	aml_dbg_verify_pinmux(pdata);
+	aml_dbg_verify_pull_up(pdata);
+	aml_sdio_print_reg(host);
+	/* aml_dbg_print_pinmux(); */
+#endif
+
+	if (host->mrq->stop && aml_card_type_mmc(pdata) && !host->cmd_is_stop) {
+		/* sdio_err("Send stop cmd before timeout retry..\n"); */
+		spin_lock_irqsave(&host->mrq_lock, flags);
+		aml_sdio_send_stop(host);
+		spin_unlock_irqrestore(&host->mrq_lock, flags);
+		is_mmc_stop = 1;
+		schedule_delayed_work(&host->timeout, 50);
+	} else {
+		if (host->cmd_is_stop)
+			host->cmd_is_stop = 0;
+		aml_sdio_request_done(host->mmc, host->mrq);
+	}
+}
+
+/*
+ * aml handle request
+ * 1. setup data
+ * 2. send cmd
+ * 3. return (aml_sdio_request_done in irq function)
+ */
+void aml_sdio_request(struct mmc_host *mmc, struct mmc_request *mrq)
+{
+	struct amlsd_platform *pdata;
+	struct amlsd_host *host;
+	unsigned long flags;
+	unsigned int timeout;
+	u32 virqc;
+	struct sdio_irq_config *irqc;
+
+	WARN_ON(!mmc);
+	WARN_ON(!mrq);
+
+	pdata = mmc_priv(mmc);
+	host = (void *)pdata->host;
+
+	virqc = readl(host->base + SDIO_IRQC);
+	irqc = (void *)&virqc;
+
+	if (aml_card_type_non_sdio(pdata)) {
+		irqc->arc_if_int_en = 0;
+		writel(virqc, host->base + SDIO_IRQC);
+	}
+
+	if (aml_check_unsupport_cmd(mmc, mrq))
+		return;
+
+	/* only for SDCARD hotplag */
+	if ((!pdata->is_in
+				|| (!host->init_flag
+					&& aml_card_type_non_sdio(pdata)))
+			&& (mrq->cmd->opcode != 0)) {
+		spin_lock_irqsave(&host->mrq_lock, flags);
+		mrq->cmd->error = -ENOMEDIUM;
+		mrq->cmd->retries = 0;
+		host->mrq = NULL;
+		host->xfer_step = XFER_FINISHED;
+		spin_unlock_irqrestore(&host->mrq_lock, flags);
+
+		mmc_request_done(mmc, mrq);
+		return;
+	}
+
+#ifdef CONFIG_MMC_AML_DEBUG
+	if (host->req_cnt)
+		sdio_err("Reentry error! host->req_cnt=%d\n", host->req_cnt);
+	host->req_cnt++;
+#endif
+
+	if (mrq->cmd->opcode == 0)
+		host->init_flag = 1;
+
+	sdio_dbg(AMLSD_DBG_REQ, "%s: starting CMD%u arg %08x flags %08x\n",
+			mmc_hostname(mmc), mrq->cmd->opcode,
+			mrq->cmd->arg, mrq->cmd->flags);
+	if (mrq->data) {
+		/*Copy data to dma buffer for write request*/
+		aml_sdio_prepare_dma(host, mrq);
+		writel(host->bn_dma_buf, host->base + SDIO_ADDR);
+		sdio_dbg(AMLSD_DBG_REQ,
+				"%s: blksz %d blocks %d flags %08x tsac %d ms nsac %d\n",
+				mmc_hostname(mmc), mrq->data->blksz,
+				mrq->data->blocks, mrq->data->flags,
+				mrq->data->timeout_ns / 1000000,
+				mrq->data->timeout_clks);
+	}
+
+	/*clear pinmux & set pinmux*/
+	if (pdata->xfer_pre)
+		pdata->xfer_pre(mmc);
+
+#ifdef CONFIG_MMC_AML_DEBUG
+	aml_dbg_verify_pull_up(pdata);
+	aml_dbg_verify_pinmux(pdata);
+#endif
+
+	if (!mrq->data)
+		timeout = 1000;
+	else
+		timeout = 5000;
+	/* 5s */
+	if (mrq->cmd->opcode == MMC_ERASE) /* maybe over 30S for erase cmd. */
+		timeout = 30000;
+
+	schedule_delayed_work(&host->timeout, msecs_to_jiffies(timeout));
+
+	CMD_PROCESS_JIT = timeout;
+	spin_lock_irqsave(&host->mrq_lock, flags);
+	if (SDIO_IRQ_SUPPORT)
+		if ((mmc->caps & MMC_CAP_SDIO_IRQ)
+				&& (mmc->ops->enable_sdio_irq))
+			mmc->ops->enable_sdio_irq(mmc, 0);
+
+	if (host->xfer_step != XFER_FINISHED
+			&& host->xfer_step != XFER_INIT)
+		sdio_err("host->xfer_step %d\n", host->xfer_step);
+
+	/* clear error flag if last command retried failed here */
+	if (sdio_error_flag & (1<<30))
+		sdio_error_flag = 0;
+
+	host->mrq = mrq;
+	host->mmc = mmc;
+	host->xfer_step = XFER_START;
+	host->opcode = mrq->cmd->opcode;
+	host->arg = mrq->cmd->arg;
+	host->time_req_sta = aml_read_cbus(ISA_TIMERE);
+
+	aml_sdio_start_cmd(mmc, mrq);
+	host->xfer_step = XFER_AFTER_START;
+	spin_unlock_irqrestore(&host->mrq_lock, flags);
+}
+
+struct mmc_command aml_sdio_cmd = {
+	.opcode = MMC_STOP_TRANSMISSION,
+	.flags = MMC_RSP_SPI_R1B | MMC_RSP_R1B | MMC_CMD_AC,
+};
+struct mmc_request aml_sdio_stop = {
+	.cmd = &aml_sdio_cmd,
+};
+
+static void aml_sdio_send_stop(struct amlsd_host *host)
+{
+	/*Already in mrq_lock*/
+	host->cmd_is_stop = 1;
+	sdio_err_bak = host->mrq->cmd->error;
+	host->mrq->cmd->error = 0;
+	aml_sdio_start_cmd(host->mmc, &aml_sdio_stop);
+}
+
+/*
+ * enable cmd & data irq, call tasket, do aml_sdio_request_done
+ */
+static irqreturn_t aml_sdio_irq(int irq, void *dev_id)
+{
+	struct amlsd_host *host = (void *)dev_id;
+	u32 virqs = readl(host->base + SDIO_IRQS);
+	struct sdio_status_irq *irqs = (void *)&virqs;
+	struct mmc_request *mrq;
+	unsigned long flags;
+	int sdio_cmd_int = 0;
+
+	spin_lock_irqsave(&host->mrq_lock, flags);
+	mrq = host->mrq;
+	if (!mrq && !irqs->sdio_if_int) {
+
+		if (host->xfer_step == XFER_FINISHED ||
+				host->xfer_step == XFER_TIMEDOUT){
+			spin_unlock_irqrestore(&host->mrq_lock, flags);
+			return IRQ_HANDLED;
+		}
+		WARN_ON(!mrq);
+		/*	aml_sdio_print_reg(host);*/
+		spin_unlock_irqrestore(&host->mrq_lock, flags);
+		return IRQ_HANDLED;
+	}
+
+	if (irqs->sdio_cmd_int  && mrq) {
+		if (host->cmd_is_stop)
+			host->xfer_step = XFER_IRQ_TASKLET_BUSY;
+		else
+			host->xfer_step = XFER_IRQ_OCCUR;
+		spin_unlock_irqrestore(&host->mrq_lock, flags);
+		if ((SDIO_IRQ_SUPPORT)
+				&& !(irqs->sdio_if_int)
+				&& (host->mmc->sdio_irq_pending != true))
+			host->mmc->ops->enable_sdio_irq(host->mmc, 1);
+		if (irqs->sdio_if_int && SDIO_IRQ_SUPPORT)
+			sdio_cmd_int = 1;
+		else
+			return IRQ_WAKE_THREAD;
+	} else
+		spin_unlock_irqrestore(&host->mrq_lock, flags);
+
+	if (irqs->sdio_if_int) {
+		if ((host->mmc->sdio_irq_thread)
+			&& (!atomic_read(&host->mmc->sdio_irq_thread_abort)))
+			mmc_signal_sdio_irq(host->mmc);
+	}
+
+	if (SDIO_IRQ_SUPPORT && sdio_cmd_int)
+		return IRQ_WAKE_THREAD;
+
+	/* if cmd has stop, call aml_sdio_send_stop */
+	return IRQ_HANDLED;
+}
+
+irqreturn_t aml_sdio_irq_thread(int irq, void *data)
+{
+	struct amlsd_host *host = (void *)data;
+	u32 virqs = readl(host->base + SDIO_IRQS);
+	struct sdio_status_irq *irqs = (void *)&virqs;
+	u32 vsend = readl(host->base + SDIO_SEND);
+	struct cmd_send *send = (void *)&vsend;
+	unsigned long flags;
+	struct mmc_request *mrq;
+	enum aml_mmc_waitfor	xfer_step;
+	struct amlsd_platform *pdata = mmc_priv(host->mmc);
+
+	spin_lock_irqsave(&host->mrq_lock, flags);
+	mrq = host->mrq;
+	xfer_step = host->xfer_step;
+
+	if ((xfer_step == XFER_FINISHED) || (xfer_step == XFER_TIMER_TIMEOUT)) {
+		sdhc_err("Warning: xfer_step=%d\n", xfer_step);
+		spin_unlock_irqrestore(&host->mrq_lock, flags);
+		return IRQ_HANDLED;
+	}
+
+	if (!mrq) {
+		sdio_err("CMD%u, arg %08x, mrq NULL xfer_step %d\n",
+				host->opcode, host->arg, xfer_step);
+		if (xfer_step == XFER_FINISHED ||
+				xfer_step == XFER_TIMEDOUT){
+			spin_unlock_irqrestore(&host->mrq_lock, flags);
+			sdio_err("[aml_sdio_irq_thread] out\n");
+			return IRQ_HANDLED;
+		}
+		spin_unlock_irqrestore(&host->mrq_lock, flags);
+		return IRQ_HANDLED;
+	}
+
+	if ((SDIO_IRQ_SUPPORT)
+			&& (host->xfer_step == XFER_TASKLET_DATA)) {
+		spin_unlock_irqrestore(&host->mrq_lock, flags);
+		return IRQ_HANDLED;
+	}
+
+	if (host->cmd_is_stop) {
+		host->cmd_is_stop = 0;
+		mrq->cmd->error = sdio_err_bak;
+		spin_unlock_irqrestore(&host->mrq_lock, flags);
+		aml_sdio_request_done(host->mmc, mrq);
+		return IRQ_HANDLED;
+	}
+	host->xfer_step = XFER_TASKLET_DATA;
+
+	if (!mrq->data) {
+		if (irqs->sdio_response_crc7_ok
+				|| send->response_do_not_have_crc7) {
+			mrq->cmd->error = 0;
+			spin_unlock_irqrestore(&host->mrq_lock, flags);
+		} else {
+			mrq->cmd->error = -EILSEQ;
+			spin_unlock_irqrestore(&host->mrq_lock, flags);
+			aml_sdio_print_err(host, "cmd crc7 error");
+		}
+		aml_sdio_request_done(host->mmc, mrq);
+	} else{
+		if (irqs->sdio_data_read_crc16_ok
+				|| irqs->sdio_data_write_crc16_ok) {
+			mrq->cmd->error = 0;
+			spin_unlock_irqrestore(&host->mrq_lock, flags);
+		} else {
+			mrq->cmd->error = -EILSEQ;
+			if ((sdio_error_flag == 0)
+					&& aml_card_type_mmc(pdata)) {
+				/* set cmd retry cnt when first error. */
+				sdio_error_flag |= (1<<0);
+				mrq->cmd->retries = AML_ERROR_RETRY_COUNTER;
+			}
+			spin_unlock_irqrestore(&host->mrq_lock, flags);
+			aml_sdio_print_err(host, "data crc16 error");
+		}
+		spin_lock_irqsave(&host->mrq_lock, flags);
+		mrq->data->bytes_xfered = mrq->data->blksz*mrq->data->blocks;
+
+		if ((mrq->cmd->error == 0) || (sdio_error_flag
+					&& (mrq->cmd->retries == 0))) {
+			sdio_error_flag |= (1<<30);
+		}
+
+		spin_unlock_irqrestore(&host->mrq_lock, flags);
+		if (mrq->data->flags & MMC_DATA_READ) {
+			aml_sg_copy_buffer(mrq->data->sg, mrq->data->sg_len,
+					host->bn_buf,
+					mrq->data->blksz*mrq->data->blocks, 0);
+			sdio_dbg(AMLSD_DBG_RD_DATA, "R Cmd %d, %x-%x-%x-%x\n",
+					host->mrq->cmd->opcode,
+					host->bn_buf[0], host->bn_buf[1],
+					host->bn_buf[2], host->bn_buf[3]);
+		}
+		spin_lock_irqsave(&host->mrq_lock, flags);
+		if (mrq->stop) {
+			aml_sdio_send_stop(host);
+			spin_unlock_irqrestore(&host->mrq_lock, flags);
+		} else {
+			spin_unlock_irqrestore(&host->mrq_lock, flags);
+			aml_sdio_request_done(host->mmc, mrq);
+		}
+	}
+	return IRQ_HANDLED;
+}
+
+/*
+ * 1. clock valid range
+ * 2. clk config enable
+ * 3. select clock source
+ * 4. set clock divide
+ */
+static void aml_sdio_set_clk_rate(struct amlsd_platform *pdata, u32 clk_ios)
+{
+	struct amlsd_host *host = (void *)pdata->host;
+	u32 vconf = readl(host->base + SDIO_CONF);
+	struct sdio_config *conf = (void *)&vconf;
+	u32 clk_rate = clk_get_rate(host->core_clk) / 2; /* tmp for 3.10 */
+	u32 clk_div;
+
+	if (clk_ios > pdata->f_max)
+		clk_ios = pdata->f_max;
+	if (clk_ios < pdata->f_min)
+		clk_ios = pdata->f_min;
+
+	WARN_ON(!clk_ios);
+
+	/*0: dont set it, 1:div2, 2:div3, 3:div4...*/
+	clk_div = clk_rate / clk_ios - !(clk_rate%clk_ios);
+
+	if (aml_card_type_sdio(pdata)
+			&& (pdata->f_max > 50000000)) /* if > 50MHz */
+		clk_div = 0;
+
+	conf->cmd_clk_divide = clk_div;
+	pdata->clkc = clk_div;
+	pdata->mmc->actual_clock = clk_rate / (clk_div + 1);
+	writel(vconf, host->base + SDIO_CONF);
+	sdio_dbg(AMLSD_DBG_IOS,
+			"Clk IOS %d, Clk Src %d, Host Max Clk %d, clk_divide=%d\n",
+			clk_ios, (clk_rate*2), pdata->f_max, clk_div);
+}
+
+static void aml_sdio_set_bus_width(struct amlsd_platform *pdata, u32 busw_ios)
+{
+	u32 bus_width = 0;
+	struct amlsd_host *host = (void *)pdata->host;
+	u32 vconf = readl(host->base + SDIO_CONF);
+	struct sdio_config *conf = (void *)&vconf;
+
+	switch (busw_ios) {
+	case MMC_BUS_WIDTH_1:
+		bus_width = 0;
+		break;
+	case MMC_BUS_WIDTH_4:
+		bus_width = 1;
+		break;
+	case MMC_BUS_WIDTH_8:
+	default:
+		sdio_err("SDIO Controller Can Not Support 8bit Data Bus\n");
+		break;
+	}
+
+	conf->bus_width = bus_width;
+	pdata->width = bus_width;
+	writel(vconf, host->base + SDIO_CONF);
+	sdio_dbg(AMLSD_DBG_IOS, "Bus Width Ios %d\n", bus_width);
+}
+
+static void aml_sdio_set_power(struct amlsd_platform *pdata, u32 power_mode)
+{
+	switch (power_mode) {
+	case MMC_POWER_ON:
+		if (pdata->pwr_pre)
+			pdata->pwr_pre(pdata);
+		if (pdata->pwr_on)
+			pdata->pwr_on(pdata);
+		break;
+	case MMC_POWER_UP:
+		break;
+	case MMC_POWER_OFF:
+	default:
+		if (pdata->pwr_pre)
+			pdata->pwr_pre(pdata);
+		if (pdata->pwr_off)
+			pdata->pwr_off(pdata);
+		break;
+	}
+}
+
+/* Routine to configure clock values. Exposed API to core */
+static void aml_sdio_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
+{
+	struct amlsd_platform *pdata = mmc_priv(mmc);
+
+	if (!pdata->is_in)
+		return;
+
+	/*set power*/
+	aml_sdio_set_power(pdata, ios->power_mode);
+
+	/*set clock*/
+	if (ios->clock)
+		aml_sdio_set_clk_rate(pdata, ios->clock);
+
+	/*set bus width*/
+	aml_sdio_set_bus_width(pdata, ios->bus_width);
+#if 1
+	if (ios->chip_select == MMC_CS_HIGH)
+		aml_cs_high(mmc);
+	else if (ios->chip_select == MMC_CS_DONTCARE)
+		aml_cs_dont_care(mmc);
+#endif
+}
+
+static int aml_sdio_get_ro(struct mmc_host *mmc)
+{
+	struct amlsd_platform *pdata = mmc_priv(mmc);
+	u32 ro = 0;
+
+	if (pdata->ro)
+		ro = pdata->ro(pdata);
+	return ro;
+}
+
+int aml_sdio_get_cd(struct mmc_host *mmc)
+{
+	struct amlsd_platform *pdata = mmc_priv(mmc);
+
+	return pdata->is_in; /* 0: no inserted  1: inserted */
+}
+
+#if 0/* def CONFIG_PM */
+static int aml_sdio_suspend(struct platform_device *pdev, pm_message_t state)
+{
+	int ret = 0;
+	int i;
+	struct amlsd_host *host = platform_get_drvdata(pdev);
+	struct mmc_host *mmc;
+	struct amlsd_platform *pdata;
+
+	pr_info("***Entered %s:%s\n", __FILE__, __func__);
+	i = 0;
+	list_for_each_entry(pdata, &host->sibling, sibling) {
+		mmc = pdata->mmc;
+		/* mmc_power_save_host(mmc); */
+		ret = mmc_suspend_host(mmc);
+		if (ret)
+			break;
+		i++;
+	}
+
+	if (ret) {
+		list_for_each_entry(pdata, &host->sibling, sibling) {
+			i--;
+			if (i < 0)
+				break;
+
+			if (!(pdata->caps & MMC_CAP_NONREMOVABLE))
+				aml_sd_uart_detect(pdata);
+
+			mmc = pdata->mmc;
+			mmc_resume_host(mmc);
+		}
+	}
+	pr_info("***Exited %s:%s\n", __FILE__, __func__);
+
+	return ret;
+}
+
+static int aml_sdio_resume(struct platform_device *pdev)
+{
+	int ret = 0;
+	struct amlsd_host *host = platform_get_drvdata(pdev);
+	struct mmc_host *mmc;
+	struct amlsd_platform *pdata;
+
+	pr_info("***Entered %s:%s\n", __FILE__, __func__);
+	list_for_each_entry(pdata, &host->sibling, sibling) {
+
+		/* detect if a card is exist or not if it is removable */
+		if (!(pdata->caps & MMC_CAP_NONREMOVABLE))
+			aml_sd_uart_detect(pdata);
+
+		mmc = pdata->mmc;
+		/* mmc_power_restore_host(mmc); */
+		ret = mmc_resume_host(mmc);
+		if (ret)
+			break;
+	}
+	pr_info("***Exited %s:%s\n", __FILE__, __func__);
+	return ret;
+}
+#else
+#define aml_sdio_suspend	NULL
+#define aml_sdio_resume		NULL
+#endif
+
+static const struct mmc_host_ops aml_sdio_ops = {
+	.request = aml_sdio_request,
+	.set_ios = aml_sdio_set_ios,
+	.enable_sdio_irq = aml_sdio_enable_irq,
+	.get_cd = aml_sdio_get_cd,
+	.get_ro = aml_sdio_get_ro,
+	.hw_reset = aml_emmc_hw_reset,
+};
+
+static ssize_t sdio_debug_func(struct class *class,
+		struct class_attribute *attr, const char *buf, size_t count)
+{
+	count = kstrtoint(buf, 0, &sdio_debug_flag);
+	pr_info("sdio_debug_flag: %d\n", sdio_debug_flag);
+
+	return count;
+}
+
+static ssize_t show_sdio_debug(struct class *class,
+		struct class_attribute *attr,	char *buf)
+{
+	pr_info("sdio_debug_flag: %d\n", sdio_debug_flag);
+	pr_info("1 : Force sdio cmd crc error\n");
+	pr_info("2 : Force sdio data crc error\n");
+	pr_info("9 : Force sdio irq timeout error\n");
+
+	return 0;
+}
+
+static struct class_attribute sdio_class_attrs[] = {
+	__ATTR(debug, 0644, show_sdio_debug, sdio_debug_func),
+	__ATTR_NULL
+};
+
+static struct amlsd_host *aml_sdio_init_host(struct amlsd_host *host)
+{
+	if (request_threaded_irq(host->irq,
+				(irq_handler_t)aml_sdio_irq,
+				aml_sdio_irq_thread,
+				IRQF_SHARED, "sdio", (void *)host)) {
+		sdio_err("Request SDIO Irq Error!\n");
+		return NULL;
+	}
+
+	host->bn_buf = dma_alloc_coherent(NULL, SDIO_BOUNCE_REQ_SIZE,
+			&host->bn_dma_buf, GFP_KERNEL);
+	if (host->bn_buf == NULL) {
+		sdio_err("Dma alloc Fail!\n");
+		return NULL;
+	}
+	INIT_DELAYED_WORK(&host->timeout, aml_sdio_timeout);
+
+	spin_lock_init(&host->mrq_lock);
+	mutex_init(&host->pinmux_lock);
+	host->xfer_step = XFER_INIT;
+
+	INIT_LIST_HEAD(&host->sibling);
+
+	host->version = AML_MMC_VERSION;
+	/*host->storage_flag = storage_flag;*/
+	host->pinctrl = NULL;
+
+	host->init_flag = 1;
+
+#ifdef CONFIG_MMC_AML_DEBUG
+	host->req_cnt = 0;
+	sdio_err("CONFIG_MMC_AML_DEBUG is on!\n");
+#endif
+
+	host->debug.name =
+		kzalloc(strlen((const char *)AML_SDIO_MAGIC)+1, GFP_KERNEL);
+	strcpy((char *)(host->debug.name), (const char *)AML_SDIO_MAGIC);
+	host->debug.class_attrs = sdio_class_attrs;
+	if (class_register(&host->debug))
+		pr_info(" class register nand_class fail!\n");
+
+	return host;
+}
+
+static int aml_sdio_probe(struct platform_device *pdev)
+{
+	struct mmc_host *mmc = NULL;
+	struct amlsd_host *host = NULL;
+	struct amlsd_platform *pdata;
+	struct resource *res_mem;
+	int size;
+	int ret = 0, i;
+
+	pr_info("%s() begin!\n", __func__);
+
+	host = kzalloc(sizeof(struct amlsd_host), GFP_KERNEL);
+	if (!host)
+		return -ENODEV;
+
+	aml_mmc_ver_msg_show();
+
+	res_mem = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!res_mem) {
+		pr_info("error to get IORESOURCE\n");
+		goto fail_init_host;
+	}
+	size = resource_size(res_mem);
+
+	host->irq = irq_of_parse_and_map(pdev->dev.of_node, 0);
+	pr_info("host->irq = %d\n", host->irq);
+	host->pinmux_base = ioremap(0xc1108000, 0x200);
+	host->base = devm_ioremap_nocache(&pdev->dev, res_mem->start, size);
+
+	aml_sdio_init_host(host);
+	/* if (amlsd_get_reg_base(pdev, host))
+	 *	goto fail_init_host;
+	 */
+
+	host->pdev = pdev;
+	host->dev = &pdev->dev;
+	platform_set_drvdata(pdev, host);
+	/* init sdio reg here */
+	aml_sdio_init_param(host);
+
+	//	for (i = 0; i < MMC_MAX_DEVICE; i++) {
+	for (i = 0; i < 1; i++) {
+		/*malloc extra amlsd_platform*/
+		mmc = mmc_alloc_host(sizeof(struct amlsd_platform), &pdev->dev);
+		if (!mmc) {
+			ret = -ENOMEM;
+			goto probe_free_host;
+		}
+
+		pdata = mmc_priv(mmc);
+		memset(pdata, 0, sizeof(struct amlsd_platform));
+		if (amlsd_get_platform_data(pdev, pdata, mmc, i)) {
+			mmc_free_host(mmc);
+			break;
+		}
+#if 0
+		/* if(pdata->parts){ */
+		if (pdata->port == PORT_SDIO_C) {
+			if (is_emmc_exist(host)) {
+				mmc->is_emmc_port = 1;
+				/* add_part_table(pdata->parts,*/
+				/*pdata->nr_parts);*/
+				/* mmc->add_part = add_emmc_partition; */
+			} else { /* there is not eMMC/tsd */
+				pr_info(
+						"[%s]:not eMMC/tsd,skip sdio_c dts config!\n",
+						__func__);
+				i++; /* skip the port written in the dts */
+				memset(pdata, 0, sizeof(struct amlsd_platform));
+				if (amlsd_get_platform_data(pdev,
+							pdata, mmc, i)) {
+					mmc_free_host(mmc);
+					break;
+				}
+			}
+		}
+#endif
+		dev_set_name(&mmc->class_dev, "%s", pdata->pinname);
+		if (pdata->caps & MMC_CAP_NONREMOVABLE)
+			pdata->is_in = true;
+
+		if (pdata->caps & MMC_PM_KEEP_POWER)
+			mmc->pm_caps |= MMC_PM_KEEP_POWER;
+
+		if (pdata->caps & MMC_CAP_SDIO_IRQ)
+			SDIO_IRQ_SUPPORT = 1;
+
+		pdata->host = host;
+		pdata->mmc = mmc;
+		pdata->is_fir_init = true;
+
+		/*	mmc->index = i;*/
+		/*	mmc->alldev_claim = &aml_sdio_claim;*/
+		mmc->ops = &aml_sdio_ops;
+		mmc->ios.clock = 400000;
+		mmc->ios.bus_width = MMC_BUS_WIDTH_1;
+		mmc->max_blk_count = 4095;
+		mmc->max_blk_size = 4095;
+		mmc->max_req_size = pdata->max_req_size;
+		mmc->max_seg_size = mmc->max_req_size;
+		mmc->max_segs = 1024;
+		mmc->ocr_avail = pdata->ocr_avail;
+		/*	mmc->ocr = pdata->ocr_avail;*/
+		mmc->caps = pdata->caps;
+		mmc->caps2 = pdata->caps2;
+		mmc->f_min = pdata->f_min;
+		mmc->f_max = pdata->f_max;
+
+		if (aml_card_type_sdio(pdata)) /* if sdio_wifi */
+			mmc->rescan_entered = 1;
+		/* do NOT run mmc_rescan for the first time */
+		else
+			mmc->rescan_entered = 0;
+
+		if (pdata->port_init)
+			pdata->port_init(pdata);
+		/*	aml_sduart_pre(pdata);*/
+
+		ret = mmc_add_host(mmc);
+		if (ret) { /* error */
+			sdhc_err("Failed to add mmc host.\n");
+			goto probe_free_host;
+		} else { /* ok */
+			if (aml_card_type_sdio(pdata)) { /* if sdio_wifi */
+				sdio_host = mmc;
+				/* mmc->rescan_entered = 1;  */
+				/* do NOT run mmc_rescan for the first time */
+			}
+		}
+
+		/*	aml_sdio_init_debugfs(mmc);*/
+		/*Add each mmc host pdata to this controller host list*/
+		INIT_LIST_HEAD(&pdata->sibling);
+		list_add_tail(&pdata->sibling, &host->sibling);
+
+		/*Register card detect irq : plug in & unplug*/
+		if (pdata->gpio_cd
+				&& aml_card_type_non_sdio(pdata)) {
+			pdata->irq_init(pdata);
+			mutex_init(&pdata->in_out_lock);
+			ret = request_threaded_irq(pdata->irq_cd,
+					aml_sd_irq_cd, aml_irq_cd_thread,
+					IRQF_TRIGGER_RISING
+					| IRQF_TRIGGER_FALLING
+					| IRQF_ONESHOT,
+					"sdio_mmc_cd", pdata);
+			if (ret) {
+				sd_emmc_err("Failed to request SD IN detect\n");
+				goto probe_free_host;
+			}
+		}
+	}
+
+	print_tmp("%s() success!\n", __func__);
+	return 0;
+
+probe_free_host:
+	list_for_each_entry(pdata, &host->sibling, sibling) {
+		mmc = pdata->mmc;
+		mmc_remove_host(mmc);
+		mmc_free_host(mmc);
+	}
+fail_init_host:
+	iounmap(host->base);
+	free_irq(host->irq, host);
+	dma_free_coherent(NULL, SDIO_BOUNCE_REQ_SIZE, host->bn_buf,
+			(dma_addr_t)host->bn_dma_buf);
+	kfree(host);
+	print_tmp("aml_sdio_probe() fail!\n");
+	return ret;
+	}
+
+	int aml_sdio_remove(struct platform_device *pdev)
+	{
+		struct amlsd_host *host = platform_get_drvdata(pdev);
+		struct mmc_host *mmc;
+		struct amlsd_platform *pdata;
+
+		dma_free_coherent(NULL, SDIO_BOUNCE_REQ_SIZE, host->bn_buf,
+				(dma_addr_t)host->bn_dma_buf);
+
+		free_irq(host->irq, host);
+		iounmap(host->base);
+
+		list_for_each_entry(pdata, &host->sibling, sibling) {
+			mmc = pdata->mmc;
+			mmc_remove_host(mmc);
+			mmc_free_host(mmc);
+		}
+
+		/*	aml_devm_pinctrl_put(host);*/
+
+		kfree(host);
+		return 0;
+	}
+
+	static const struct of_device_id aml_sdio_dt_match[] = {
+		{
+			.compatible = "amlogic, aml_sdio",
+		},
+		{},
+	};
+
+	MODULE_DEVICE_TABLE(of, aml_sdio_dt_match);
+
+	static struct platform_driver aml_sdio_driver = {
+		.probe		 = aml_sdio_probe,
+		.remove		= aml_sdio_remove,
+		.suspend	= aml_sdio_suspend,
+		.resume		= aml_sdio_resume,
+		.driver		= {
+			.name = "aml_sdio",
+			.owner = THIS_MODULE,
+			.of_match_table = aml_sdio_dt_match,
+		},
+	};
+
+	static int __init aml_sdio_init(void)
+	{
+		return platform_driver_register(&aml_sdio_driver);
+	}
+
+	static void __exit aml_sdio_cleanup(void)
+	{
+		platform_driver_unregister(&aml_sdio_driver);
+	}
+
+	module_init(aml_sdio_init);
+	module_exit(aml_sdio_cleanup);
+
+	MODULE_DESCRIPTION("Amlogic SDIO Controller driver");
+	MODULE_LICENSE("GPL");
+
diff --git a/drivers/amlogic/mmc/amlsd.c b/drivers/amlogic/mmc/amlsd.c
new file mode 100644
index 0000000..5cbed9e
--- /dev/null
+++ b/drivers/amlogic/mmc/amlsd.c
@@ -0,0 +1,853 @@
+/*
+ * drivers/amlogic/mmc/amlsd.c
+ *
+ * Copyright (C) 2017 Amlogic, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/interrupt.h>
+#include <linux/delay.h>
+#include <linux/dma-mapping.h>
+#include <linux/platform_device.h>
+#include <linux/io.h>
+#include <linux/gpio.h>
+#include <linux/regulator/consumer.h>
+#include <linux/mmc/host.h>
+#include <linux/mmc/core.h>
+#include <linux/mmc/mmc.h>
+#include <linux/mmc/sdio.h>
+#include <linux/mmc/sd.h>
+#include <linux/mmc/card.h>
+#include <linux/slab.h>
+#include <linux/amlogic/sd.h>
+#include <linux/amlogic/iomap.h>
+#include <linux/amlogic/cpu_version.h>
+#include <linux/highmem.h>
+#include <linux/of.h>
+#include <linux/pinctrl/consumer.h>
+#include <linux/amlogic/amlsd.h>
+#ifdef CONFIG_AMLOGIC_M8B_MMC
+#include <linux/amlogic/gpio-amlogic.h>
+#endif
+
+const u8 tuning_blk_pattern_4bit[64] = {
+	0xff, 0x0f, 0xff, 0x00, 0xff, 0xcc, 0xc3, 0xcc,
+	0xc3, 0x3c, 0xcc, 0xff, 0xfe, 0xff, 0xfe, 0xef,
+	0xff, 0xdf, 0xff, 0xdd, 0xff, 0xfb, 0xff, 0xfb,
+	0xbf, 0xff, 0x7f, 0xff, 0x77, 0xf7, 0xbd, 0xef,
+	0xff, 0xf0, 0xff, 0xf0, 0x0f, 0xfc, 0xcc, 0x3c,
+	0xcc, 0x33, 0xcc, 0xcf, 0xff, 0xef, 0xff, 0xee,
+	0xff, 0xfd, 0xff, 0xfd, 0xdf, 0xff, 0xbf, 0xff,
+	0xbb, 0xff, 0xf7, 0xff, 0xf7, 0x7f, 0x7b, 0xde,
+};
+const u8 tuning_blk_pattern_8bit[128] = {
+	0xff, 0xff, 0x00, 0xff, 0xff, 0xff, 0x00, 0x00,
+	0xff, 0xff, 0xcc, 0xcc, 0xcc, 0x33, 0xcc, 0xcc,
+	0xcc, 0x33, 0x33, 0xcc, 0xcc, 0xcc, 0xff, 0xff,
+	0xff, 0xee, 0xff, 0xff, 0xff, 0xee, 0xee, 0xff,
+	0xff, 0xff, 0xdd, 0xff, 0xff, 0xff, 0xdd, 0xdd,
+	0xff, 0xff, 0xff, 0xbb, 0xff, 0xff, 0xff, 0xbb,
+	0xbb, 0xff, 0xff, 0xff, 0x77, 0xff, 0xff, 0xff,
+	0x77, 0x77, 0xff, 0x77, 0xbb, 0xdd, 0xee, 0xff,
+	0xff, 0xff, 0xff, 0x00, 0xff, 0xff, 0xff, 0x00,
+	0x00, 0xff, 0xff, 0xcc, 0xcc, 0xcc, 0x33, 0xcc,
+	0xcc, 0xcc, 0x33, 0x33, 0xcc, 0xcc, 0xcc, 0xff,
+	0xff, 0xff, 0xee, 0xff, 0xff, 0xff, 0xee, 0xee,
+	0xff, 0xff, 0xff, 0xdd, 0xff, 0xff, 0xff, 0xdd,
+	0xdd, 0xff, 0xff, 0xff, 0xbb, 0xff, 0xff, 0xff,
+	0xbb, 0xbb, 0xff, 0xff, 0xff, 0x77, 0xff, 0xff,
+	0xff, 0x77, 0x77, 0xff, 0x77, 0xbb, 0xdd, 0xee,
+};
+
+void aml_mmc_ver_msg_show(void)
+{
+	static bool one_time_flag;
+
+	if (!one_time_flag) {
+		pr_info("mmc driver version: %d.%02d, %s\n",
+			AML_MMC_MAJOR_VERSION, AML_MMC_MINOR_VERSION,
+				AML_MMC_VER_MESSAGE);
+
+	one_time_flag = true;
+	}
+}
+
+
+
+static int aml_is_card_insert(struct amlsd_platform *pdata)
+{
+	int ret = 0, in_count = 0, out_count = 0, i;
+
+	if (pdata->gpio_cd) {
+		mdelay(pdata->card_in_delay);
+		for (i = 0; i < 200; i++) {
+			ret = gpio_get_value(pdata->gpio_cd);
+			if (ret)
+				out_count++;
+			in_count++;
+			if ((out_count > 100) || (in_count > 100))
+				break;
+		}
+		if (out_count > 100)
+			ret = 1;
+		else if (in_count > 100)
+			ret = 0;
+	}
+	sdio_err("card %s\n", ret?"OUT":"IN");
+	if (!pdata->gpio_cd_level)
+		ret = !ret; /* reverse, so ---- 0: no inserted  1: inserted */
+
+	return ret;
+}
+
+#ifdef CONFIG_AMLOGIC_M8B_MMC
+int aml_sd_uart_detect(struct amlsd_platform *pdata)
+#else
+int aml_sd_uart_detect(struct amlsd_host *host)
+#endif
+{
+#ifdef CONFIG_AMLOGIC_M8B_MMC
+	struct mmc_host *mmc  = pdata->mmc;
+#else
+	struct amlsd_platform *pdata = host->pdata;
+	struct mmc_host *mmc  = host->mmc;
+#endif
+
+	if (aml_is_card_insert(pdata)) {
+		if (pdata->is_in)
+			return 1;
+		pdata->is_in = true;
+		pr_info("normal card in\n");
+		if (pdata->caps & MMC_CAP_4_BIT_DATA)
+			mmc->caps |= MMC_CAP_4_BIT_DATA;
+	} else {
+		if (!pdata->is_in)
+			return 1;
+		pdata->is_in = false;
+		pr_info("card out\n");
+
+		pdata->is_tuned = false;
+		if (mmc && mmc->card)
+			mmc_card_set_removed(mmc->card);
+		/* switch to 3.3V */
+		aml_sd_voltage_switch(mmc,
+				MMC_SIGNAL_VOLTAGE_330);
+
+		if (pdata->caps & MMC_CAP_4_BIT_DATA)
+			mmc->caps |= MMC_CAP_4_BIT_DATA;
+	}
+	return 0;
+}
+
+static int card_dealed;
+irqreturn_t aml_irq_cd_thread(int irq, void *data)
+{
+#ifdef CONFIG_AMLOGIC_M8B_MMC
+	struct amlsd_platform *pdata = (struct amlsd_platform *)data;
+	struct mmc_host *mmc = pdata->mmc;
+	struct amlsd_host *host = pdata->host;
+#else
+	struct amlsd_host *host = (struct amlsd_host *)data;
+	struct amlsd_platform *pdata = host->pdata;
+	struct mmc_host *mmc = host->mmc;
+#endif
+	int ret = 0;
+
+	mutex_lock(&pdata->in_out_lock);
+	if (card_dealed == 1) {
+		card_dealed = 0;
+		mutex_unlock(&pdata->in_out_lock);
+		return IRQ_HANDLED;
+	}
+#ifdef CONFIG_AMLOGIC_M8B_MMC
+	ret = aml_sd_uart_detect(pdata);
+#else
+	ret = aml_sd_uart_detect(host);
+#endif
+	if (ret == 1) {/* the same as the last*/
+		mutex_unlock(&pdata->in_out_lock);
+		return IRQ_HANDLED;
+	}
+	card_dealed = 1;
+	if ((pdata->is_in == 0) && aml_card_type_non_sdio(pdata))
+		host->init_flag = 0;
+	mutex_unlock(&pdata->in_out_lock);
+
+	/* mdelay(500); */
+	if (pdata->is_in)
+		mmc_detect_change(mmc, msecs_to_jiffies(100));
+	else
+		mmc_detect_change(mmc, msecs_to_jiffies(0));
+
+	card_dealed = 0;
+	return IRQ_HANDLED;
+}
+
+irqreturn_t aml_sd_irq_cd(int irq, void *dev_id)
+{
+	/* pr_info("cd dev_id %x\n", (unsigned)dev_id); */
+	return IRQ_WAKE_THREAD;
+}
+
+static int aml_cmd_invalid(struct mmc_host *mmc, struct mmc_request *mrq)
+{
+#ifdef CONFIG_AMLOGIC_M8B_MMC
+	struct amlsd_platform *pdata = mmc_priv(mmc);
+	struct amlsd_host *host = pdata->host;
+#else
+	struct amlsd_host *host = mmc_priv(mmc);
+#endif
+	unsigned long flags;
+
+	spin_lock_irqsave(&host->mrq_lock, flags);
+	mrq->cmd->error = -EINVAL;
+	spin_unlock_irqrestore(&host->mrq_lock, flags);
+	mmc_request_done(mmc, mrq);
+
+	return -EINVAL;
+}
+
+static int aml_rpmb_cmd_invalid(struct mmc_host *mmc, struct mmc_request *mrq)
+{
+#ifdef CONFIG_AMLOGIC_M8B_MMC
+	struct amlsd_platform *pdata = mmc_priv(mmc);
+	struct amlsd_host *host = pdata->host;
+#else
+	struct amlsd_host *host = mmc_priv(mmc);
+#endif
+	unsigned long flags;
+
+	spin_lock_irqsave(&host->mrq_lock, flags);
+	host->xfer_step = XFER_FINISHED;
+	host->mrq = NULL;
+	host->status = HOST_INVALID;
+	spin_unlock_irqrestore(&host->mrq_lock, flags);
+	mrq->data->bytes_xfered = mrq->data->blksz*mrq->data->blocks;
+	mmc_request_done(mmc, mrq);
+	return -EINVAL;
+}
+
+int aml_check_unsupport_cmd(struct mmc_host *mmc, struct mmc_request *mrq)
+{
+#ifdef CONFIG_AMLOGIC_M8B_MMC
+	struct amlsd_platform *pdata = mmc_priv(mmc);
+#else
+	struct amlsd_host *host = mmc_priv(mmc);
+	struct amlsd_platform *pdata = host->pdata;
+#endif
+	u32 opcode, arg;
+
+	opcode = mrq->cmd->opcode;
+	arg = mrq->cmd->arg;
+	/* CMD3 means the first time initialized flow is running */
+	if (opcode == 3)
+		mmc->first_init_flag = false;
+
+	if (aml_card_type_mmc(pdata)) {
+		if (opcode == 6) {
+			if (arg == 0x3B30301)
+				pdata->rmpb_cmd_flag = 1;
+			else
+				pdata->rmpb_cmd_flag = 0;
+		}
+		if (pdata->rmpb_cmd_flag && (!pdata->rpmb_valid_command)) {
+			if ((opcode == 18)
+				|| (opcode == 25))
+				return aml_rpmb_cmd_invalid(mmc, mrq);
+		}
+		if (pdata->rmpb_cmd_flag && (opcode == 23))
+			pdata->rpmb_valid_command = 1;
+		else
+			pdata->rpmb_valid_command = 0;
+	}
+
+	if (mmc->caps & MMC_CAP_NONREMOVABLE) { /* nonremovable device */
+		if (mmc->first_init_flag) { /* init for the first time */
+			/* for 8189ETV needs ssdio reset when starts */
+			if (aml_card_type_sdio(pdata)) {
+				/* if (opcode == SD_IO_RW_DIRECT
+				 * || opcode == SD_IO_RW_EXTENDED
+				 * || opcode == SD_SEND_IF_COND)
+				 * return aml_cmd_invalid(mmc, mrq);
+				 */
+				return 0;
+			} else if (aml_card_type_mmc(pdata)) {
+				if (opcode == SD_IO_SEND_OP_COND
+					|| opcode == SD_IO_RW_DIRECT
+					|| opcode == SD_IO_RW_EXTENDED
+					|| opcode == SD_SEND_IF_COND
+					|| opcode == MMC_APP_CMD)
+					return aml_cmd_invalid(mmc, mrq);
+			} else if (aml_card_type_sd(pdata)
+					|| aml_card_type_non_sdio(pdata)) {
+				if (opcode == SD_IO_SEND_OP_COND
+					|| opcode == SD_IO_RW_DIRECT
+					|| opcode == SD_IO_RW_EXTENDED)
+					return aml_cmd_invalid(mmc, mrq);
+			}
+		}
+	} else { /* removable device */
+		/* filter cmd 5/52/53 for a non-sdio device */
+		if (!aml_card_type_sdio(pdata)
+			&& !aml_card_type_unknown(pdata)) {
+			if (opcode == SD_IO_SEND_OP_COND
+				|| opcode == SD_IO_RW_DIRECT
+				|| opcode == SD_IO_RW_EXTENDED)
+				return aml_cmd_invalid(mmc, mrq);
+		}
+	}
+	return 0;
+}
+
+int aml_sd_voltage_switch(struct mmc_host *mmc, char signal_voltage)
+{
+#ifndef CONFIG_AMLOGIC_M8B_MMC
+	struct amlsd_host *host = mmc_priv(mmc);
+	struct amlsd_platform *pdata = host->pdata;
+	int ret = 0;
+
+	/* voltage is the same, return directly */
+	if (!aml_card_type_non_sdio(pdata)
+		|| (pdata->signal_voltage == signal_voltage)) {
+		if (aml_card_type_sdio(pdata))
+			host->sd_sdio_switch_volat_done = 1;
+		return 0;
+	}
+	if (pdata->vol_switch) {
+		if (pdata->signal_voltage == 0xff) {
+			gpio_free(pdata->vol_switch);
+			ret = gpio_request_one(pdata->vol_switch,
+					GPIOF_OUT_INIT_HIGH, MODULE_NAME);
+			if (ret) {
+				pr_err("%s [%d] request error\n",
+						__func__, __LINE__);
+				return -EINVAL;
+			}
+		}
+		if (signal_voltage == MMC_SIGNAL_VOLTAGE_180)
+			ret = gpio_direction_output(pdata->vol_switch,
+						pdata->vol_switch_18);
+		else
+			ret = gpio_direction_output(pdata->vol_switch,
+					(!pdata->vol_switch_18));
+		CHECK_RET(ret);
+		if (!ret)
+			pdata->signal_voltage = signal_voltage;
+	} else
+		return -EINVAL;
+
+	host->sd_sdio_switch_volat_done = 1;
+#endif
+	return 0;
+}
+
+/* boot9 here */
+void aml_emmc_hw_reset(struct mmc_host *mmc)
+{
+#ifdef CONFIG_AMLOGIC_M8B_MMC
+	struct amlsd_platform *pdata = mmc_priv(mmc);
+	void __iomem *hw_ctrl;
+
+	if (!aml_card_type_mmc(pdata))
+		return;
+	hw_ctrl = ioremap(P_PREG_PAD_GPIO3_EN_N, 0x200);
+
+	//boot_9 used as eMMC hw_rst pin here.
+
+	//clr nand ce1 pinmux
+	aml_clr_reg32_mask((hw_ctrl + (0x19 << 2)), (1<<24));
+
+	//set out
+	aml_clr_reg32_mask(hw_ctrl, (1<<9));
+
+	//high
+	aml_set_reg32_mask((hw_ctrl + (0x1 << 2)), (1<<9));
+	mdelay(1);
+
+	//low
+	aml_clr_reg32_mask((hw_ctrl + (0x1 << 2)), (1<<9));
+	mdelay(2);
+
+	//high
+	aml_set_reg32_mask((hw_ctrl + (0x1 << 2)), (1<<9));
+	mdelay(1);
+#else
+	struct amlsd_host *host = mmc_priv(mmc);
+	struct amlsd_platform *pdata = host->pdata;
+	u32 ret;
+
+	if (!aml_card_type_mmc(pdata) || !pdata->hw_reset)
+		return;
+
+	/* boot_9 used as eMMC hw_rst pin here. */
+	gpio_free(pdata->hw_reset);
+	ret = gpio_request_one(pdata->hw_reset,
+			GPIOF_OUT_INIT_HIGH, MODULE_NAME);
+	CHECK_RET(ret);
+	if (ret) {
+		pr_err("%s [%d] request error\n",
+				__func__, __LINE__);
+		return;
+	}
+	ret = gpio_direction_output(pdata->hw_reset, 0);
+	CHECK_RET(ret);
+	if (ret) {
+		pr_err("%s [%d] output high error\n",
+			__func__, __LINE__);
+		return;
+	}
+	mdelay(2);
+	ret = gpio_direction_output(pdata->hw_reset, 1);
+	CHECK_RET(ret);
+	if (ret) {
+		pr_err("%s [%d] output high error\n",
+			__func__, __LINE__);
+		return;
+	}
+	mdelay(2);
+#endif
+}
+
+static void sdio_rescan(struct mmc_host *mmc)
+{
+	int ret;
+
+	mmc->rescan_entered = 0;
+/*	mmc->host_rescan_disable = false;*/
+	mmc_detect_change(mmc, 0);
+	/* start the delayed_work */
+	ret = flush_work(&(mmc->detect.work));
+	/* wait for the delayed_work to finish */
+	if (!ret)
+		pr_info("Error: delayed_work mmc_rescan() already idle!\n");
+}
+
+//void sdio_reinit(void)
+//{
+//	if (sdio_host) {
+//		if (sdio_host->card)
+//			sdio_reset_comm(sdio_host->card);
+//		else
+//			sdio_rescan(sdio_host);
+//	} else {
+//		pr_info("Error: sdio_host is NULL\n");
+//	}
+//
+//	pr_info("[%s] finish\n", __func__);
+//}
+//EXPORT_SYMBOL(sdio_reinit);
+
+void of_amlsd_irq_init(struct amlsd_platform *pdata)
+{
+	if (aml_card_type_non_sdio(pdata))
+		pdata->irq_cd = gpio_to_irq(pdata->gpio_cd);
+	pr_info("sd irq num = %d\n", pdata->irq_cd);
+}
+
+int of_amlsd_init(struct amlsd_platform *pdata)
+{
+	int ret;
+
+	WARN_ON(!pdata);
+
+	if (pdata->gpio_cd) {
+		pr_info("gpio_cd = %x\n", pdata->gpio_cd);
+		ret = gpio_request_one(pdata->gpio_cd,
+				GPIOF_IN, MODULE_NAME);
+		CHECK_RET(ret);
+	}
+#if 0
+	if (pdata->gpio_ro) {
+		ret = amlogic_gpio_request_one(pdata->gpio_ro,
+				GPIOF_IN, MODULE_NAME);
+		if (!ret) { // ok
+			/* 0:pull down, 1:pull up */
+			ret = amlogic_set_pull_up_down(pdata->gpio_ro,
+			  1, MODULE_NAME);
+			CHECK_RET(ret);
+		} else {
+			sdio_err("request gpio_ro pin fail!\n");
+		}
+	}
+#endif
+	if (pdata->gpio_power) {
+		if (pdata->power_level) {
+			ret = gpio_request_one(pdata->gpio_power,
+					GPIOF_OUT_INIT_LOW, MODULE_NAME);
+			CHECK_RET(ret);
+		} else {
+			ret = gpio_request_one(pdata->gpio_power,
+					GPIOF_OUT_INIT_HIGH, MODULE_NAME);
+			CHECK_RET(ret);
+		}
+	}
+
+	/* if(pdata->port == MESON_SDIO_PORT_A) */
+	/* wifi_setup_dt(); */
+	return 0;
+}
+
+void aml_devm_pinctrl_put(struct amlsd_host *host)
+{
+	if (host->pinctrl) {
+		devm_pinctrl_put(host->pinctrl);
+		host->pinctrl = NULL;
+
+		host->pinctrl_name[0] = '\0';
+		/* sdio_err("Put Pinctrl\n"); */
+	}
+}
+
+static struct pinctrl * __must_check aml_devm_pinctrl_get_select(
+				struct amlsd_host *host, const char *name)
+{
+	struct pinctrl *p = host->pinctrl;
+	struct pinctrl_state *s;
+	int ret;
+
+	if (!p) {
+		p = devm_pinctrl_get(&host->pdev->dev);
+
+		if (IS_ERR(p))
+			return p;
+
+		host->pinctrl = p;
+		/* sdio_err("switch %s\n", name); */
+	}
+
+	s = pinctrl_lookup_state(p, name);
+	if (IS_ERR(s)) {
+		sdio_err("lookup %s fail\n", name);
+		devm_pinctrl_put(p);
+		return ERR_CAST(s);
+	}
+
+	ret = pinctrl_select_state(p, s);
+	if (ret < 0) {
+		sdio_err("select %s fail\n", name);
+		devm_pinctrl_put(p);
+		return ERR_PTR(ret);
+	}
+	return p;
+}
+
+void of_amlsd_xfer_pre(struct mmc_host *mmc)
+{
+#ifdef CONFIG_AMLOGIC_M8B_MMC
+	struct amlsd_platform *pdata = mmc_priv(mmc);
+	struct amlsd_host *host = pdata->host;
+#else
+	struct amlsd_host *host = mmc_priv(mmc);
+	struct amlsd_platform *pdata = host->pdata;
+#endif
+	char pinctrl[30];
+	char *p = pinctrl;
+	int i, size = 0;
+	struct pinctrl *ppin;
+
+	size = sizeof(pinctrl);
+#ifdef CONFIG_AMLOGIC_M8B_MMC
+	if (pdata->port > PORT_SDIO_C) // so it should be PORT_SDHC_X
+		aml_snprint(&p, &size, "sdhc_");
+#endif
+
+	if (mmc->ios.chip_select == MMC_CS_DONTCARE) {
+		if ((mmc->caps & MMC_CAP_4_BIT_DATA)
+		|| (strcmp(pdata->pinname, "sd"))
+		|| (mmc->caps & MMC_CAP_8_BIT_DATA))
+			aml_snprint(&p, &size, "%s_all_pins", pdata->pinname);
+	} else { /* MMC_CS_HIGH */
+		if (pdata->is_sduart && (!strcmp(pdata->pinname, "sd"))) {
+			aml_snprint(&p, &size,
+				"%s_clk_cmd_uart_pins", pdata->pinname);
+		} else {
+			aml_snprint(&p, &size,
+				"%s_clk_cmd_pins", pdata->pinname);
+		}
+	}
+
+	/* if pinmux setting is changed (pinctrl_name is different) */
+	if (strncmp(host->pinctrl_name, pinctrl,
+				sizeof(host->pinctrl_name))) {
+		if (strlcpy(host->pinctrl_name, pinctrl,
+					sizeof(host->pinctrl_name))
+				>= sizeof(host->pinctrl_name)) {
+
+			sdio_err("Pinctrl name is too long!\n");
+			return;
+		}
+
+		for (i = 0; i < 100; i++) {
+			mutex_lock(&host->pinmux_lock);
+			ppin = aml_devm_pinctrl_get_select(host, pinctrl);
+			mutex_unlock(&host->pinmux_lock);
+			if (!IS_ERR(ppin)) {
+				/* pdata->host->pinctrl = ppin; */
+				break;
+			}
+			/* else -> aml_irq_cdin_thread()
+			 *should be using one of the GPIO of card,
+			 * then we should wait here until the GPIO is free,
+			 * otherwise something must be wrong.
+			 */
+			mdelay(1);
+		}
+		if (i == 100)
+			sdhc_err("CMD%d: get pinctrl %s fail.\n",
+					host->opcode, pinctrl);
+	}
+}
+
+void of_amlsd_xfer_post(struct mmc_host *mmc)
+{
+}
+
+int of_amlsd_ro(struct amlsd_platform *pdata)
+{
+	int ret = 0; /* 0--read&write, 1--read only */
+
+	if (pdata->gpio_ro)
+		ret = gpio_get_value(pdata->gpio_ro);
+	/* sdio_err("read-only?--%s\n", ret?"YES":"NO"); */
+	return ret;
+}
+
+void aml_snprint (char **pp, int *left_size,  const char *fmt, ...)
+{
+	va_list args;
+	char *p = *pp;
+	int size;
+
+	if (*left_size <= 1) {
+		sdhc_err("buf is full\n");
+		return;
+	}
+
+	va_start(args, fmt);
+	size = vsnprintf(p, *left_size, fmt, args);
+	va_end(args);
+	*pp += size;
+	*left_size -= size;
+}
+
+void aml_cs_high(struct mmc_host *mmc) /* chip select high */
+{
+	int ret;
+#ifdef CONFIG_AMLOGIC_M8B_MMC
+	struct amlsd_platform *pdata = mmc_priv(mmc);
+	struct amlsd_host *host = pdata->host;
+#else
+	struct amlsd_host *host = mmc_priv(mmc);
+	struct amlsd_platform *pdata = host->pdata;
+#endif
+
+	if ((mmc->ios.chip_select == MMC_CS_HIGH)
+			&& (pdata->gpio_dat3 != 0)) {
+		aml_devm_pinctrl_put(host);
+		ret = gpio_request_one(pdata->gpio_dat3,
+				GPIOF_OUT_INIT_HIGH, MODULE_NAME);
+		CHECK_RET(ret);
+		if (ret == 0) {
+			ret = gpio_direction_output(pdata->gpio_dat3, 1);
+			CHECK_RET(ret);
+		}
+	}
+}
+
+void aml_cs_dont_care(struct mmc_host *mmc)
+{
+#ifdef CONFIG_AMLOGIC_M8B_MMC
+	struct amlsd_platform *pdata = mmc_priv(mmc);
+#else
+	struct amlsd_host *host = mmc_priv(mmc);
+	struct amlsd_platform *pdata = host->pdata;
+#endif
+
+	if ((mmc->ios.chip_select == MMC_CS_DONTCARE)
+			&& (pdata->gpio_dat3 != 0)
+			&& (gpio_get_value(pdata->gpio_dat3) >= 0))
+		gpio_free(pdata->gpio_dat3);
+}
+
+void of_amlsd_pwr_prepare(struct amlsd_platform *pdata)
+{
+}
+
+void of_amlsd_pwr_on(struct amlsd_platform *pdata)
+{
+	if (pdata->gpio_power)
+		gpio_set_value(pdata->gpio_power, pdata->power_level);
+}
+
+void of_amlsd_pwr_off(struct amlsd_platform *pdata)
+{
+	if (pdata->gpio_power)
+		gpio_set_value(pdata->gpio_power, !pdata->power_level);
+}
+
+#ifdef CONFIG_AMLOGIC_M8B_MMC
+/*-----------sg copy buffer------------*/
+/**
+ * aml_sg_miter_stop - stop mapping iteration for amlogic,
+ * We don't disable irq in this function
+ */
+static void aml_sg_miter_stop(struct sg_mapping_iter *miter)
+{
+	WARN_ON(miter->consumed > miter->length);
+
+	/* drop resources from the last iteration */
+	if (miter->addr) {
+		miter->__offset += miter->consumed;
+		miter->__remaining -= miter->consumed;
+
+		if (miter->__flags & SG_MITER_TO_SG)
+			flush_kernel_dcache_page(miter->page);
+
+		if (miter->__flags & SG_MITER_ATOMIC) {
+			WARN_ON_ONCE(preemptible());
+			kunmap_atomic(miter->addr);
+		} else
+			kunmap(miter->page);
+
+		miter->page = NULL;
+		miter->addr = NULL;
+		miter->length = 0;
+		miter->consumed = 0;
+	}
+}
+
+/**
+ * aml_sg_miter_next - proceed mapping iterator to the next mapping for amlogic,
+ * We don't disable irq in this function
+ */
+static bool aml_sg_miter_next(struct sg_mapping_iter *miter)
+{
+	unsigned long flags;
+
+	sg_miter_stop(miter);
+
+	/*
+	 * Get to the next page if necessary.
+	 * __remaining, __offset is adjusted by sg_miter_stop
+	 */
+	if (!miter->__remaining) {
+		struct scatterlist *sg;
+		unsigned long pgoffset;
+
+		if (!__sg_page_iter_next(&miter->piter))
+			return false;
+
+		sg = miter->piter.sg;
+		pgoffset = miter->piter.sg_pgoffset;
+
+		miter->__offset = pgoffset ? 0 : sg->offset;
+		miter->__remaining = sg->offset + sg->length -
+				(pgoffset << PAGE_SHIFT) - miter->__offset;
+		miter->__remaining = min_t(unsigned long, miter->__remaining,
+					   PAGE_SIZE - miter->__offset);
+	}
+	miter->page = sg_page_iter_page(&miter->piter);
+	miter->consumed = miter->length = miter->__remaining;
+
+	if (miter->__flags & SG_MITER_ATOMIC) {
+		/*pr_info(KERN_DEBUG "AML_SDHC miter_next highmem\n"); */
+		local_irq_save(flags);
+		miter->addr = kmap_atomic(miter->page) + miter->__offset;
+		local_irq_restore(flags);
+	} else
+		miter->addr = kmap(miter->page) + miter->__offset;
+	return true;
+}
+
+/*
+ * aml_sg_copy_buffer - Copy data between a linear buffer
+ * and an SG list  for amlogic,
+ * We don't disable irq in this function
+ */
+EXPORT_SYMBOL(aml_sg_copy_buffer);
+size_t aml_sg_copy_buffer(struct scatterlist *sgl, unsigned int nents,
+			     void *buf, size_t buflen, int to_buffer)
+{
+	unsigned int offset = 0;
+	struct sg_mapping_iter miter;
+	unsigned int sg_flags = SG_MITER_ATOMIC;
+	unsigned long flags;
+
+	if (to_buffer)
+		sg_flags |= SG_MITER_FROM_SG;
+	else
+		sg_flags |= SG_MITER_TO_SG;
+
+	sg_miter_start(&miter, sgl, nents, sg_flags);
+	local_irq_save(flags);
+
+	while (aml_sg_miter_next(&miter) && offset < buflen) {
+		unsigned int len;
+
+		len = min(miter.length, buflen - offset);
+
+		if (to_buffer)
+			memcpy(buf + offset, miter.addr, len);
+		else
+			memcpy(miter.addr, buf + offset, len);
+
+		offset += len;
+	}
+
+	aml_sg_miter_stop(&miter);
+	local_irq_restore(flags);
+
+	return offset;
+}
+
+/*-------------------eMMC/tSD-------------------*/
+int storage_flag;
+
+bool is_emmc_exist(struct amlsd_host *host) // is eMMC/tSD exist
+{
+	print_tmp("host->storage_flag=%d, POR_BOOT_VALUE=%d\n",
+			host->storage_flag, POR_BOOT_VALUE);
+	if ((host->storage_flag == EMMC_BOOT_FLAG)
+			|| (host->storage_flag == SPI_EMMC_FLAG)
+			|| (((host->storage_flag == 0)
+					|| (host->storage_flag == -1))
+				&& (POR_EMMC_BOOT() || POR_SPI_BOOT())))
+		return true;
+
+	return false;
+}
+
+/*-------------------debug---------------------*/
+
+unsigned long sdhc_debug; // 0xffffffff;
+static int __init sdhc_debug_setup(char *str)
+{
+	ssize_t status = 0;
+
+	status = kstrtol(str, 0, &sdhc_debug);
+	return 1;
+}
+__setup("sdhc_debug=", sdhc_debug_setup);
+
+unsigned long sdio_debug; // 0xffffff;
+static int __init sdio_debug_setup(char *str)
+{
+	ssize_t status = 0;
+
+	status = kstrtol(str, 0, &sdio_debug);
+	return 1;
+}
+__setup("sdio_debug=", sdio_debug_setup);
+#endif
diff --git a/drivers/amlogic/mmc/amlsd_of.c b/drivers/amlogic/mmc/amlsd_of.c
new file mode 100644
index 0000000..0282cf0
--- /dev/null
+++ b/drivers/amlogic/mmc/amlsd_of.c
@@ -0,0 +1,216 @@
+/*
+ * drivers/amlogic/mmc/amlsd_of.c
+ *
+ * Copyright (C) 2017 Amlogic, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ */
+
+#include <linux/debugfs.h>
+#include <linux/kernel.h>
+#include <linux/dma-mapping.h>
+#include <linux/platform_device.h>
+#include <linux/mmc/host.h>
+#include <linux/mmc/core.h>
+#include <linux/mmc/mmc.h>
+#include <linux/mtd/partitions.h>
+#include <linux/slab.h>
+#include <linux/amlogic/sd.h>
+#include <linux/gpio/consumer.h>
+#include <linux/amlogic/amlsd.h>
+#include <linux/amlogic/cpu_version.h>
+
+unsigned int sd_emmc_debug;
+
+static const struct sd_caps host_caps[] = {
+	SD_CAPS(MMC_CAP_4_BIT_DATA, "MMC_CAP_4_BIT_DATA"),
+	SD_CAPS(MMC_CAP_MMC_HIGHSPEED, "MMC_CAP_MMC_HIGHSPEED"),
+	SD_CAPS(MMC_CAP_SD_HIGHSPEED, "MMC_CAP_SD_HIGHSPEED"),
+	SD_CAPS(MMC_CAP_SDIO_IRQ, "MMC_CAP_SDIO_IRQ"),
+	SD_CAPS(MMC_CAP_SPI, "MMC_CAP_SPI"),
+	SD_CAPS(MMC_CAP_NEEDS_POLL, "MMC_CAP_NEEDS_POLL"),
+	SD_CAPS(MMC_CAP_8_BIT_DATA, "MMC_CAP_8_BIT_DATA"),
+	SD_CAPS(MMC_CAP_NONREMOVABLE, "MMC_CAP_NONREMOVABLE"),
+	SD_CAPS(MMC_CAP_WAIT_WHILE_BUSY, "MMC_CAP_WAIT_WHILE_BUSY"),
+	SD_CAPS(MMC_CAP_ERASE, "MMC_CAP_ERASE"),
+	SD_CAPS(MMC_CAP_1_8V_DDR, "MMC_CAP_1_8V_DDR"),
+	SD_CAPS(MMC_CAP_1_2V_DDR, "MMC_CAP_1_2V_DDR"),
+	SD_CAPS(MMC_CAP_POWER_OFF_CARD, "MMC_CAP_POWER_OFF_CARD"),
+	SD_CAPS(MMC_CAP_BUS_WIDTH_TEST, "MMC_CAP_BUS_WIDTH_TEST"),
+	SD_CAPS(MMC_CAP_UHS_SDR12, "MMC_CAP_UHS_SDR12"),
+	SD_CAPS(MMC_CAP_UHS_SDR25, "MMC_CAP_UHS_SDR25"),
+	SD_CAPS(MMC_CAP_UHS_SDR50, "MMC_CAP_UHS_SDR50"),
+	SD_CAPS(MMC_CAP_UHS_SDR104, "MMC_CAP_UHS_SDR104"),
+	SD_CAPS(MMC_CAP_UHS_DDR50, "MMC_CAP_UHS_DDR50"),
+	SD_CAPS(MMC_CAP_DRIVER_TYPE_A, "MMC_CAP_DRIVER_TYPE_A"),
+	SD_CAPS(MMC_CAP_DRIVER_TYPE_C, "MMC_CAP_DRIVER_TYPE_C"),
+	SD_CAPS(MMC_CAP_DRIVER_TYPE_D, "MMC_CAP_DRIVER_TYPE_D"),
+	SD_CAPS(MMC_CAP_CMD23, "MMC_CAP_CMD23"),
+	SD_CAPS(MMC_CAP_HW_RESET, "MMC_CAP_HW_RESET"),
+	SD_CAPS(MMC_CAP_AGGRESSIVE_PM, "MMC_CAP_AGGRESSIVE_PM"),
+	SD_CAPS(MMC_PM_KEEP_POWER, "MMC_PM_KEEP_POWER"),
+};
+
+static int amlsd_get_host_caps(struct device_node *of_node,
+		struct amlsd_platform *pdata)
+{
+	const char *str_caps;
+	struct property *prop;
+	u32 i, caps = 0;
+
+	of_property_for_each_string(of_node, "caps", prop, str_caps) {
+		for (i = 0; i < ARRAY_SIZE(host_caps); i++) {
+			if (!strcasecmp(host_caps[i].name, str_caps))
+				caps |= host_caps[i].caps;
+		}
+	};
+	if (caps & MMC_CAP_8_BIT_DATA)
+		caps |= MMC_CAP_4_BIT_DATA;
+
+	pdata->caps = caps;
+	pr_info("%s:pdata->caps = %x\n", pdata->pinname, pdata->caps);
+	return 0;
+}
+
+static const struct sd_caps host_caps2[] = {
+	SD_CAPS(MMC_CAP2_BOOTPART_NOACC, "MMC_CAP2_BOOTPART_NOACC"),
+	/*SD_CAPS(MMC_CAP2_CACHE_CTRL, "MMC_CAP2_CACHE_CTRL"),*/
+	/* SD_CAPS(MMC_CAP2_POWEROFF_NOTIFY, "MMC_CAP2_POWEROFF_NOTIFY"), */
+	SD_CAPS(MMC_CAP2_NO_MULTI_READ, "MMC_CAP2_NO_MULTI_READ"),
+	/*SD_CAPS(MMC_CAP2_NO_SLEEP_CMD, "MMC_CAP2_NO_SLEEP_CMD"),*/
+	SD_CAPS(MMC_CAP2_HS200_1_8V_SDR, "MMC_CAP2_HS200_1_8V_SDR"),
+	SD_CAPS(MMC_CAP2_HS200_1_2V_SDR, "MMC_CAP2_HS200_1_2V_SDR"),
+	SD_CAPS(MMC_CAP2_HS200, "MMC_CAP2_HS200"),
+	SD_CAPS(MMC_CAP2_HS400_1_8V, "MMC_CAP2_HS400_1_8V"),
+	SD_CAPS(MMC_CAP2_HS400_1_2V, "MMC_CAP2_HS400_1_2V"),
+	SD_CAPS(MMC_CAP2_HS400, "MMC_CAP2_HS400"),
+	/*SD_CAPS(MMC_CAP2_BROKEN_VOLTAGE, "MMC_CAP2_BROKEN_VOLTAGE"),*/
+	/* SD_CAPS(MMC_CAP2_DETECT_ON_ERR, "MMC_CAP2_DETECT_ON_ERR"), */
+	SD_CAPS(MMC_CAP2_HC_ERASE_SZ, "MMC_CAP2_HC_ERASE_SZ"),
+	SD_CAPS(MMC_CAP2_CD_ACTIVE_HIGH, "MMC_CAP2_CD_ACTIVE_HIGH"),
+	SD_CAPS(MMC_CAP2_RO_ACTIVE_HIGH, "MMC_CAP2_RO_ACTIVE_HIGH"),
+};
+
+static int amlsd_get_host_caps2(struct device_node *of_node,
+		struct amlsd_platform *pdata)
+{
+	const char *str_caps;
+	struct property *prop;
+	u32 i, caps = 0;
+
+	of_property_for_each_string(of_node, "caps2", prop, str_caps) {
+		for (i = 0; i < ARRAY_SIZE(host_caps2); i++) {
+			if (!strcasecmp(host_caps2[i].name, str_caps))
+				caps |= host_caps2[i].caps;
+		}
+	};
+	pdata->caps2 = caps;
+	pr_info("%s:pdata->caps2 = %x\n", pdata->pinname, pdata->caps2);
+	return 0;
+}
+
+int amlsd_get_platform_data(struct platform_device *pdev,
+		struct amlsd_platform *pdata,
+		struct mmc_host *mmc, u32 index)
+{
+	struct device_node *of_node;
+	struct device_node *child;
+	u32 i, prop;
+	const char *str = "none";
+
+#ifdef CONFIG_AMLOGIC_M8B_MMC
+	of_node = pdev->dev.of_node;
+#else
+	if (!mmc->parent)
+		return 0;
+	of_node = mmc->parent->of_node;
+#endif
+	if (of_node) {
+		child = of_node->child;
+		WARN_ON(!child);
+		WARN_ON(index >= MMC_MAX_DEVICE);
+		for (i = 0; i < index; i++)
+			child = child->sibling;
+		if (!child)
+			return -EINVAL;
+
+		/*	amlsd_init_pins_input(child, pdata);*/
+
+		SD_PARSE_U32_PROP_HEX(child, "port",
+				prop, pdata->port);
+		SD_PARSE_U32_PROP_HEX(child, "ocr_avail",
+				prop, pdata->ocr_avail);
+		WARN_ON(!pdata->ocr_avail);
+		SD_PARSE_U32_PROP_DEC(child, "f_min",
+				prop, pdata->f_min);
+		SD_PARSE_U32_PROP_DEC(child, "f_max",
+				prop, pdata->f_max);
+		SD_PARSE_U32_PROP_HEX(child, "max_req_size",
+				prop, pdata->max_req_size);
+		SD_PARSE_GPIO_NUM_PROP(child, "gpio_cd",
+				str, pdata->gpio_cd);
+		SD_PARSE_GPIO_NUM_PROP(child, "gpio_ro",
+				str, pdata->gpio_ro);
+		SD_PARSE_GPIO_NUM_PROP(child, "vol_switch",
+				str, pdata->vol_switch);
+
+		SD_PARSE_U32_PROP_HEX(child, "power_level",
+				prop, pdata->power_level);
+		SD_PARSE_GPIO_NUM_PROP(child, "gpio_power",
+				str, pdata->gpio_power);
+
+		SD_PARSE_U32_PROP_DEC(child, "gpio_cd_level",
+				prop, pdata->gpio_cd_level);
+		SD_PARSE_STRING_PROP(child, "pinname",
+				str, pdata->pinname);
+		SD_PARSE_U32_PROP_DEC(child, "auto_clk_close",
+				prop, pdata->auto_clk_close);
+		SD_PARSE_U32_PROP_DEC(child, "vol_switch_18",
+				prop, pdata->vol_switch_18);
+		SD_PARSE_U32_PROP_DEC(child, "vol_switch_delay",
+				prop, pdata->vol_switch_delay);
+		SD_PARSE_U32_PROP_DEC(child, "card_type",
+				prop, pdata->card_type);
+		if (get_cpu_type() > MESON_CPU_MAJOR_ID_M8B) {
+			if (aml_card_type_mmc(pdata)) {
+				/*tx_phase set default value first*/
+				if (get_cpu_type() == MESON_CPU_MAJOR_ID_GXTVBB)
+					pdata->tx_phase = 1;
+				if (get_cpu_type() == MESON_CPU_MAJOR_ID_TXL)
+					pdata->tx_delay = 3;
+				SD_PARSE_U32_PROP_DEC(child, "tx_phase",
+						prop, pdata->tx_phase);
+			}
+			if (aml_card_type_non_sdio(pdata)) {
+				/*card in default value*/
+				pdata->card_in_delay = 0;
+				SD_PARSE_U32_PROP_DEC(child, "card_in_delay",
+						prop, pdata->card_in_delay);
+			}
+		}
+		SD_PARSE_GPIO_NUM_PROP(child, "hw_reset",
+				str, pdata->hw_reset);
+		SD_PARSE_GPIO_NUM_PROP(child, "gpio_dat3",
+				str, pdata->gpio_dat3);
+
+		pdata->xfer_pre = of_amlsd_xfer_pre;
+		pdata->xfer_post = of_amlsd_xfer_post;
+
+		amlsd_get_host_caps(child, pdata);
+		amlsd_get_host_caps2(child, pdata);
+		pdata->port_init = of_amlsd_init;
+		pdata->irq_init = of_amlsd_irq_init;
+		pdata->ro = of_amlsd_ro;
+	}
+	return 0;
+}
+
diff --git a/drivers/amlogic/mmc/emmc_key.c b/drivers/amlogic/mmc/emmc_key.c
new file mode 100644
index 0000000..6df23b8
--- /dev/null
+++ b/drivers/amlogic/mmc/emmc_key.c
@@ -0,0 +1,213 @@
+/*
+ * drivers/amlogic/mmc/emmc_key.c
+ *
+ * Copyright (C) 2017 Amlogic, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ */
+
+#include <linux/types.h>
+#include <linux/err.h>
+#include <linux/mtd/mtd.h>
+#include <linux/mtd/partitions.h>
+#include <linux/slab.h>
+#include <linux/mmc/card.h>
+#include <linux/mmc/emmc_partitions.h>
+#include <linux/amlogic/key_manage.h>
+#include "emmc_key.h"
+#include "../../mmc/core/core.h"
+
+#define		EMMC_BLOCK_SIZE		(0x100)
+#define		MAX_EMMC_BLOCK_SIZE	(128*1024)
+
+/*
+ * kernel head file
+ *
+ */
+static struct mmc_card *mmc_card_key;
+static struct aml_emmckey_info_t *emmckey_info;
+
+static int aml_emmc_key_check(void)
+{
+	u8 keypart_cnt;
+	u64 part_size;
+	struct emmckey_valid_node_t *emmckey_valid_node, *temp_valid_node;
+
+	emmckey_info->key_part_count =
+		emmckey_info->keyarea_phy_size / EMMC_KEYAREA_SIZE;
+
+	if (emmckey_info->key_part_count
+			> EMMC_KEYAREA_COUNT) {
+		emmckey_info->key_part_count = EMMC_KEYAREA_COUNT;
+	}
+	keypart_cnt = 0;
+	part_size = EMMC_KEYAREA_SIZE;
+	do {
+		emmckey_valid_node = kmalloc(
+			sizeof(*emmckey_valid_node), GFP_KERNEL);
+
+		if (emmckey_valid_node == NULL) {
+			pr_info("%s:%d,kmalloc memory fail\n",
+				__func__, __LINE__);
+			return -ENOMEM;
+		}
+		emmckey_valid_node->phy_addr = emmckey_info->keyarea_phy_addr
+						+ part_size * keypart_cnt;
+		emmckey_valid_node->phy_size = EMMC_KEYAREA_SIZE;
+		emmckey_valid_node->next = NULL;
+		emmckey_info->key_valid = 0;
+		if (emmckey_info->key_valid_node == NULL) {
+
+			emmckey_info->key_valid_node = emmckey_valid_node;
+
+		} else{
+			temp_valid_node = emmckey_info->key_valid_node;
+
+			while (temp_valid_node->next != NULL)
+				temp_valid_node = temp_valid_node->next;
+
+			temp_valid_node->next = emmckey_valid_node;
+		}
+	} while (++keypart_cnt < emmckey_info->key_part_count);
+
+	emmckey_info->key_valid = 1;
+	return 0;
+}
+
+int32_t emmc_key_read(uint8_t *buffer,
+	uint32_t length, uint32_t *actual_length)
+{
+	int ret;
+	u64  addr = 0;
+	u32  size = 0;
+	int blk, cnt;
+	unsigned char *dst = NULL;
+	struct mmc_card *card = mmc_card_key;
+	int bit = card->csd.read_blkbits;
+
+	size = length;
+	*actual_length = length;
+	addr = get_reserve_partition_off_from_tbl() + EMMCKEY_RESERVE_OFFSET;
+	blk = addr >> bit;
+	cnt = size >> bit;
+	dst = (unsigned char *)buffer;
+	mmc_claim_host(card->host);
+	do {
+		ret = mmc_read_internal(card, blk, EMMC_BLOCK_SIZE, dst);
+		if (ret) {
+			pr_err("%s [%d] mmc_write_internal error\n",
+				__func__, __LINE__);
+			return ret;
+		}
+		blk += EMMC_BLOCK_SIZE;
+		cnt -= EMMC_BLOCK_SIZE;
+		dst = (unsigned char *)buffer + MAX_EMMC_BLOCK_SIZE;
+	} while (cnt != 0);
+	pr_info("%s:%d, read %s\n", __func__, __LINE__, (ret) ? "error":"ok");
+
+	mmc_release_host(card->host);
+	return ret;
+}
+EXPORT_SYMBOL(emmc_key_read);
+
+int32_t emmc_key_write(uint8_t *buffer,
+	uint32_t length, uint32_t *actual_length)
+{
+	int ret;
+	u64  addr = 0;
+	u32  size = 0;
+	int blk, cnt;
+	unsigned char *src = NULL;
+	struct mmc_card *card = mmc_card_key;
+	int bit = card->csd.read_blkbits;
+
+	size = length;
+	addr = get_reserve_partition_off_from_tbl() + EMMCKEY_RESERVE_OFFSET;
+	blk = addr >> bit;
+	cnt = size >> bit;
+	src = (unsigned char *)buffer;
+	mmc_claim_host(card->host);
+	do {
+		ret = mmc_write_internal(card, blk, EMMC_BLOCK_SIZE, src);
+		if (ret) {
+			pr_err("%s [%d] mmc_write_internal error\n",
+				__func__, __LINE__);
+			return ret;
+		}
+		blk += EMMC_BLOCK_SIZE;
+		cnt -= EMMC_BLOCK_SIZE;
+		src = (unsigned char *)buffer + MAX_EMMC_BLOCK_SIZE;
+	} while (cnt != 0);
+	pr_info("%s:%d, write %s\n", __func__, __LINE__, (ret) ? "error":"ok");
+	mmc_release_host(card->host);
+	return ret;
+}
+EXPORT_SYMBOL(emmc_key_write);
+
+int emmc_key_init(struct mmc_card *card)
+{
+	u64  addr = 0;
+	u32  size = 0;
+	u64  lba_start = 0, lba_end = 0;
+	int err = 0;
+	int bit = card->csd.read_blkbits;
+
+	pr_info("card key: card_blk_probe.\n");
+	emmckey_info = kmalloc(sizeof(*emmckey_info), GFP_KERNEL);
+	if (emmckey_info == NULL) {
+		pr_info("%s:%d,kmalloc memory fail\n", __func__, __LINE__);
+		return -ENOMEM;
+	}
+	memset(emmckey_info, 0, sizeof(*emmckey_info));
+	emmckey_info->key_init = 0;
+
+	size = EMMCKEY_AREA_PHY_SIZE;
+	addr = get_reserve_partition_off_from_tbl() + EMMCKEY_RESERVE_OFFSET;
+	if (addr < 0) {
+		err = -EINVAL;
+		goto exit_err;
+	}
+	lba_start = addr >> bit;
+	lba_end = (addr + size) >> bit;
+	emmckey_info->key_init = 1;
+
+	pr_info("%s:%d emmc key lba_start:0x%llx,lba_end:0x%llx\n",
+	 __func__, __LINE__, lba_start, lba_end);
+
+	if (!emmckey_info->key_init) {
+		err = -EINVAL;
+
+		pr_info("%s:%d,emmc key init fail\n", __func__, __LINE__);
+		goto exit_err;
+	}
+	emmckey_info->keyarea_phy_addr = addr;
+	emmckey_info->keyarea_phy_size = size;
+	emmckey_info->lba_start = lba_start;
+	emmckey_info->lba_end   = lba_end;
+	mmc_card_key = card;
+	err = aml_emmc_key_check();
+	if (err) {
+		pr_info("%s:%d,emmc key check fail\n", __func__, __LINE__);
+	goto exit_err;
+	}
+
+	storage_ops_read(emmc_key_read);
+	storage_ops_write(emmc_key_write);
+
+	pr_info("emmc key: %s:%d ok.\n", __func__, __LINE__);
+	return err;
+
+exit_err:
+	kfree(emmckey_info);
+	return err;
+}
+
diff --git a/drivers/amlogic/mmc/emmc_key.h b/drivers/amlogic/mmc/emmc_key.h
new file mode 100644
index 0000000..67b5675
--- /dev/null
+++ b/drivers/amlogic/mmc/emmc_key.h
@@ -0,0 +1,74 @@
+/*
+ * drivers/amlogic/mmc/emmc_key.h
+ *
+ * Copyright (C) 2017 Amlogic, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ */
+
+#ifndef __EMMC_KEY_H__
+#define __EMMC_KEY_H__
+
+#include <linux/mmc/host.h>
+#include <linux/mmc/card.h>
+#include <linux/mmc/mmc.h>
+#include <linux/mmc/core.h>
+
+#define EMMC_KEY_AREA_SIGNAL		"emmckeys"
+#define EMMC_KEY_AREA_SIGNAL_LEN	16
+
+#define EMMC_KEYAREA_SIZE		(128*1024)
+#define EMMC_KEYAREA_COUNT		2
+
+/* we store partition table in the previous 16KB space */
+#define EMMCKEY_RESERVE_OFFSET          0x4000
+#define EMMCKEY_AREA_PHY_SIZE           (EMMC_KEYAREA_COUNT * EMMC_KEYAREA_SIZE)
+
+struct emmckey_valid_node_t {
+	u64 phy_addr;
+	u64 phy_size;
+	struct emmckey_valid_node_t *next;
+};
+
+struct aml_emmckey_info_t {
+	/* struct memory_card *card; */
+	struct emmckey_valid_node_t *key_valid_node;
+	u64    keyarea_phy_addr;
+	u64    keyarea_phy_size;
+	u64    lba_start;
+	u64    lba_end;
+	u32    blk_size;
+	u32    blk_shift;
+	u8     key_init;
+	u8     key_valid;
+	u8     key_part_count;
+};
+
+#define EMMCKEY_DATA_VALID_LEN		\
+	(EMMC_KEYAREA_SIZE - EMMC_KEY_AREA_SIGNAL_LEN - 4 - 4 - 4)
+struct emmckey_data_t {
+	u8     keyarea_mark[EMMC_KEY_AREA_SIGNAL_LEN];
+	u32	   keyarea_mark_checksum;
+	u32    checksum;
+	u32    reserve;
+	u8     data[EMMCKEY_DATA_VALID_LEN];
+};
+
+int emmc_key_init(struct mmc_card *card);
+
+int32_t emmc_key_read(uint8_t *buffer,
+	uint32_t length, uint32_t *actual_length);
+int32_t emmc_key_write(uint8_t *buffer,
+	uint32_t length, uint32_t *actual_length);
+
+#endif
+
diff --git a/drivers/amlogic/mmc/emmc_partitions.c b/drivers/amlogic/mmc/emmc_partitions.c
new file mode 100644
index 0000000..5a4e971
--- /dev/null
+++ b/drivers/amlogic/mmc/emmc_partitions.c
@@ -0,0 +1,1018 @@
+/*
+ * drivers/amlogic/mmc/emmc_partitions.c
+ *
+ * Copyright (C) 2017 Amlogic, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ */
+
+#include <linux/types.h>
+#include <linux/stddef.h>
+#include <linux/mtd/mtd.h>
+#include <linux/mtd/partitions.h>
+#include <linux/proc_fs.h>
+#include <linux/seq_file.h>
+#include <linux/genhd.h>
+#include <linux/blkdev.h>
+#include <linux/scatterlist.h>
+#include <linux/cdev.h>
+#include <linux/device.h>
+#include <linux/uaccess.h>
+#include <linux/vmalloc.h>
+
+#include <linux/mmc/emmc_partitions.h>
+#include <linux/amlogic/cpu_version.h>
+#include <linux/amlogic/iomap.h>
+#include <linux/amlogic/sd.h>
+#include "emmc_key.h"
+#include "../../mmc/core/core.h"
+
+#define DTB_NAME	"dtb"
+#define	SZ_1M	0x00100000
+#define		MMC_DTB_PART_OFFSET		(40*SZ_1M)
+#define		EMMC_BLOCK_SIZE		(0x100)
+#define		MAX_EMMC_BLOCK_SIZE		(128*1024)
+
+static dev_t amlmmc_dtb_no;
+struct cdev amlmmc_dtb;
+struct device *dtb_dev;
+struct class *amlmmc_dtb_class;
+struct mmc_card *card_dtb;
+struct mmc_partitions_fmt *pt_fmt;
+
+int amlmmc_dtb_write(struct mmc_card *card,
+		unsigned char *buf, int len)
+{
+	int ret = 0, start_blk, size, blk_cnt;
+	int bit = card->csd.read_blkbits;
+	unsigned char *src = NULL;
+
+	if (len > CONFIG_DTB_SIZE) {
+		pr_err("%s dtb data len too much", __func__);
+		return -EFAULT;
+	}
+	start_blk = MMC_DTB_PART_OFFSET;
+	if (start_blk < 0) {
+		ret = -EINVAL;
+		return ret;
+	}
+	start_blk >>= bit;
+	size = CONFIG_DTB_SIZE;
+	blk_cnt = size>>bit;
+	src = (unsigned char *)buf;
+	do {
+		ret = mmc_write_internal(card, start_blk, EMMC_BLOCK_SIZE, src);
+		if (ret) {
+			pr_err("%s: save dtb error", __func__);
+			ret = -EFAULT;
+			return ret;
+		}
+		start_blk += EMMC_BLOCK_SIZE;
+		blk_cnt -= EMMC_BLOCK_SIZE;
+		src = (unsigned char *)buf + MAX_EMMC_BLOCK_SIZE;
+	} while (blk_cnt != 0);
+
+	return ret;
+}
+
+int amlmmc_dtb_read(struct mmc_card *card,
+		unsigned char *buf, int len)
+{
+	int ret = 0, start_blk, size, blk_cnt;
+	int bit = card->csd.read_blkbits;
+	unsigned char *dst = NULL;
+
+	if (len > CONFIG_DTB_SIZE) {
+		pr_err("%s dtb data len too much", __func__);
+		return -EFAULT;
+	}
+	memset(buf, 0x0, len);
+
+	start_blk = MMC_DTB_PART_OFFSET;
+	if (start_blk < 0) {
+		ret = -EINVAL;
+		return ret;
+	}
+
+	start_blk >>= bit;
+	size = CONFIG_DTB_SIZE;
+	blk_cnt = size>>bit;
+	dst = (unsigned char *)buf;
+	do {
+		ret = mmc_read_internal(card, start_blk, EMMC_BLOCK_SIZE, dst);
+		if (ret) {
+			pr_err("%s read dtb error", __func__);
+			ret = -EFAULT;
+			return ret;
+		}
+		start_blk += EMMC_BLOCK_SIZE;
+		blk_cnt -= EMMC_BLOCK_SIZE;
+		dst = (unsigned char *)buf + MAX_EMMC_BLOCK_SIZE;
+	} while (blk_cnt != 0);
+	return ret;
+}
+static CLASS_ATTR(emmcdtb, 0644, NULL, NULL);
+
+int mmc_dtb_open(struct inode *node, struct file *file)
+{
+	return 0;
+}
+
+ssize_t mmc_dtb_read(struct file *file,
+		char __user *buf,
+		size_t count,
+		loff_t *ppos)
+{
+	unsigned char *dtb_ptr = NULL;
+	ssize_t read_size = 0;
+	int ret = 0;
+
+	if (*ppos == CONFIG_DTB_SIZE)
+		return 0;
+
+	if (*ppos >= CONFIG_DTB_SIZE) {
+		pr_err("%s: out of space!", __func__);
+		return -EFAULT;
+	}
+
+	dtb_ptr = vmalloc(CONFIG_DTB_SIZE);
+	if (dtb_ptr == NULL) {
+		/*	pr_err("%s: malloc buf failed", __func__);*/
+		return -ENOMEM;
+	}
+
+	mmc_claim_host(card_dtb->host);
+	ret = amlmmc_dtb_read(card_dtb,
+			(unsigned char *)dtb_ptr,
+			CONFIG_DTB_SIZE);
+	if (ret) {
+		pr_err("%s: read failed:%d", __func__, ret);
+		ret = -EFAULT;
+		goto exit;
+	}
+	if ((*ppos + count) > CONFIG_DTB_SIZE)
+		read_size = CONFIG_DTB_SIZE - *ppos;
+	else
+		read_size = count;
+	ret = copy_to_user(buf, (dtb_ptr + *ppos), read_size);
+	*ppos += read_size;
+exit:
+	mmc_release_host(card_dtb->host);
+	vfree(dtb_ptr);
+	return read_size;
+}
+
+ssize_t mmc_dtb_write(struct file *file,
+		const char __user *buf,
+		size_t count, loff_t *ppos)
+{
+	unsigned char *dtb_ptr = NULL;
+	ssize_t write_size = 0;
+	int ret = 0;
+
+	if (*ppos == CONFIG_DTB_SIZE)
+		return 0;
+
+	if (*ppos >= CONFIG_DTB_SIZE) {
+		pr_err("%s: out of space!", __func__);
+		return -EFAULT;
+	}
+	dtb_ptr = vmalloc(CONFIG_DTB_SIZE);
+	if (dtb_ptr == NULL) {
+		/*	pr_err("%s: malloc buf failed", __func__);*/
+		return -ENOMEM;
+	}
+	mmc_claim_host(card_dtb->host);
+
+	if ((*ppos + count) > CONFIG_DTB_SIZE)
+		write_size = CONFIG_DTB_SIZE - *ppos;
+	else
+		write_size = count;
+
+	ret = copy_from_user((dtb_ptr + *ppos), buf, write_size);
+
+	ret = amlmmc_dtb_write(card_dtb,
+			dtb_ptr, CONFIG_DTB_SIZE);
+	if (ret) {
+		pr_err("%s: write dtb failed", __func__);
+		ret = -EFAULT;
+		goto exit;
+	}
+
+	*ppos += write_size;
+exit:
+	mmc_release_host(card_dtb->host);
+	/* kfree(dtb_ptr); */
+	vfree(dtb_ptr);
+	return write_size;
+}
+
+long mmc_dtb_ioctl(struct file *file, unsigned int cmd, unsigned long args)
+{
+	return 0;
+}
+
+static const struct file_operations dtb_ops = {
+	.open = mmc_dtb_open,
+	.read = mmc_dtb_read,
+	.write = mmc_dtb_write,
+	.unlocked_ioctl = mmc_dtb_ioctl,
+};
+
+int amlmmc_dtb_init(struct mmc_card *card)
+{
+	int ret = 0;
+
+	card_dtb = card;
+	pr_info("%s: register dtb chardev", __func__);
+	ret = alloc_chrdev_region(&amlmmc_dtb_no, 0, 1, DTB_NAME);
+	if (ret < 0) {
+		pr_err("alloc dtb dev_t no failed");
+		ret = -1;
+		goto exit_err;
+	}
+
+	cdev_init(&amlmmc_dtb, &dtb_ops);
+	amlmmc_dtb.owner = THIS_MODULE;
+	ret = cdev_add(&amlmmc_dtb, amlmmc_dtb_no, 1);
+	if (ret) {
+		pr_err("dtb dev add failed");
+		ret = -1;
+		goto exit_err1;
+	}
+
+	amlmmc_dtb_class = class_create(THIS_MODULE, DTB_NAME);
+	if (IS_ERR(amlmmc_dtb_class)) {
+		pr_err("dtb dev add failed");
+		ret = -1;
+		goto exit_err2;
+	}
+
+	ret = class_create_file(amlmmc_dtb_class, &class_attr_emmcdtb);
+	if (ret) {
+		pr_err("dtb dev add failed");
+		ret = -1;
+		goto exit_err2;
+	}
+
+	dtb_dev = device_create(amlmmc_dtb_class,
+			NULL,
+			amlmmc_dtb_no,
+			NULL,
+			DTB_NAME);
+	if (IS_ERR(dtb_dev)) {
+		pr_err("dtb dev add failed");
+		ret = -1;
+		goto exit_err3;
+	}
+
+	pr_info("%s: register dtb chardev OK", __func__);
+
+	return ret;
+
+exit_err3:
+	class_remove_file(amlmmc_dtb_class, &class_attr_emmcdtb);
+	class_destroy(amlmmc_dtb_class);
+exit_err2:
+	cdev_del(&amlmmc_dtb);
+exit_err1:
+	unregister_chrdev_region(amlmmc_dtb_no, 1);
+exit_err:
+	return ret;
+}
+
+/*
+ * Checks that a normal transfer didn't have any errors
+ */
+static int mmc_check_result(struct mmc_request *mrq)
+{
+	int ret;
+
+	WARN_ON(!mrq || !mrq->cmd || !mrq->data);
+
+	ret = 0;
+
+	if (!ret && mrq->cmd->error)
+		ret = mrq->cmd->error;
+	if (!ret && mrq->data->error)
+		ret = mrq->data->error;
+	if (!ret && mrq->stop && mrq->stop->error)
+		ret = mrq->stop->error;
+	if (!ret && mrq->data->bytes_xfered !=
+			mrq->data->blocks * mrq->data->blksz)
+		ret = RESULT_FAIL;
+
+	if (ret == -EINVAL)
+		ret = RESULT_UNSUP_HOST;
+
+	return ret;
+}
+
+static void mmc_prepare_mrq(struct mmc_card *card,
+		struct mmc_request *mrq, struct scatterlist *sg,
+		unsigned int sg_len, unsigned int dev_addr, unsigned int blocks,
+		unsigned int blksz, int write)
+{
+	WARN_ON(!mrq || !mrq->cmd || !mrq->data || !mrq->stop);
+
+	if (blocks > 1) {
+		mrq->cmd->opcode = write ?
+			MMC_WRITE_MULTIPLE_BLOCK : MMC_READ_MULTIPLE_BLOCK;
+	} else {
+		mrq->cmd->opcode = write ?
+			MMC_WRITE_BLOCK : MMC_READ_SINGLE_BLOCK;
+	}
+
+	mrq->cmd->arg = dev_addr;
+	if (!mmc_card_blockaddr(card))
+		mrq->cmd->arg <<= 9;
+
+	mrq->cmd->flags = MMC_RSP_R1 | MMC_CMD_ADTC;
+
+	if (blocks == 1)
+		mrq->stop = NULL;
+	else {
+		mrq->stop->opcode = MMC_STOP_TRANSMISSION;
+		mrq->stop->arg = 0;
+		mrq->stop->flags = MMC_RSP_R1B | MMC_CMD_AC;
+	}
+
+	mrq->data->blksz = blksz;
+	mrq->data->blocks = blocks;
+	mrq->data->flags = write ? MMC_DATA_WRITE : MMC_DATA_READ;
+	mrq->data->sg = sg;
+	mrq->data->sg_len = sg_len;
+
+	mmc_set_data_timeout(mrq->data, card);
+}
+
+unsigned int mmc_capacity(struct mmc_card *card)
+{
+	if (!mmc_card_sd(card) && mmc_card_blockaddr(card))
+		return card->ext_csd.sectors;
+	else
+		return card->csd.capacity << (card->csd.read_blkbits - 9);
+}
+
+static int mmc_transfer(struct mmc_card *card, unsigned int dev_addr,
+		unsigned int blocks, void *buf, int write)
+{
+	unsigned int size;
+	struct scatterlist sg;
+	struct mmc_request mrq = {0};
+	struct mmc_command cmd = {0};
+	struct mmc_command stop = {0};
+	struct mmc_data data = {0};
+	int ret;
+
+	if ((dev_addr + blocks) >= mmc_capacity(card)) {
+		pr_info("[%s] %s range exceeds device capacity!\n",
+				__func__, write?"write":"read");
+		ret = -1;
+		return ret;
+	}
+
+	size = blocks << card->csd.read_blkbits;
+	sg_init_one(&sg, buf, size);
+
+	mrq.cmd = &cmd;
+	mrq.data = &data;
+	mrq.stop = &stop;
+
+	mmc_prepare_mrq(card, &mrq, &sg, 1, dev_addr,
+			blocks, 1<<card->csd.read_blkbits, write);
+
+	mmc_wait_for_req(card->host, &mrq);
+
+	ret = mmc_check_result(&mrq);
+	return ret;
+}
+
+int mmc_read_internal(struct mmc_card *card, unsigned int dev_addr,
+		unsigned int blocks, void *buf)
+{
+	return mmc_transfer(card, dev_addr, blocks, buf, 0);
+}
+
+int mmc_write_internal(struct mmc_card *card, unsigned int dev_addr,
+		unsigned int blocks, void *buf)
+{
+	return mmc_transfer(card, dev_addr, blocks, buf, 1);
+}
+
+
+static int mmc_partition_tbl_checksum_calc(
+		struct partitions *part, int part_num)
+{
+	int i, j;
+	u32 checksum = 0, *p;
+
+	for (i = 0; i < part_num; i++) {
+		p = (u32 *)part;
+
+		for (j = sizeof(struct partitions)/sizeof(checksum);
+				j > 0; j--) {
+			checksum += *p;
+			p++;
+		}
+	}
+
+	return checksum;
+}
+
+int get_reserve_partition_off(struct mmc_card *card) /* byte unit */
+{
+	int off = -1, storage_flag;
+	struct mmc_host *mmc_host = card->host;
+	struct amlsd_host *host = mmc_priv(mmc_host);
+
+	storage_flag = host->storage_flag;
+	if (!strcmp(mmc_hostname(mmc_host), "mmc1"))//emmc
+		storage_flag = EMMC_BOOT_FLAG;
+	if ((storage_flag == EMMC_BOOT_FLAG)
+			|| (storage_flag == SPI_EMMC_FLAG))	{
+		off = MMC_BOOT_PARTITION_SIZE + MMC_BOOT_PARTITION_RESERVED;
+	} else if ((storage_flag == 0) || (storage_flag == -1)) {
+		if (POR_EMMC_BOOT()) {
+			off = MMC_BOOT_PARTITION_SIZE
+				+ MMC_BOOT_PARTITION_RESERVED;
+		} else if (POR_SPI_BOOT() || POR_CARD_BOOT()) {
+			off = 0;
+		} else { /* POR_NAND_BOOT */
+			off = -1;
+		}
+	} else { /* error, the storage device does NOT relate to eMMC */
+		off = -1;
+	}
+
+	if (off == -1)
+		pr_info(
+				"[%s] Error, NOT relate to eMMC,\"\" storage_flag=%d\n",
+				__func__, storage_flag);
+
+	return off;
+}
+
+int get_reserve_partition_off_from_tbl(void)
+{
+	int i;
+
+	for (i = 0; i < pt_fmt->part_num; i++) {
+		if (!strcmp(pt_fmt->partitions[i].name, MMC_RESERVED_NAME))
+			return pt_fmt->partitions[i].offset;
+	}
+	return -1;
+}
+
+/* static void show_mmc_patition (struct partitions *part, int part_num)
+ * {
+ * int i, cnt_stuff;
+
+ * pr_info("	name	offset	size\n");
+ * pr_info("===========================\n");
+ * for (i=0; i < part_num ; i++) {
+ * pr_info("%4d: %s", i, part[i].name);
+ * cnt_stuff = sizeof(part[i].name) - strlen(part[i].name);
+ * // something is wrong
+ * if (cnt_stuff < 0)
+ * cnt_stuff = 0;
+ * cnt_stuff += 2;
+ * while (cnt_stuff--) {
+ * pr_info(" ");
+ * }
+ * pr_info("%18llx%18llx\n", part[i].offset, part[i].size);
+ * }
+ * }
+ */
+
+static int mmc_read_partition_tbl(struct mmc_card *card,
+		struct mmc_partitions_fmt *pt_fmt)
+{
+	int ret = 0, start_blk, size, blk_cnt;
+	int bit = card->csd.read_blkbits;
+	int blk_size = 1 << bit; /* size of a block */
+	char *buf, *dst;
+
+	buf = kmalloc(blk_size, GFP_KERNEL);
+	if (buf == NULL) {
+		/*	pr_info("malloc failed for buffer!\n");*/
+		ret = -ENOMEM;
+		goto exit_err;
+	}
+	memset(pt_fmt, 0, sizeof(struct mmc_partitions_fmt));
+	memset(buf, 0, blk_size);
+
+	start_blk = get_reserve_partition_off(card);
+	if (start_blk < 0) {
+		ret = -EINVAL;
+		goto exit_err;
+	}
+	start_blk >>= bit;
+	size = sizeof(struct mmc_partitions_fmt);
+	dst = (char *)pt_fmt;
+	if (size >= blk_size) {
+		blk_cnt = size >> bit;
+		ret = mmc_read_internal(card, start_blk, blk_cnt, dst);
+		if (ret) { /* error */
+			goto exit_err;
+		}
+		start_blk += blk_cnt;
+		dst += blk_cnt << bit;
+		size -= blk_cnt << bit;
+	}
+	if (size > 0) { /* the last block */
+		ret = mmc_read_internal(card, start_blk, 1, buf);
+		if (ret)
+			goto exit_err;
+		memcpy(dst, buf, size);
+	}
+	/* pr_info("Partition table stored in eMMC/TSD:\n"); */
+	/* pr_info("magic: %s, version: %s, checksum=%#x\n", */
+	/* pt_fmt->magic, pt_fmt->version, pt_fmt->checksum); */
+	/* show_mmc_patition(pt_fmt->partitions, pt_fmt->part_num); */
+
+	if ((strncmp(pt_fmt->magic,
+				MMC_PARTITIONS_MAGIC,
+				sizeof(pt_fmt->magic)) == 0) /* the same */
+			&& (pt_fmt->part_num > 0)
+			&& (pt_fmt->part_num <= MAX_MMC_PART_NUM)
+			&& (pt_fmt->checksum ==
+				mmc_partition_tbl_checksum_calc(
+					pt_fmt->partitions,
+					pt_fmt->part_num))) {
+
+		ret = 0; /* everything is OK now */
+
+	} else {
+		if (strncmp(pt_fmt->magic, MMC_PARTITIONS_MAGIC,
+					sizeof(pt_fmt->magic)) != 0) {
+
+			print_tmp("magic error: %s\n",
+					(pt_fmt->magic)?pt_fmt->magic:"NULL");
+
+		} else if ((pt_fmt->part_num < 0)
+				|| (pt_fmt->part_num > MAX_MMC_PART_NUM)) {
+
+			print_tmp("partition number error: %d\n",
+					pt_fmt->part_num);
+
+		} else {
+			print_tmp(
+				"checksum error: pt_fmt->checksum=%d,calc_result=%d\n",
+				pt_fmt->checksum,
+				mmc_partition_tbl_checksum_calc(
+					pt_fmt->partitions,
+					pt_fmt->part_num));
+		}
+
+		pr_info("[%s]: partition verified error\n", __func__);
+		ret = -1; /* the partition information is invalid */
+	}
+
+exit_err:
+	kfree(buf);
+
+	pr_info("[%s] mmc read partition %s!\n",
+			__func__, (ret == 0) ? "OK" : "ERROR");
+
+	return ret;
+}
+
+/* This function is copy and modified from kernel function add_partition() */
+static struct hd_struct *add_emmc_each_part(struct gendisk *disk, int partno,
+		sector_t start, sector_t len, int flags,
+		char *pname)
+{
+	struct hd_struct *p;
+	dev_t devt = MKDEV(0, 0);
+	struct device *ddev = disk_to_dev(disk);
+	struct device *pdev;
+	struct disk_part_tbl *ptbl;
+	const char *dname;
+	int err;
+
+	err = disk_expand_part_tbl(disk, partno);
+	if (err)
+		return ERR_PTR(err);
+	ptbl = disk->part_tbl;
+
+	if (ptbl->part[partno])
+		return ERR_PTR(-EBUSY);
+
+	p = kzalloc(sizeof(*p), GFP_KERNEL);
+	if (!p)
+		return ERR_PTR(-EBUSY);
+
+	if (!init_part_stats(p)) {
+		err = -ENOMEM;
+		goto out_free;
+	}
+	seqcount_init(&p->nr_sects_seq);
+	pdev = part_to_dev(p);
+
+	p->start_sect = start;
+	p->alignment_offset =
+		queue_limit_alignment_offset(&disk->queue->limits, start);
+	p->discard_alignment =
+		queue_limit_discard_alignment(&disk->queue->limits, start);
+	p->nr_sects = len;
+	p->partno = partno;
+	p->policy = get_disk_ro(disk);
+
+	dname = dev_name(ddev);
+	dev_set_name(pdev, "%s", pname);
+
+	device_initialize(pdev);
+	pdev->class = &block_class;
+	pdev->type = &part_type;
+	pdev->parent = ddev;
+
+	err = blk_alloc_devt(p, &devt);
+	if (err)
+		goto out_free_info;
+	pdev->devt = devt;
+
+	/* delay uevent until 'holders' subdir is created */
+	dev_set_uevent_suppress(pdev, 1);
+	err = device_add(pdev);
+	if (err)
+		goto out_put;
+
+	err = -ENOMEM;
+	p->holder_dir = kobject_create_and_add("holders", &pdev->kobj);
+	if (!p->holder_dir)
+		goto out_del;
+
+	dev_set_uevent_suppress(pdev, 0);
+
+	/* everything is up and running, commence */
+	rcu_assign_pointer(ptbl->part[partno], p);
+
+	/* suppress uevent if the disk suppresses it */
+	if (!dev_get_uevent_suppress(ddev))
+		kobject_uevent(&pdev->kobj, KOBJ_ADD);
+
+	hd_ref_init(p);
+	return p;
+
+out_free_info:
+	free_part_info(p);
+out_free:
+	kfree(p);
+	return ERR_PTR(err);
+out_del:
+	kobject_put(p->holder_dir);
+	device_del(pdev);
+out_put:
+	put_device(pdev);
+	blk_free_devt(devt);
+	return ERR_PTR(err);
+}
+
+static inline int card_proc_info(struct seq_file *m, char *dev_name, int i)
+{
+	struct partitions *this = &(pt_fmt->partitions[i]);
+
+	if (i >= pt_fmt->part_num)
+		return 0;
+
+	seq_printf(m, "%s%02d: %9llx %9x \"%s\"\n", dev_name,
+			i+1, (unsigned long long)this->size,
+			512*1024, this->name);
+	return 0;
+}
+
+static int card_proc_show(struct seq_file *m, void *v)
+{
+	int i;
+
+	seq_puts(m, "dev:	size   erasesize  name\n");
+	for (i = 0; i < 16; i++)
+		card_proc_info(m, "inand", i);
+
+	return 0;
+}
+
+static int card_proc_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, card_proc_show, NULL);
+}
+
+static const struct file_operations card_proc_fops = {
+	.open = card_proc_open,
+	.read = seq_read,
+	.llseek = seq_lseek,
+	.release = seq_release,
+};
+
+static int add_emmc_partition(struct gendisk *disk,
+		struct mmc_partitions_fmt *pt_fmt)
+{
+	unsigned int i;
+	struct hd_struct *ret = NULL;
+	uint64_t offset, size, cap;
+	struct partitions *pp;
+	struct proc_dir_entry *proc_card;
+
+	pr_info("add_emmc_partition\n");
+
+	cap = get_capacity(disk); /* unit:512 bytes */
+	for (i = 0; i < pt_fmt->part_num; i++) {
+		pp = &(pt_fmt->partitions[i]);
+		offset = pp->offset >> 9; /* unit:512 bytes */
+		size = pp->size >> 9; /* unit:512 bytes */
+		if ((offset + size) <= cap) {
+			ret = add_emmc_each_part(disk, 1+i, offset,
+					size, 0, pp->name);
+
+			pr_info("[%sp%02d] %20s  offset 0x%012llx, size 0x%012llx %s\n",
+					disk->disk_name, 1+i,
+					pp->name, offset<<9,
+					size<<9, IS_ERR(ret) ? "add fail":"");
+		} else {
+			pr_info("[%s] %s: partition exceeds device capacity:\n",
+					__func__, disk->disk_name);
+
+			pr_info("\%20s  offset 0x%012llx, size 0x%012llx\n",
+					pp->name, offset<<9, size<<9);
+
+			break;
+		}
+	}
+	/* create /proc/inand */
+
+	proc_card = proc_create("inand", 0444, NULL, &card_proc_fops);
+	if (!proc_card)
+		pr_info("[%s] create /proc/inand fail.\n", __func__);
+
+	/* create /proc/ntd */
+	if (!proc_create("ntd", 0444, NULL, &card_proc_fops))
+		pr_info("[%s] create /proc/ntd fail.\n", __func__);
+
+	return 0;
+}
+
+static int is_card_emmc(struct mmc_card *card)
+{
+	struct mmc_host *mmc = card->host;
+
+	/* emmc port, so it must be an eMMC or TSD */
+	if (!strcmp(mmc_hostname(mmc), "mmc1"))//emmc
+		return 1;
+	else
+		return 0;
+	/*return mmc->is_emmc_port;*/
+}
+
+static ssize_t emmc_version_get(struct class *class,
+		struct class_attribute *attr, char *buf)
+{
+	int num = 0;
+
+	return sprintf(buf, "%d", num);
+}
+
+static void show_partition_table(struct partitions *table)
+{
+	int i = 0;
+	struct partitions *par_table = NULL;
+
+	pr_info("show partition table:\n");
+	for (i = 0; i < MAX_MMC_PART_NUM; i++) {
+		par_table = &table[i];
+		if (par_table->size == -1)
+			pr_info("part: %d, name : %10s, size : %-4s mask_flag %d\n",
+					i, par_table->name, "end",
+					par_table->mask_flags);
+		else
+			pr_info("part: %d, name : %10s, size : %-4llx  mask_flag %d\n",
+					i, par_table->name, par_table->size,
+					par_table->mask_flags);
+	}
+}
+
+static ssize_t emmc_part_table_get(struct class *class,
+		struct class_attribute *attr, char *buf)
+{
+	struct partitions *part_table = NULL;
+	struct partitions *tmp_table = NULL;
+	int i = 0, part_num = 0;
+
+	tmp_table = pt_fmt->partitions;
+	part_table = kmalloc(MAX_MMC_PART_NUM
+			*sizeof(struct partitions), GFP_KERNEL);
+
+	if (!part_table) {
+		pr_info("[%s] malloc failed for  part_table!\n", __func__);
+		return -ENOMEM;
+	}
+
+	for (i = 0; i < MAX_MMC_PART_NUM; i++) {
+		if (tmp_table[i].mask_flags == STORE_CODE) {
+			strncpy(part_table[part_num].name,
+					tmp_table[i].name,
+					MAX_MMC_PART_NAME_LEN);
+
+			part_table[part_num].size = tmp_table[i].size;
+			part_table[part_num].offset = tmp_table[i].offset;
+
+			part_table[part_num].mask_flags =
+				tmp_table[i].mask_flags;
+			part_num++;
+		}
+	}
+	for (i = 0; i < MAX_MMC_PART_NUM; i++) {
+		if (tmp_table[i].mask_flags == STORE_CACHE) {
+			strncpy(part_table[part_num].name,
+					tmp_table[i].name,
+					MAX_MMC_PART_NAME_LEN);
+
+			part_table[part_num].size = tmp_table[i].size;
+			part_table[part_num].offset = tmp_table[i].offset;
+
+			part_table[part_num].mask_flags =
+				tmp_table[i].mask_flags;
+
+			part_num++;
+		}
+	}
+	for (i = 0; i < MAX_MMC_PART_NUM; i++) {
+		if (tmp_table[i].mask_flags == STORE_DATA) {
+			strncpy(part_table[part_num].name,
+					tmp_table[i].name,
+					MAX_MMC_PART_NAME_LEN);
+
+			part_table[part_num].size = tmp_table[i].size;
+			part_table[part_num].offset = tmp_table[i].offset;
+			part_table[part_num].mask_flags =
+				tmp_table[i].mask_flags;
+
+			if (!strncmp(part_table[part_num].name, "data",
+						MAX_MMC_PART_NAME_LEN))
+				/* last part size is FULL */
+				part_table[part_num].size = -1;
+
+			part_num++;
+		}
+	}
+
+	show_partition_table(part_table);
+	memcpy(buf, part_table, MAX_MMC_PART_NUM*sizeof(struct partitions));
+
+	kfree(part_table);
+	part_table = NULL;
+
+	return MAX_MMC_PART_NUM*sizeof(struct partitions);
+}
+
+static int store_device = -1;
+static ssize_t store_device_flag_get(struct class *class,
+		struct class_attribute *attr, char *buf)
+{
+	if (store_device == -1) {
+		pr_info("[%s]  get store device flag something wrong !\n",
+				__func__);
+	}
+
+	return sprintf(buf, "%d", store_device);
+}
+
+static ssize_t get_bootloader_offset(struct class *class,
+		struct class_attribute *attr, char *buf)
+{
+	int offset = 0;
+
+	offset = 512;
+	return sprintf(buf, "%d", offset);
+}
+
+/*
+ * extern u32 cd_irq_cnt[2];
+ *
+ *static ssize_t get_cdirq_cnt(struct class *class,
+ *	struct class_attribute *attr, char *buf)
+ *{
+ *	return sprintf(buf, "in:%d, out:%d\n", cd_irq_cnt[1], cd_irq_cnt[0]);
+ *}
+ */
+
+static struct class_attribute aml_version =
+__ATTR(version, 0444, emmc_version_get, NULL);
+static struct class_attribute aml_part_table =
+__ATTR(part_table, 0444, emmc_part_table_get, NULL);
+static struct class_attribute aml_store_device =
+__ATTR(store_device, 0444, store_device_flag_get, NULL);
+static struct class_attribute bootloader_offset =
+__ATTR(bl_off_bytes, 0444, get_bootloader_offset, NULL);
+
+/* for irq cd dbg */
+/* static struct class_attribute cd_irq_cnt_ =
+ *	__ATTR(cdirq_cnt, S_IRUGO, get_cdirq_cnt, NULL);
+ */
+
+int aml_emmc_partition_ops(struct mmc_card *card, struct gendisk *disk)
+{
+	int ret = 0;
+	struct mmc_host *mmc_host = card->host;
+	struct amlsd_host *host = mmc_priv(mmc_host);
+	struct disk_part_iter piter;
+	struct hd_struct *part;
+	struct class *aml_store_class = NULL;
+
+	pr_info("Enter %s\n", __func__);
+
+	if (!is_card_emmc(card)) /* not emmc, nothing to do */
+		return 0;
+
+	store_device = host->storage_flag;
+	pt_fmt = kmalloc(sizeof(struct mmc_partitions_fmt), GFP_KERNEL);
+	if (pt_fmt == NULL) {
+		/*	pr_info(
+		 *	"[%s] malloc failed for struct mmc_partitions_fmt!\n",
+		 *	__func__);
+		 */
+		return -ENOMEM;
+	}
+
+	mmc_claim_host(card->host);
+	disk_part_iter_init(&piter, disk, DISK_PITER_INCL_EMPTY);
+
+	while ((part = disk_part_iter_next(&piter))) {
+		pr_info("Delete invalid mbr partition part %p, part->partno %d\n",
+				part, part->partno);
+		delete_partition(disk, part->partno);
+	}
+
+	disk_part_iter_exit(&piter);
+
+	ret = mmc_read_partition_tbl(card, pt_fmt);
+	if (ret == 0) { /* ok */
+		ret = add_emmc_partition(disk, pt_fmt);
+	}
+
+	mmc_release_host(card->host);
+
+	if (ret == 0) /* ok */
+		ret = emmc_key_init(card);
+
+	amlmmc_dtb_init(card);
+
+	aml_store_class = class_create(THIS_MODULE, "aml_store");
+	if (IS_ERR(aml_store_class)) {
+		pr_info("[%s] create aml_store_class class fail.\n", __func__);
+		ret = -1;
+		goto out;
+	}
+
+	ret = class_create_file(aml_store_class, &aml_version);
+	if (ret) {
+		pr_info("[%s] can't create aml_store_class file .\n", __func__);
+		goto out_class1;
+	}
+	ret = class_create_file(aml_store_class, &aml_part_table);
+	if (ret) {
+		pr_info("[%s] can't create aml_store_class file .\n", __func__);
+		goto out_class2;
+	}
+	ret = class_create_file(aml_store_class, &aml_store_device);
+	if (ret) {
+		pr_info("[%s] can't create aml_store_class file .\n", __func__);
+		goto out_class3;
+	}
+
+	ret = class_create_file(aml_store_class, &bootloader_offset);
+	if (ret) {
+		pr_info("[%s] can't create aml_store_class file .\n", __func__);
+		goto out_class3;
+	}
+
+	/* ret = class_create_file(aml_store_class, &cd_irq_cnt_);
+	 *if (ret) {
+	 *	pr_info("[%s] can't create aml_store_class file .\n", __func__);
+	 *	goto out_class3;
+	 *}
+	 */
+	pr_info("Exit %s %s.\n", __func__, (ret == 0)?"OK":"ERROR");
+	return ret;
+
+out_class3:
+	class_remove_file(aml_store_class, &aml_part_table);
+out_class2:
+	class_remove_file(aml_store_class, &aml_version);
+out_class1:
+	class_destroy(aml_store_class);
+out:
+	return ret;
+}
+
+
+
diff --git a/drivers/mmc/core/block.c b/drivers/mmc/core/block.c
index 8273b07..5f9abca 100644
--- a/drivers/mmc/core/block.c
+++ b/drivers/mmc/core/block.c
@@ -55,6 +55,10 @@
 #include "quirks.h"
 #include "sd_ops.h"

+#ifdef CONFIG_AMLOGIC_MMC
+#include <linux/mmc/emmc_partitions.h>
+#endif
+
 MODULE_ALIAS("mmc:block");
 #ifdef MODULE_PARAM_PREFIX
 #undef MODULE_PARAM_PREFIX
@@ -2200,6 +2204,12 @@ static int mmc_blk_probe(struct mmc_card *card)
 	if (mmc_add_disk(md))
 		goto out;

+#ifdef CONFIG_AMLOGIC_MMC
+       /* amlogic add emmc partitions ops */
+       aml_emmc_partition_ops(card, md->disk);
+#endif
+
+
 	list_for_each_entry(part_md, &md->part, part) {
 		if (mmc_add_disk(part_md))
 			goto out;
diff --git a/include/linux/amlogic/amlsd.h b/include/linux/amlogic/amlsd.h
new file mode 100644
index 0000000..9323c5c
--- /dev/null
+++ b/include/linux/amlogic/amlsd.h
@@ -0,0 +1,239 @@
+/*
+ * include/linux/amlogic/amlsd.h
+ *
+ * Copyright (C) 2016 Amlogic, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ */
+
+#ifndef AMLSD_H
+#define AMLSD_H
+#include <linux/of_gpio.h>
+
+#define AML_MMC_MAJOR_VERSION   1
+#define AML_MMC_MINOR_VERSION   07
+#define AML_MMC_VERSION \
+	((AML_MMC_MAJOR_VERSION << 8) | AML_MMC_MINOR_VERSION)
+#define AML_MMC_VER_MESSAGE \
+	"2015-01-21: fix a bug in tuning which caused eMMC data CRC error"
+
+extern unsigned long sdhc_debug;
+extern unsigned long sdio_debug;
+extern unsigned int sd_emmc_debug;
+extern const u8 tuning_blk_pattern_4bit[64];
+extern const u8 tuning_blk_pattern_8bit[128];
+#define DEBUG_SD_OF		1
+/* #define DEBUG_SD_OF			0 */
+
+#define MODULE_NAME		"amlsd"
+
+#if 0
+#define A0_GP_CFG0			(0xc8100240)
+#define A0_GP_CFG2			(0xc8100248)
+#define STORAGE_DEV_NOSET	(0)
+#define STORAGE_DEV_EMMC	(1)
+#define STORAGE_DEV_NAND	(2)
+#define STORAGE_DEV_SPI		(3)
+#define STORAGE_DEV_SDCARD	(4)
+#define STORAGE_DEV_USB		(5)
+#define LDO4DAC_REG_ADDR        0x4f
+#define LDO4DAC_REG_1_8_V       0x24
+#define LDO4DAC_REG_2_8_V       0x4c
+#define LDO4DAC_REG_3_3_V       0x60
+#endif
+
+#define AMLSD_DBG_COMMON	(1<<0)
+#define AMLSD_DBG_REQ		(1<<1)
+#define AMLSD_DBG_RESP		(1<<2)
+#define AMLSD_DBG_REG		(1<<3)
+#define AMLSD_DBG_RD_TIME	(1<<4)
+#define AMLSD_DBG_WR_TIME	(1<<5)
+#define AMLSD_DBG_BUSY_TIME	(1<<6)
+#define AMLSD_DBG_RD_DATA	(1<<7)
+#define AMLSD_DBG_WR_DATA	(1<<8)
+#define AMLSD_DBG_IOS		(1<<9)
+#define AMLSD_DBG_IRQ		(1<<10)
+#define AMLSD_DBG_CLKC		(1<<11)
+#define AMLSD_DBG_TUNING	(1<<12)
+
+#define     DETECT_CARD_IN          1
+#define     DETECT_CARD_OUT         2
+#define     DETECT_CARD_JTAG_IN     3
+#define     DETECT_CARD_JTAG_OUT    4
+
+#define EMMC_DAT3_PINMUX_CLR    0
+#define EMMC_DAT3_PINMUX_SET    1
+
+#ifdef CONFIG_AMLOGIC_M8B_MMC
+#define P_PERIPHS_PIN_MUX_2 (0xc1100000 + (0x202e << 2))
+#define P_PREG_PAD_GPIO3_EN_N (0xc1100000 + (0x2015 << 2))
+#define P_PREG_PAD_GPIO3_O (0xc1100000 + (0x2016 << 2))
+#endif
+
+#define CHECK_RET(ret) { \
+	if (ret) \
+	pr_info("[%s] gpio op failed(%d) at line %d\n",\
+			__func__, ret, __LINE__); \
+}
+
+#define sdhc_dbg(dbg_level, fmt, args...) do {\
+	if (dbg_level & sdhc_debug)	\
+	pr_info("[%s]" fmt, __func__, ##args);	\
+} while (0)
+
+#define sdhc_err(fmt, args...) \
+	pr_info("[%s] " fmt, __func__, ##args)
+
+
+#define sdio_dbg(dbg_level, fmt, args...) do {\
+	if (dbg_level & sdio_debug)	\
+	pr_info("[%s]" fmt, __func__, ##args);	\
+} while (0)
+
+#define sdio_err(fmt, args...) \
+	pr_info("[%s] " fmt, __func__, ##args)
+
+#define sd_emmc_dbg(dbg_level, fmt, args...) do {\
+	if (dbg_level & sd_emmc_debug)	\
+	pr_info("[%s]" fmt, __func__, ##args);	\
+} while (0)
+#define sd_emmc_err(fmt, args...) \
+	pr_warn("[%s] " fmt, __func__, ##args)
+
+#define SD_PARSE_U32_PROP_HEX(node, prop_name, prop, value) do { \
+	if (!of_property_read_u32(node, prop_name, &prop)) {\
+		value = prop;\
+		prop = 0;\
+		if (DEBUG_SD_OF) {	\
+			pr_info("get property:%25s, value:0x%08x\n", \
+					prop_name, (unsigned int)value); \
+		} \
+	} \
+} while (0)
+
+#define SD_PARSE_U32_PROP_DEC(node, prop_name, prop, value) do { \
+	if (!of_property_read_u32(node, prop_name, &prop)) {\
+		value = prop;\
+		prop = 0;\
+		if (DEBUG_SD_OF) { \
+			pr_info("get property:%25s, value:%d\n", \
+					prop_name, (unsigned int)value); \
+		} \
+	} \
+} while (0)
+
+#define SD_PARSE_GPIO_NUM_PROP(node, prop_name, str, gpio_pin) {\
+	if (!of_property_read_string(node, prop_name, &str)) {\
+		gpio_pin = \
+		of_get_named_gpio(node, \
+				prop_name, 0);\
+		if (DEBUG_SD_OF) {	\
+			pr_info("get property:%25s, str:%s\n",\
+					prop_name, str);\
+		} \
+	} \
+}
+
+#define SD_PARSE_STRING_PROP(node, prop_name, str, prop) {\
+	if (!of_property_read_string(node, prop_name, &str)) {\
+		strcpy(prop, str);\
+		if (DEBUG_SD_OF) {\
+			pr_info("get property:%25s, str:%s\n",\
+					prop_name, prop);	\
+		} \
+	} \
+}
+
+#define SD_CAPS(a, b) { .caps = a, .name = b }
+
+struct sd_caps {
+	unsigned int caps;
+	const char *name;
+};
+
+void aml_mmc_ver_msg_show(void);
+extern int sdio_reset_comm(struct mmc_card *card);
+#if 0
+extern int storage_flag;
+
+extern void aml_debug_print_buf(char *buf, int size);
+extern int aml_buf_verify(int *buf, int blocks, int lba);
+extern void aml_sdhc_init_debugfs(struct mmc_host *mmc);
+void aml_sdhc_print_reg_(u32 *buf);
+extern void aml_sdhc_print_reg(struct amlsd_host *host);
+extern void aml_sdio_init_debugfs(struct mmc_host *mmc);
+extern void aml_sd_emmc_init_debugfs(struct mmc_host *mmc);
+extern void aml_sdio_print_reg(struct amlsd_host *host);
+extern void aml_sd_emmc_print_reg(struct amlsd_host *host);
+
+extern int add_part_table(struct mtd_partition *part, unsigned int nr_part);
+extern int add_emmc_partition(struct gendisk *disk);
+#endif
+#ifdef CONFIG_AMLOGIC_M8B_MMC
+extern size_t aml_sg_copy_buffer(struct scatterlist *sgl, unsigned int nents,
+		void *buf, size_t buflen, int to_buffer);
+#endif
+int amlsd_get_platform_data(struct platform_device *pdev,
+		struct amlsd_platform *pdata,
+		struct mmc_host *mmc, u32 index);
+
+void of_amlsd_irq_init(struct amlsd_platform *pdata);
+int of_amlsd_init(struct amlsd_platform *pdata);
+#if 0
+int amlsd_get_reg_base(struct platform_device *pdev,
+		struct amlsd_host *host);
+
+/* int of_amlsd_detect(struct amlsd_platform* pdata); */
+
+int aml_sd_uart_detect(struct amlsd_platform *pdata);
+void aml_sd_uart_detect_clr(struct amlsd_platform *pdata);
+#endif
+void of_amlsd_pwr_prepare(struct amlsd_platform *pdata);
+void of_amlsd_pwr_on(struct amlsd_platform *pdata);
+void of_amlsd_pwr_off(struct amlsd_platform *pdata);
+
+void of_amlsd_xfer_pre(struct mmc_host *mmc);
+void of_amlsd_xfer_post(struct mmc_host *mmc);
+
+irqreturn_t aml_sd_irq_cd(int irq, void *dev_id);
+irqreturn_t aml_irq_cd_thread(int irq, void *data);
+#if 0
+void aml_sduart_pre(struct amlsd_platform *pdata);
+
+/* is eMMC/tSD exist */
+bool is_emmc_exist(struct amlsd_host *host);
+void aml_devm_pinctrl_put(struct amlsd_host *host);
+/* void of_init_pins (struct amlsd_platform* pdata); */
+
+void aml_dbg_print_pinmux(void);
+#ifdef CONFIG_MMC_AML_DEBUG
+void aml_dbg_verify_pull_up(struct amlsd_platform *pdata);
+int aml_dbg_verify_pinmux(struct amlsd_platform *pdata);
+#endif
+#endif
+/* chip select high */
+void aml_cs_high(struct mmc_host *mmc);
+
+/* chip select don't care */
+void aml_cs_dont_care(struct mmc_host *mmc);
+
+void aml_snprint (char **pp, int *left_size,  const char *fmt, ...);
+
+int of_amlsd_ro(struct amlsd_platform *pdata);
+int aml_sd_voltage_switch(struct mmc_host *mmc, char signal_voltage);
+int aml_signal_voltage_switch(struct mmc_host *mmc, struct mmc_ios *ios);
+
+int aml_check_unsupport_cmd(struct mmc_host *mmc, struct mmc_request *mrq);
+extern void aml_emmc_hw_reset(struct mmc_host *mmc);
+#endif
+
+
diff --git a/include/linux/amlogic/cpu_version.h b/include/linux/amlogic/cpu_version.h
new file mode 100644
index 0000000..5c35a0f
--- /dev/null
+++ b/include/linux/amlogic/cpu_version.h
@@ -0,0 +1,144 @@
+/*
+ * include/linux/amlogic/cpu_version.h
+ *
+ * Copyright (C) 2017 Amlogic, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ */
+
+#ifndef __PLAT_MESON_CPU_H
+#define __PLAT_MESON_CPU_H
+
+#define MESON_CPU_MAJOR_ID_M8B      0x1B
+#define MESON_CPU_MAJOR_ID_GXBB		0x1F
+#define MESON_CPU_MAJOR_ID_GXTVBB	0x20
+#define MESON_CPU_MAJOR_ID_GXL		0x21
+#define MESON_CPU_MAJOR_ID_GXM		0x22
+#define MESON_CPU_MAJOR_ID_TXL		0x23
+#define MESON_CPU_MAJOR_ID_TXLX		0x24
+
+#define MESON_CPU_VERSION_LVL_MAJOR	0
+#define MESON_CPU_VERSION_LVL_MINOR	1
+#define MESON_CPU_VERSION_LVL_PACK	2
+#define MESON_CPU_VERSION_LVL_MISC	3
+#define MESON_CPU_VERSION_LVL_MAX	MESON_CPU_VERSION_LVL_MISC
+extern unsigned int system_serial_low0;
+extern unsigned int system_serial_low1;
+extern unsigned int system_serial_high0;
+extern unsigned int system_serial_high1;
+
+int  meson_cpu_version_init(void);
+#ifdef CONFIG_AMLOGIC_CPU_VERSION
+int get_meson_cpu_version(int level);
+int arch_big_cpu(int cpu);
+#else
+static inline int get_meson_cpu_version(int level)
+{
+	return -1;
+}
+
+static inline int arch_big_cpu(int cpu)
+{
+	return 0;
+}
+#endif
+
+static inline int get_cpu_type(void)
+{
+	return get_meson_cpu_version(MESON_CPU_VERSION_LVL_MAJOR);
+}
+
+static inline u32 get_cpu_package(void)
+{
+	unsigned int pk;
+
+	pk = get_meson_cpu_version(MESON_CPU_VERSION_LVL_PACK) & 0xF0;
+	return pk;
+}
+
+static inline bool package_id_is(unsigned int id)
+{
+	return get_cpu_package() == id;
+}
+
+static inline bool is_meson_m8b_cpu(void)
+{
+	return get_cpu_type() == MESON_CPU_MAJOR_ID_M8B;
+}
+
+static inline bool is_meson_gxbb_cpu(void)
+{
+	return get_cpu_type() == MESON_CPU_MAJOR_ID_GXBB;
+}
+
+static inline bool is_meson_gxtvbb_cpu(void)
+{
+	return get_cpu_type() == MESON_CPU_MAJOR_ID_GXTVBB;
+}
+
+static inline bool is_meson_gxbb_package_905(void)
+{
+	return (get_cpu_type() == MESON_CPU_MAJOR_ID_GXBB) &&
+		(get_cpu_package() != 0x20);
+}
+
+static inline bool is_meson_gxbb_package_905m(void)
+{
+	return (get_cpu_type() == MESON_CPU_MAJOR_ID_GXBB) &&
+		(get_cpu_package() == 0x20);
+}
+
+static inline bool is_meson_gxl_cpu(void)
+{
+	return get_cpu_type() == MESON_CPU_MAJOR_ID_GXL;
+}
+
+static inline bool is_meson_gxl_package_905D(void)
+{
+	return is_meson_gxl_cpu() && package_id_is(0x0);
+}
+static inline bool is_meson_gxl_package_905X(void)
+{
+	return is_meson_gxl_cpu() && package_id_is(0x80);
+}
+
+static inline bool is_meson_gxl_package_905L(void)
+{
+	return is_meson_gxl_cpu() && package_id_is(0xc0);
+}
+
+static inline bool is_meson_gxl_package_905M2(void)
+{
+	return is_meson_gxl_cpu() && package_id_is(0xe0);
+}
+
+static inline bool is_meson_gxm_cpu(void)
+{
+	return get_cpu_type() == MESON_CPU_MAJOR_ID_GXM;
+}
+
+static inline bool is_meson_txl_cpu(void)
+{
+	return get_cpu_type() == MESON_CPU_MAJOR_ID_TXL;
+}
+
+static inline bool is_meson_txlx_cpu(void)
+{
+	return get_cpu_type() == MESON_CPU_MAJOR_ID_TXLX;
+}
+
+static inline bool cpu_after_eq(unsigned int id)
+{
+	return get_cpu_type() >= id;
+}
+
+#endif
diff --git a/include/linux/amlogic/iomap.h b/include/linux/amlogic/iomap.h
new file mode 100644
index 0000000..c5f2653
--- /dev/null
+++ b/include/linux/amlogic/iomap.h
@@ -0,0 +1,83 @@
+/*
+ * include/linux/amlogic/iomap.h
+ *
+ * Copyright (C) 2017 Amlogic, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ */
+
+#ifndef __SOC_IO_H
+#define __SOC_IO_H
+
+enum{
+	IO_CBUS_BASE = 0,
+	IO_APB_BUS_BASE,
+	IO_AOBUS_BASE,
+	IO_HIUBUS_BASE,
+	IO_BUS_MAX,
+};
+extern int aml_reg_read(u32 bus_type, unsigned int reg, unsigned int *val);
+extern int aml_reg_write(u32 bus_type, unsigned int reg, unsigned int val);
+extern int aml_regmap_update_bits(u32 bus_type,
+			unsigned int reg, unsigned int mask,
+			unsigned int val);
+/*
+ ** CBUS REG Read Write and Update some bits
+ */
+extern  int aml_read_cbus(unsigned int reg);
+
+
+extern   void aml_write_cbus(unsigned int reg, unsigned int val);
+
+
+extern  void aml_cbus_update_bits(unsigned int reg,
+		unsigned int mask, unsigned int val);
+
+/*
+ ** AO REG Read Write and Update some bits
+ */
+extern  int aml_read_aobus(unsigned int reg);
+
+
+extern  void aml_write_aobus(unsigned int reg, unsigned int val);
+
+
+extern  void aml_aobus_update_bits(unsigned int reg,
+		unsigned int mask, unsigned int val);
+
+
+
+/*
+ ** VCBUS Bus REG Read Write and Update some bits
+ */
+extern  int aml_read_vcbus(unsigned int reg);
+
+extern  void aml_write_vcbus(unsigned int reg, unsigned int val);
+
+extern  void aml_vcbus_update_bits(unsigned int reg,
+		unsigned int mask, unsigned int val);
+
+
+/*
+ ** DOS BUS Bus REG Read Write and Update some bits
+ */
+extern  int aml_read_dosbus(unsigned int reg);
+
+extern  void aml_write_dosbus(unsigned int reg, unsigned int val);
+
+extern  void aml_dosbus_update_bits(unsigned int reg,
+		unsigned int mask, unsigned int val);
+
+extern int  aml_read_sec_reg(unsigned int reg);
+extern void  aml_write_sec_reg(unsigned int reg, unsigned int val);
+
+#endif
diff --git a/include/linux/amlogic/key_manage.h b/include/linux/amlogic/key_manage.h
new file mode 100644
index 0000000..b6df6a7
--- /dev/null
+++ b/include/linux/amlogic/key_manage.h
@@ -0,0 +1,37 @@
+/*
+ * include/linux/amlogic/key_manage.h
+ *
+ * Copyright (C) 2017 Amlogic, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ */
+
+#ifndef __KEYMANAGE1__
+#define __KEYMANAGE1__
+
+typedef int32_t (*store_key_ops)(uint8_t *buf,
+					uint32_t len, uint32_t *actual_length);
+
+#ifdef CONFIG_AMLOGIC_KEY_MANAGE
+void storage_ops_read(store_key_ops read);
+void storage_ops_write(store_key_ops write);
+#else
+void storage_ops_read(store_key_ops read)
+{
+}
+
+void storage_ops_write(store_key_ops read)
+{
+}
+#endif /*CONFIG_KEY_MANAGE*/
+
+#endif /*__KEYMANAGE1__*/
diff --git a/include/linux/amlogic/sd.h b/include/linux/amlogic/sd.h
new file mode 100644
index 0000000..19a142f
--- /dev/null
+++ b/include/linux/amlogic/sd.h
@@ -0,0 +1,1514 @@
+/*
+ * include/linux/amlogic/sd.h
+ *
+ * Copyright (C) 2016 Amlogic, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ */
+
+#ifndef __AML_SD_H__
+#define __AML_SD_H__
+
+#include <linux/types.h>
+#include <linux/device.h>
+#include <linux/clk.h>
+#include <linux/clk-provider.h>
+#include <linux/mmc/host.h>
+/* #include <linux/earlysuspend.h> */
+
+#define	 AML_ERROR_RETRY_COUNTER		 10
+#define	 AML_TIMEOUT_RETRY_COUNTER	   2
+#define AML_CALIBRATION
+#define AML_SDHC_MAGIC			 "amlsdhc"
+#define AML_SDIO_MAGIC			 "amlsdio"
+#define AML_SD_EMMC_MAGIC			 "amlsd_emmc"
+#define SD_EMMC_MANUAL_CMD23
+#define MAX_TUNING_RETRY 4
+#define TUNING_NUM_PER_POINT 10
+#define CALI_PATTERN_OFFSET ((SZ_1M * (36 + 3)) / 512)
+/* #define AML_RESP_WR_EXT */
+#ifdef AML_CALIBRATION
+#define MAX_CALI_RETRY	3
+#define MAX_DELAY_CNT	16
+#define CALI_BLK_CNT	10
+#endif
+
+#define SD_EMMC_CLOCK 0x0
+#define SD_EMMC_DELAY 0x4
+#define SD_EMMC_ADJUST 0x8
+#define SD_EMMC_CALOUT 0x10
+#define SD_EMMC_START 0x40
+#define SD_EMMC_CFG 0x44
+#define SD_EMMC_STATUS 0x48
+#define SD_EMMC_IRQ_EN 0x4c
+#define SD_EMMC_CMD_RSP 0x5c
+#define SD_EMMC_CMD_RSP1 0x60
+#define SD_EMMC_CMD_RSP2 0x64
+#define SD_EMMC_CMD_RSP3 0x68
+
+#define   CLK_DIV_SHIFT 0
+#define   CLK_DIV_WIDTH 6
+#define   CLK_DIV_MASK 0x3f
+#define   CLK_DIV_MAX 63
+#define   CLK_SRC_SHIFT 6
+#define   CLK_SRC_WIDTH 2
+#define   CLK_SRC_MASK 0x3
+#define   CLK_SRC_XTAL_RATE 24000000
+#define   CLK_SRC_PLL_RATE 1000000000
+
+#define   CFG_BLK_LEN_SHIFT 4
+#define   CFG_BLK_LEN_MASK 0xf
+
+#define CMD_CFG_LENGTH_SHIFT 0
+#define CMD_CFG_LENGTH_MASK 0x1ff
+#define CMD_CFG_BLOCK_MODE BIT(9)
+#define CMD_CFG_DATA_IO BIT(18)
+#define CMD_CFG_DATA_WR BIT(19)
+#define CMD_CFG_DATA_NUM BIT(23)
+
+#define CMD_DATA_MASK (~0x3)
+
+struct aml_tuning_data {
+	const u8 *blk_pattern;
+	unsigned int blksz;
+};
+
+enum aml_mmc_waitfor {
+	XFER_INIT,			  /* 0 */
+	XFER_START,				/* 1 */
+	XFER_AFTER_START,		/* 2 */
+	XFER_IRQ_OCCUR,			/* 3 */
+	XFER_IRQ_TASKLET_CMD,	/* 4 */
+	XFER_IRQ_TASKLET_DATA,	/* 5 */
+	XFER_IRQ_TASKLET_BUSY,	/* 6 */
+	XFER_IRQ_UNKNOWN_IRQ,	/* 7 */
+	XFER_TIMER_TIMEOUT,		/* 8 */
+	XFER_TASKLET_CMD,		/* 9 */
+	XFER_TASKLET_DATA,		/* 10 */
+	XFER_TASKLET_BUSY,		/* 11 */
+	XFER_TIMEDOUT,			/* 12 */
+	XFER_FINISHED,			/* 13 */
+};
+
+enum aml_host_status { /* Host controller status */
+	HOST_INVALID = 0,	   /* 0, invalid value */
+	HOST_RX_FIFO_FULL = 1,  /* 1, start with 1 */
+	HOST_TX_FIFO_EMPTY,		/* 2 */
+	HOST_RSP_CRC_ERR,		/* 3 */
+	HOST_DAT_CRC_ERR,		/* 4 */
+	HOST_RSP_TIMEOUT_ERR,   /* 5 */
+	HOST_DAT_TIMEOUT_ERR,   /* 6 */
+	HOST_ERR_END,			/* 7, end of errors */
+	HOST_TASKLET_CMD,		/* 8 */
+	HOST_TASKLET_DATA,		/* 9 */
+};
+
+enum aml_host_bus_fsm { /* Host bus fsm status */
+	BUS_FSM_IDLE,			/* 0, idle */
+	BUS_FSM_SND_CMD,		/* 1, send cmd */
+	BUS_FSM_CMD_DONE,		/* 2, wait for cmd done */
+	BUS_FSM_RESP_START,		/* 3, resp start */
+	BUS_FSM_RESP_DONE,		/* 4, wait for resp done */
+	BUS_FSM_DATA_START,		/* 5, data start */
+	BUS_FSM_DATA_DONE,		/* 6, wait for data done */
+	BUS_FSM_DESC_WRITE_BACK,/* 7, wait for desc write back */
+	BUS_FSM_IRQ_SERVICE,	/* 8, wait for irq service */
+};
+
+enum aml_host_tuning_mode {
+	NONE_TUNING,
+	ADJ_TUNING_MODE,
+	AUTO_TUNING_MODE,
+	RX_PHASE_DELAY_TUNING_MODE,
+};
+
+struct cali_data {
+	u8 ln_delay[8];
+	u32 base_index[10];
+	u32 base_index_max;
+	u32 base_index_min;
+};
+
+struct cali_ctrl {
+	u8 line_x;
+	u8 cal_time;
+	u8 dly_tmp;
+	u8 max_index;
+};
+
+struct amlsd_host;
+struct amlsd_platform {
+	struct amlsd_host *host;
+	struct mmc_host *mmc;
+	struct list_head sibling;
+	u32 ocr_avail;
+	u32 port;
+#define	 PORT_SDIO_A	 0
+#define	 PORT_SDIO_B	 1
+#define	 PORT_SDIO_C	 2
+#define	 PORT_SDHC_A	 3
+#define	 PORT_SDHC_B	 4
+#define	 PORT_SDHC_C	 5
+
+#ifdef CONFIG_AMLOGIC_M8B_MMC
+	unsigned int width;
+	unsigned int tune_phase;	/* store tuning result */
+#endif
+	unsigned int caps;
+	unsigned int caps2;
+	unsigned int card_capacity;
+	unsigned int tx_phase;
+	unsigned int tx_delay;
+	unsigned int f_min;
+	unsigned int f_max;
+	unsigned int clkc;
+	unsigned int clk2;
+	unsigned int clkc_w;
+	unsigned int ctrl;
+	unsigned int clock;
+	/* signalling voltage (1.8V or 3.3V) */
+	unsigned char signal_voltage;
+
+	unsigned int low_burst;
+	struct mutex in_out_lock;
+	unsigned int irq_cd;
+	unsigned int gpio_cd;
+	unsigned int gpio_cd_level;
+	unsigned int gpio_power;
+	unsigned int power_level;
+	unsigned int auto_clk_close;
+	unsigned int vol_switch;
+	unsigned int vol_switch_18;
+	unsigned int vol_switch_delay;
+	char pinname[32];
+	unsigned int gpio_ro;
+	unsigned int gpio_dat3;
+	unsigned int hw_reset;
+	unsigned int jtag_pin;
+	int is_sduart;
+	unsigned int card_in_delay;
+	bool is_in;
+	bool is_tuned;		/* if card has been tuning */
+	bool need_retuning;
+	bool rmpb_cmd_flag;
+	bool rpmb_valid_command;
+	/* we used this flag to filter
+	 * some unnecessary cmd before initialized flow
+	 */
+	/* has been initialized for the first time */
+	bool is_fir_init;
+	struct delayed_work	retuning;
+#ifdef AML_CALIBRATION
+	unsigned char caling;
+	unsigned char calout[20][20];
+#endif
+	/* 0:unknown, 1:mmc card(include eMMC), 2:sd card(include tSD),
+	 * 3:sdio device(ie:sdio-wifi), 4:SD combo (IO+mem) card,
+	 * 5:NON sdio device(means sd/mmc card), other:reserved
+	 */
+	unsigned int card_type;
+	struct cali_ctrl c_ctrl;
+	/* unknown */
+#define CARD_TYPE_UNKNOWN		0
+	/* MMC card */
+#define CARD_TYPE_MMC			1
+	/* SD card */
+#define CARD_TYPE_SD			2
+	/* SDIO card */
+#define CARD_TYPE_SDIO			3
+	/* SD combo (IO+mem) card */
+#define CARD_TYPE_SD_COMBO		4
+	/* NON sdio device (means SD/MMC card) */
+#define CARD_TYPE_NON_SDIO		5
+
+#define aml_card_type_unknown(c)	((c)->card_type == CARD_TYPE_UNKNOWN)
+#define aml_card_type_mmc(c)		((c)->card_type == CARD_TYPE_MMC)
+#define aml_card_type_sd(c)		 ((c)->card_type == CARD_TYPE_SD)
+#define aml_card_type_sdio(c)	   ((c)->card_type == CARD_TYPE_SDIO)
+#define aml_card_type_non_sdio(c)   ((c)->card_type == CARD_TYPE_NON_SDIO)
+
+	/* struct pinctrl *uart_ao_pinctrl; */
+	void (*irq_init)(struct amlsd_platform *pdata);
+
+	unsigned int max_blk_count;
+	unsigned int max_blk_size;
+	unsigned int max_req_size;
+	unsigned int max_seg_size;
+
+	/*for inand partition: struct mtd_partition, easy porting from nand*/
+	struct mtd_partition *parts;
+	unsigned int nr_parts;
+
+	struct resource *resource;
+	void (*xfer_pre)(struct mmc_host *mmc);
+	void (*xfer_post)(struct mmc_host *mmc);
+
+	int (*port_init)(struct amlsd_platform *pdata);
+	int (*cd)(struct amlsd_platform *pdata);
+	int (*ro)(struct amlsd_platform *pdata);
+	void (*pwr_pre)(struct amlsd_platform *pdata);
+	void (*pwr_on)(struct amlsd_platform *pdata);
+	void (*pwr_off)(struct amlsd_platform *pdata);
+
+};
+
+struct aml_emmc_adjust {
+	int adj_win_start;
+	int adj_win_len;
+	int adj_point;
+	int clk_div;
+};
+
+struct aml_emmc_rxclk {
+	int rxclk_win_start;
+	int rxclk_win_len;
+	int rxclk_rx_phase;
+	int rxclk_rx_delay;
+	int rxclk_point;
+};
+
+#define MUX_CLK_NUM_PARENTS 2
+struct amlsd_host {
+	/* back-link to device */
+	struct device *dev;
+	struct list_head sibling;
+	struct platform_device *pdev;
+	struct amlsd_platform *pdata;
+	struct mmc_host		*mmc;
+	struct mmc_request	*request;
+
+	struct mmc_command	*cmd;
+	u32 ocr_mask;
+	struct clk *core_clk;
+	struct clk_mux mux;
+	struct clk *mux_clk;
+	struct clk *mux_parent[MUX_CLK_NUM_PARENTS];
+	unsigned long mux_parent_rate[MUX_CLK_NUM_PARENTS];
+	struct clk_divider cfg_div;
+	struct clk *cfg_div_clk;
+#ifdef CONFIG_AMLOGIC_M8B_MMC
+	struct clk *div3_clk;
+#endif
+
+	struct resource		*mem;
+	struct sd_emmc_regs *sd_emmc_regs;
+	void __iomem		*base;
+	void __iomem		*pinmux_base;
+	int			dma;
+	char *bn_buf;
+	dma_addr_t		bn_dma_buf;
+#ifdef AML_RESP_WR_EXT
+	u32 *resp_buf;
+	dma_addr_t resp_dma_buf;
+#endif
+	dma_addr_t		dma_gdesc; /* 0x200 */
+	dma_addr_t		dma_gping; /* 0x400 */
+	dma_addr_t		dma_gpong; /* 0x800 */
+	char is_tunning;
+	char tuning_mode;
+	unsigned int irq;
+	unsigned int irq_in;
+	unsigned int irq_out;
+	unsigned int f_max;
+	unsigned int f_max_w;
+	unsigned int f_min;
+	int	sdio_irqen;
+	unsigned int error_bak;
+	struct delayed_work	timeout;
+	struct class debug;
+
+	unsigned int send;
+	unsigned int ctrl;
+	unsigned int clkc;
+	unsigned int misc;
+	unsigned int ictl;
+	unsigned int ista;
+	unsigned int dma_addr;
+
+	unsigned long		clk_rate;
+
+	char *desc_buf;
+	dma_addr_t		desc_dma_addr;
+	unsigned int dma_sts;
+	unsigned int sg_cnt;
+	char *desc_cur;
+	unsigned int desc_cur_cnt;
+	char *desc_pre;
+	unsigned int desc_pre_cnt;
+	struct  mmc_request	*mrq;
+	struct  mmc_request	*mrq2;
+	spinlock_t	mrq_lock;
+	struct mutex	pinmux_lock;
+	int			cmd_is_stop;
+	enum aml_mmc_waitfor	xfer_step;
+	enum aml_mmc_waitfor	xfer_step_prev;
+
+	int			bus_width;
+	int	 port;
+	int	 locked;
+	bool	is_gated;
+	unsigned char sd_sdio_switch_volat_done;
+
+	int	 status; /* host status: xx_error/ok */
+	int init_flag;
+
+	char	*msg_buf;
+#define MESSAGE_BUF_SIZE			512
+
+#ifdef CONFIG_DEBUG_FS
+	struct dentry		*debug_root;
+	struct dentry		*debug_state;
+	struct dentry		*debug_regs;
+#endif
+
+#ifdef CONFIG_CPU_FREQ
+	struct notifier_block	freq_transition;
+#endif
+
+	u32			opcode;
+	u32			arg;
+	u32		 cmd25_cnt;
+
+#ifdef CONFIG_MMC_AML_DEBUG
+	u32		 req_cnt;
+	u32		 trans_size;
+
+	u32		 reg_buf[16];
+#endif
+	u32		 time_req_sta; /* request start time */
+
+	struct pinctrl  *pinctrl;
+	char		pinctrl_name[30];
+	/* used for judging if there is a tsd/emmc */
+	int		 storage_flag;
+	/* bit[7-0]--minor version, bit[31-8]--major version */
+	int		 version;
+	unsigned long	clksrc_rate;
+	struct aml_emmc_adjust emmc_adj;
+	struct aml_emmc_rxclk emmc_rxclk;
+	u32 error_flag;
+};
+
+/*-sdio-*/
+
+#define SDIO_ARGU	   (0x0)
+#define SDIO_SEND	   (0x4)
+#define SDIO_CONF	   (0x8)
+#define SDIO_IRQS	   (0xc)
+#define SDIO_IRQC	   (0x10)
+#define SDIO_MULT	   (0x14)
+#define SDIO_ADDR	   (0x18)
+#define SDIO_EXT		(0x1c)
+#define SDIO_CCTL	   (0x40)
+#define SDIO_CDAT	   (0x44)
+
+#define CLK_DIV		 (0x1f4)
+
+struct cmd_send {
+	u32 cmd_command:8; /*[7:0] Command Index*/
+	u32 cmd_response_bits:8;
+	/*[15:8]
+	 * 00 means no response
+	 * others: Response bit number
+	 * (cmd bits+response bits+crc bits-1)
+	 */
+	u32 response_do_not_have_crc7:1;
+	/*[16]
+	 * 0:Response need check CRC7,
+	 * 1: dont need check
+	 */
+	u32 response_have_data:1;
+	/*[17]
+	 * 0:Receiving Response without data,
+	 * 1:Receiving response with data
+	 */
+	u32 response_crc7_from_8:1;
+	/*[18]
+	 * 0:Normal CRC7, Calculating CRC7 will
+	 * be from bit0 of all response bits,
+	 * 1:Calculating CRC7 will be from
+	 * bit8 of all response bits
+	 */
+	u32 check_busy_on_dat0:1;
+	/*[19]
+	 * used for R1b response
+	 * 0: dont check busy on dat0,
+	 * 1:need check
+	 */
+	u32 cmd_send_data:1;
+	/*[20]
+	 * 0:This command is not for transmitting data,
+	 * 1:This command is for transmitting data
+	 */
+	u32 use_int_window:1;
+	/*[21]
+	 * 0:SDIO DAT1 interrupt window disabled, 1:Enabled
+	 */
+	u32 reserved:2;/*[23:22]*/
+	u32 repeat_package_times:8;
+	/*[31:24] Total packages to be sent*/
+};
+
+struct sdio_config {
+	u32 cmd_clk_divide:10;
+	/*[9:0] Clock rate setting,
+	 * Frequency of SD equals to Fsystem/((cmd_clk_divide+1)*2)
+	 */
+	u32 cmd_disable_crc:1;
+	/*[10]
+	 * 0:CRC employed, 1:dont send CRC during command being sent
+	 */
+	u32 cmd_out_at_posedge:1;
+	/*[11]
+	 * Command out at negedge normally, 1:at posedge
+	 */
+	u32 cmd_argument_bits:6;
+	/*[17:12] before CRC added, normally 39*/
+	u32 do_not_delay_data:1;
+	/*[18]
+	 *0:Delay one clock normally, 1:dont delay
+	 */
+	u32 data_latch_at_negedge:1;
+	/*[19]
+	 * 0:Data caught at posedge normally, 1:negedge
+	 */
+	u32 bus_width:1;
+	/*[20] 0:1bit, 1:4bit*/
+	u32 m_endian:2;
+	/*[22:21]
+	 * Change ENDIAN(bytes order) from DMA data (e.g. dma_din[31:0]).
+	 * (00: ENDIAN no change, data output equals to original dma_din[31:0];
+	 * 01: data output equals to {dma_din[23:16],dma_din[31:24],
+	 * dma_din[7:0],dma_din[15:8]};10: data output equals to
+	 * {dma_din[15:0],dma_din[31:16]};11: data output equals to
+	 * {dma_din[7:0],dma_din[15:8],dma_din[23:16],dma_din[31:24]})
+	 */
+	u32 sdio_write_nwr:6;
+	/*[28:23]
+	 * Number of clock cycles waiting before writing data
+	 */
+	u32 sdio_write_crc_ok_status:3;
+	/*[31:29] if CRC status
+	 * equals this register, sdio write can be consider as correct
+	 */
+};
+
+struct sdio_status_irq {
+	u32 sdio_status:4;
+	/*[3:0] Read Only
+	 * SDIO State Machine Current State, just for debug
+	 */
+	u32 sdio_cmd_busy:1;
+	/*[4] Read Only
+	 * SDIO Command Busy, 1:Busy State
+	 */
+	u32 sdio_response_crc7_ok:1;
+	/*[5] Read Only
+	 * SDIO Response CRC7 status, 1:OK
+	 */
+	u32 sdio_data_read_crc16_ok:1;
+	/*[6] Read Only
+	 * SDIO Data Read CRC16 status, 1:OK
+	 */
+	u32 sdio_data_write_crc16_ok:1;
+	/*[7] Read Only
+	 * SDIO Data Write CRC16 status, 1:OK
+	 */
+	u32 sdio_if_int:1;
+	/*[8] write 1 clear this int bit
+	 * SDIO DAT1 Interrupt Status
+	 */
+	u32 sdio_cmd_int:1;
+	/*[9] write 1 clear this int bit
+	 * Command Done Interrupt Status
+	 */
+	u32 sdio_soft_int:1;
+	/*[10] write 1 clear this int bit
+	 * Soft Interrupt Status
+	 */
+	u32 sdio_set_soft_int:1;
+	/*[11] write 1 to this bit
+	 * will set Soft Interrupt, read out is m_req_sdio, just for debug
+	 */
+	u32 sdio_status_info:4;
+	/*[15:12]
+	 * used for change information between ARC and Amrisc
+	 */
+	u32 sdio_timing_out_int:1;
+	/*[16] write 1 clear this int bit
+	 * Timeout Counter Interrupt Status
+	 */
+	u32 amrisc_timing_out_int_en:1;
+	/*[17]
+	 * Timeout Counter Interrupt Enable for AMRISC
+	 */
+	u32 arc_timing_out_int_en:1;
+	/*[18]
+	 * Timeout Counter Interrupt Enable for ARC/ARM
+	 */
+	u32 sdio_timing_out_count:13;
+	/*[31:19]
+	 * Timeout Counter Preload Setting and Present Status
+	 */
+};
+
+struct sdio_irq_config {
+	u32 amrisc_if_int_en:1;
+	/*[0]
+	 * 1:SDIO DAT1 Interrupt Enable for AMRISC
+	 */
+	u32 amrisc_cmd_int_en:1;
+	/*[1]
+	 * 1:Command Done Interrupt Enable for AMRISC
+	 */
+	u32 amrisc_soft_int_en:1;
+	/*[2]
+	 * 1:Soft Interrupt Enable for AMRISC
+	 */
+	u32 arc_if_int_en:1;
+	/*[3]
+	 * 1:SDIO DAT1 Interrupt Enable for ARM/ARC
+	 */
+	u32 arc_cmd_int_en:1;
+	/*[4]
+	 * 1:Command Done Interrupt Enable for ARM/ARC
+	 */
+	u32 arc_soft_int_en:1;
+	/*[5]
+	 * 1:Soft Interrupt Enable for ARM/ARC
+	 */
+	u32 sdio_if_int_config:2;
+	/*[7:6]
+	 * 00:sdio_if_interrupt window will reset after data Tx/Rx or command
+	 * done, others: only after command done
+	 */
+	u32 sdio_force_data:6;
+	/*[13:8]
+	 * Write operation: Data forced by software
+	 * Read operation: {CLK,CMD,DAT[3:0]}
+	 */
+	u32 sdio_force_enable:1;
+	/*[14] Software Force Enable
+	 * This is the software force mode, Software can directly
+	 * write to sdio 6 ports (cmd, clk, dat0..3) if force_output_en
+	 * is enabled. and hardware outputs will be bypassed.
+	 */
+	u32 soft_reset:1;
+	/*[15]
+	 * Write 1 Soft Reset, Don't need to clear it
+	 */
+	u32 sdio_force_output_en:6;
+	/*[21:16]
+	 * Force Data Output Enable,{CLK,CMD,DAT[3:0]}
+	 */
+	u32 disable_mem_halt:2;
+	/*[23:22] write and read
+	 * 23:Disable write memory halt, 22:Disable read memory halt
+	 */
+	u32 sdio_force_data_read:6;
+	/*[29:24] Read Only
+	 * Data read out which have been forced by software
+	 */
+	u32 force_halt:1;
+	/*[30] 1:Force halt SDIO by software
+	 * Halt in this sdio host controller means stop to transmit or
+	 * receive data from sd card. and then sd card clock will be shutdown.
+	 * Software can force to halt anytime, and hardware will automatically
+	 * halt the sdio when reading fifo is full or writing fifo is empty
+	 */
+	u32 halt_hole:1;
+	/*[31]
+	 * 0: SDIO halt for 8bit mode, 1:SDIO halt for 16bit mode
+	 */
+};
+
+struct sdio_mult_config {
+	u32 sdio_port_sel:2; /*[1:0] 0:sdio_a, 1:sdio_b, 2:sdio_c*/
+	u32 ms_enable:1; /*[2] 1:Memory Stick Enable*/
+	u32 ms_sclk_always:1; /*[3] 1: Always send ms_sclk*/
+	u32 stream_enable:1; /*[4] 1:Stream Enable*/
+	u32 stream_8_bits_mode:1; /*[5] Stream 8bits mode*/
+	u32 data_catch_level:2; /*[7:6] Level of data catch*/
+	u32 write_read_out_index:1;
+	/*[8] Write response index Enable
+	 * [31:16], [11:10], [7:0] is set only when
+	 * bit8 of this register is not set.
+	 * And other bits are set only when bit8
+	 * of this register is also set.
+	 */
+	u32 data_catch_readout_en:1; /*[9] Data catch readout Enable*/
+	u32 sdio_0_data_on_1:1; /*[10] 1:dat0 is on dat1*/
+	u32 sdio_1_data_swap01:1; /*[11] 1:dat1 and dat0 swapped*/
+	u32 response_read_index:4; /*[15:12] Index of internal read response*/
+	u32 data_catch_finish_point:12;
+	/*[27:16] If internal data
+	 * catch counter equals this register,
+	 *	it indicates data catching is finished
+	 */
+	u32 reserved:4; /*[31:28]*/
+};
+
+struct sdio_extension {
+	u32 cmd_argument_ext:16;
+	/*[15:0] for future use*/
+	u32 data_rw_number:14;
+	/*[29:16]
+	 * Data Read/Write Number in one packet, include CRC16 if has CRC16
+	 */
+	u32 data_rw_do_not_have_crc16:1;
+	/*[30]
+	 * 0:data Read/Write has crc16, 1:without crc16
+	 */
+	u32 crc_status_4line:1;
+	/*[31] 1:4Lines check CRC Status*/
+};
+
+struct sdio_reg {
+	u32 argument; /*2308*/
+	struct cmd_send send; /*2309*/
+	struct sdio_config config; /*230a*/
+	struct sdio_status_irq status; /*230b*/
+	struct sdio_irq_config irqc; /*230c*/
+	struct sdio_mult_config mult; /*230d*/
+	u32 m_addr; /*230e*/
+	struct sdio_extension ext;/*230f*/
+};
+
+/*-sdhc-*/
+
+#define SDHC_ARGU				(0x00)
+#define SDHC_SEND				(0x04)
+#define SDHC_CTRL				(0x08)
+#define SDHC_STAT				(0x0C)
+#define SDHC_CLKC				(0x10)
+#define SDHC_ADDR				(0x14)
+#define SDHC_PDMA				(0x18)
+#define SDHC_MISC				(0x1C)
+#define SDHC_DATA				(0x20)
+#define SDHC_ICTL				(0x24)
+#define SDHC_ISTA				(0x28)
+#define SDHC_SRST				(0x2C)
+#define SDHC_ESTA				(0x30)
+#define SDHC_ENHC				(0x34)
+#define SDHC_CLK2				(0x38)
+
+/* sdio cbus register */
+#define CBUS_SDIO_ARGU		(0x2308)
+#define CBUS_SDIO_SEND		(0x2309)
+#define CBUS_SDIO_CONF		(0x230a)
+#define CBUS_SDIO_IRQS		(0x230b)
+#define CBUS_SDIO_IRQC		(0x230c)
+#define CBUS_SDIO_MULT		(0x230d)
+#define CBUS_SDIO_ADDR		(0x230e)
+#define CBUS_SDIO_EXT		(0x230f)
+
+
+/* CBUS reg definition */
+#define	ISA_TIMERE			0x2655
+#define	HHI_GCLK_MPEG0		0x1050
+#define	ASSIST_POR_CONFIG	0x1f55
+
+#define PREG_PAD_GPIO0_EN_N 0x200c
+#define PREG_PAD_GPIO0_O	0x200d
+#define PREG_PAD_GPIO0_I	0x200e
+#define PREG_PAD_GPIO1_EN_N 0x200f
+#define PREG_PAD_GPIO1_O	0x2010
+#define PREG_PAD_GPIO1_I	0x2011
+#define PREG_PAD_GPIO2_EN_N 0x2012
+#define PREG_PAD_GPIO2_O	0x2013
+#define PREG_PAD_GPIO2_I	0x2014
+#define PREG_PAD_GPIO3_EN_N 0x2015
+#define PREG_PAD_GPIO3_O	0x2016
+#define PREG_PAD_GPIO3_I	0x2017
+#define PREG_PAD_GPIO4_EN_N 0x2018
+#define PREG_PAD_GPIO4_O	0x2019
+#define PREG_PAD_GPIO4_I	0x201a
+#define PREG_PAD_GPIO5_EN_N 0x201b
+#define PREG_PAD_GPIO5_O	0x201c
+#define PREG_PAD_GPIO5_I	0x201d
+
+#define	PERIPHS_PIN_MUX_0	0x202c
+#define	PERIPHS_PIN_MUX_1	0x202d
+#define	PERIPHS_PIN_MUX_2	0x202e
+#define	PERIPHS_PIN_MUX_3	0x202f
+#define	PERIPHS_PIN_MUX_4	0x2030
+#define	PERIPHS_PIN_MUX_5	0x2031
+#define	PERIPHS_PIN_MUX_6	0x2032
+#define	PERIPHS_PIN_MUX_7	0x2033
+#define	PERIPHS_PIN_MUX_8	0x2034
+#define	PERIPHS_PIN_MUX_9	0x2035
+
+/* interrupt definition */
+#define	INT_SDIO	(60-32)
+#define	INT_SDHC	(110-32)
+
+#define INT_GPIO_0	(96-32)
+#define INT_GPIO_1	(97-32)
+#define INT_GPIO_2	(98-32)
+#define INT_GPIO_3	(99-32)
+#define INT_GPIO_4	(100-32)
+#define INT_GPIO_5	(101-32)
+#define INT_GPIO_6	(102-32)
+#define INT_GPIO_7	(103-32)
+
+
+struct sdhc_send {
+	/*[5:0] command index*/
+	u32 cmd_index:6;
+	/*[6] 0:no resp 1:has resp*/
+	u32 cmd_has_resp:1;
+	/*[7] 0:no data 1:has data*/
+	u32 cmd_has_data:1;
+	/*[8] 0:48bit 1:136bit*/
+	u32 resp_len:1;
+	/*[9] 0:check crc7 1:don't check crc7*/
+	u32 resp_no_crc:1;
+	/*[10] 0:data rx, 1:data tx*/
+	u32 data_dir:1;
+	/*[11] 0:rx or tx, 1:data stop,ATTN:will give rx a softreset*/
+	u32 data_stop:1;
+	/*[12] 0: resp with no busy, 1:R1B*/
+	u32 r1b:1;
+	/*[15:13] reserved*/
+	u32 reserved:3;
+	/*[31:16] total package number for writing or reading*/
+	u32 total_pack:16;
+};
+
+struct sdhc_ctrl {
+	/*[1:0] 0:1bit, 1:4bits, 2:8bits, 3:reserved*/
+	u32 dat_type:2;
+	/*[2] 0:SDR mode, 1:Don't set it*/
+	u32 ddr_mode:1;
+	/*[3] 0:check sd write crc result, 1:disable tx crc check*/
+	u32 tx_crc_nocheck:1;
+	/*[12:4] 0:512Bytes, 1:1, 2:2, ..., 511:511Bytes*/
+	u32 pack_len:9;
+	/*[19:13] cmd or wcrc Receiving Timeout, default 64*/
+	u32 rx_timeout:7;
+	/*[23:20]Period between response/cmd and next cmd, default 8*/
+	u32 rx_period:4;
+	/*[26:24] Rx Endian Control*/
+	u32 rx_endian:3;
+	/*[27]0:Normal mode, 1: support data block gap
+	 *(need turn off clock gating)
+	 */
+	u32 sdio_irq_mode:1;
+	/*[28] Dat0 Interrupt selection,0:busy check after response,
+	 *1:any rising edge of dat0
+	 */
+	u32 dat0_irq_sel:1;
+	/*[31:29] Tx Endian Control*/
+	u32 tx_endian:3;
+};
+
+struct sdhc_stat {
+	/*[0] 0:Ready for command, 1:busy*/
+	u32 cmd_busy:1;
+	/*[4:1] DAT[3:0]*/
+	u32 dat3_0:4;
+	/*[5] CMD*/
+	u32 cmd:1;
+	/*[12:6] RxFIFO count*/
+	u32 rxfifo_cnt:7;
+	/*[19:13] TxFIFO count*/
+	u32 txfifo_cnt:7;
+	/*[23:20] DAT[7:4]*/
+	u32 dat7_4:4;
+	/*[31:24] Reserved*/
+	u32 reserved:8;
+};
+
+/*
+ * to avoid glitch issue,
+ * 1. clk_switch_on better be set after cfg_en be set to 1'b1
+ * 2. clk_switch_off shall be set before cfg_en be set to 1'b0
+ * 3. rx_clk/sd_clk phase diff please see SD_REGE_CLK2.
+ */
+struct sdhc_clkc {
+	/*[11:0] clk_div for TX_CLK 0: don't set it,1:div2, 2:div3, 3:div4 ...*/
+	u32 clk_div:12;
+	/*[12] TX_CLK 0:switch off, 1:switch on*/
+	u32 tx_clk_on:1;
+	/*[13] RX_CLK 0:switch off, 1:switch on*/
+	u32 rx_clk_on:1;
+	/*[14] SD_CLK 0:switch off, 1:switch on*/
+	u32 sd_clk_on:1;
+	/*[15] Clock Module Enable, Should set before bit[14:12] switch on,
+	 *	and after bit[14:12] switch off
+	 */
+	u32 mod_clk_on:1;
+	/*[17:16] 0:osc, 1:fclk_div4, 2:fclk_div3, 3:fclk_div5*/
+	u32 clk_src_sel:2;
+	/*[23:18] Reserved*/
+	u32 reserved:6;
+	/*[24] Clock JIC for clock gating control
+	 *1: will turn off clock gating
+	 */
+	u32 clk_jic:1;
+	/*[26:25] 00:Memory Power Up, 11:Memory Power Off*/
+	u32 mem_pwr_off:2;
+	/*[31:27] Reserved*/
+	u32 reserved2:5;
+};
+
+/*
+ * Note1: dma_urgent is just set when bandwidth is very tight
+ * Note2: pio_rdresp need to be combined with REG0_ARGU;
+ * For R0, when 0, reading REG0 will get the normal 32bit response;
+ * For R2, when 1, reading REG0 will get CID[31:0], when 2, get CID[63:32],
+ * and so on; 6 or 7, will get original command argument.
+ */
+struct sdhc_pdma {
+	/*[0] 0:PIO mode, 1:DMA mode*/
+	u32 dma_mode:1;
+	/*[3:1] 0:[39:8] 1:1st 32bits, 2:2nd ...,6 or 7:command argument*/
+	u32 pio_rdresp:3;
+	/*[4] 0:not urgent, 1:urgent*/
+	u32 dma_urgent:1;
+	/*[9:5] Number in one Write request burst(0:1,1:2...)*/
+	u32 wr_burst:5;
+	/*[14:10] Number in one Read request burst(0:1, 1:2...)*/
+	u32 rd_burst:5;
+	/*[21:15] RxFIFO threshold, >=rxth, will request write*/
+	u32 rxfifo_th:7;
+	/*[28:22] TxFIFO threshold, <=txth, will request read*/
+	u32 txfifo_th:7;
+	/*[30:29] [30]self-clear-flush,[29] mode: 0:hw, 1:sw*/
+	u32 rxfifo_manual_flush:2;
+	/*[31] self-clear-fill, recommand to write before sd send*/
+	u32 txfifo_fill:1;
+};
+
+struct sdhc_misc {
+	/*[3:0] reserved*/
+	u32 reserved:4;
+	/*[6:4] WCRC Error Pattern*/
+	u32 wcrc_err_patt:3;
+	/*[9:7] WCRC OK Pattern*/
+	u32 wcrc_ok_patt:3;
+	/*[15:10] reserved*/
+	u32 reserved1:6;
+	/*[21:16] Burst Number*/
+	u32 burst_num:6;
+	/*[27:22] Thread ID*/
+	u32 thread_id:6;
+	/*[28] 0:auto stop mode, 1:manual stop mode*/
+	u32 manual_stop:1;
+	/*[31:29] txstart_thres(if (txfifo_cnt/4)>
+	 *	(threshold*2), Tx will start)
+	 */
+	u32 txstart_thres:3;
+};
+
+struct sdhc_ictl {
+	/*[0] Response is received OK*/
+	u32 resp_ok:1;
+	/*[1] Response Timeout Error*/
+	u32 resp_timeout:1;
+	/*[2] Response CRC Error*/
+	u32 resp_err_crc:1;
+	/*[3] Response is received OK(always no self reset)*/
+	u32 resp_ok_noclear:1;
+	/*[4] One Package Data Completed ok*/
+	u32 data_1pack_ok:1;
+	/*[5] One Package Data Failed (Timeout Error)*/
+	u32 data_timeout:1;
+	/*[6] One Package Data Failed (CRC Error)*/
+	u32 data_err_crc:1;
+	/*[7] Data Transfer Completed ok*/
+	u32 data_xfer_ok:1;
+	/*[8] RxFIFO count > threshold*/
+	u32 rx_higher:1;
+	/*[9] TxFIFO count < threshold*/
+	u32 tx_lower:1;
+	/*[10] SDIO DAT1 Interrupt*/
+	u32 dat1_irq:1;
+	/*[11] DMA Done*/
+	u32 dma_done:1;
+	/*[12] RxFIFO Full*/
+	u32 rxfifo_full:1;
+	/*[13] TxFIFO Empty*/
+	u32 txfifo_empty:1;
+	/*[14] Additional SDIO DAT1 Interrupt*/
+	u32 addi_dat1_irq:1;
+	/*[15] reserved*/
+	u32 reserved:1;
+	/*[17:16] sdio dat1 interrupt mask windows
+	 *	clear delay control,0:2cycle 1:1cycles
+	 */
+	u32 dat1_irq_delay:2;
+	/*[31:18] reserved*/
+	u32 reserved1:14;
+};
+
+/*Note1: W1C is write one clear.*/
+struct sdhc_ista {
+	/*[0] Response is received OK (W1C)*/
+	u32 resp_ok:1;
+	/*[1] Response is received Failed (Timeout Error) (W1C)*/
+	u32 resp_timeout:1;
+	/*[2] Response is received Failed (CRC Error) (W1C)*/
+	u32 resp_err_crc:1;
+	/*[3] Response is Received OK (always no self reset)*/
+	u32 resp_ok_noclear:1;
+	/*[4] One Package Data Completed ok (W1C)*/
+	u32 data_1pack_ok:1;
+	/*[5] One Package Data Failed (Timeout Error) (W1C)*/
+	u32 data_timeout:1;
+	/*[6] One Package Data Failed (CRC Error) (W1C)*/
+	u32 data_err_crc:1;
+	/*[7] Data Transfer Completed ok (W1C)*/
+	u32 data_xfer_ok:1;
+	/*[8] RxFIFO count > threshold (W1C)*/
+	u32 rx_higher:1;
+	/*[9] TxFIFO count < threshold (W1C)*/
+	u32 tx_lower:1;
+	/*[10] SDIO DAT1 Interrupt (W1C)*/
+	u32 dat1_irq:1;
+	/*[11] DMA Done (W1C)*/
+	u32 dma_done:1;
+	/*[12] RxFIFO Full(W1C)*/
+	u32 rxfifo_full:1;
+	/*[13] TxFIFO Empty(W1C)*/
+	u32 txfifo_empty:1;
+	/*[14] Additional SDIO DAT1 Interrupt*/
+	u32 addi_dat1_irq:1;
+	/*[31:13] reserved*/
+	u32 reserved:17;
+};
+
+/*
+ * Note1: Soft reset for DPHY TX/RX needs programmer to set it
+ * and then clear it manually.
+ */
+struct sdhc_srst {
+	/*[0] Soft reset for MAIN CTRL(self clear)*/
+	u32 main_ctrl:1;
+	/*[1] Soft reset for RX FIFO(self clear)*/
+	u32 rxfifo:1;
+	/*[2] Soft reset for TX FIFO(self clear)*/
+	u32 txfifo:1;
+	/*[3] Soft reset for DPHY RX*/
+	u32 dphy_rx:1;
+	/*[4] Soft reset for DPHY TX*/
+	u32 dphy_tx:1;
+	/*[5] Soft reset for DMA IF(self clear)*/
+	u32 dma_if:1;
+	/*[31:6] reserved*/
+	u32 reserved:26;
+};
+
+struct  sdhc_enhc {
+	union  {
+		struct  {
+			/*[0] 0:Wrrsp Check in DMA Rx FSM 1:No Check in FSM*/
+			u32 wrrsp_mode:1;
+			/*[1] Rx Done without checking if Wrrsp count is 0*/
+			u32 chk_wrrsp:1;
+			/*[2] Rx Done without checking if DMA is IDLE*/
+			u32 chk_dma:1;
+			/*[5:3] debug only*/
+			u32 debug:3;
+			u32 reserved:2;
+			/*[15:8] SDIO IRQ Period Setting*/
+			u32 sdio_irq_period:8;
+			u32 reserved1:2;
+			/*[24:18] RXFIFO Full Threshold,default 60*/
+			u32 rxfifo_th:7;
+			/*[31:25] TXFIFO Empty Threshold,default 0*/
+			u32 txfifo_th:7;
+		}  meson8m2;
+		struct  {
+			/*[7:0] Data Rx Timeout Setting*/
+			u32 rx_timeout:8;
+			/*[15:8] SDIO IRQ Period Setting
+			 *(IRQ checking window length)
+			 */
+			u32 sdio_irq_period:8;
+			/*[16] No Read DMA Response Check*/
+			u32 dma_rd_resp:1;
+			/*[16] No Write DMA Response Check*/
+			u32 dma_wr_resp:1;
+			/*[24:18] RXFIFO Full Threshold,default 60*/
+			u32 rxfifo_th:7;
+			/*[31:25] TXFIFO Empty Threshold,default 0*/
+			u32 txfifo_th:7;
+		}  meson;
+	} reg;
+};
+
+struct sdhc_clk2 {
+	/*[11:0] rx_clk phase diff(default 0:no diff,
+	 *1:one input clock cycle ...)
+	 */
+	u32 rx_clk_phase:12;
+	/*[23:12] sd_clk phase diff(default 0:half(180 degree),
+	 *1:half+one input clock cycle, 2:half+2 input clock cycles, ...)
+	 */
+	u32 sd_clk_phase:12;
+	/*[31:24] reserved*/
+	u32 reserved:8;
+};
+
+#define SDHC_CLOCK_SRC_OSC			  0 /* 24MHz */
+#define SDHC_CLOCK_SRC_FCLK_DIV4		1
+#define SDHC_CLOCK_SRC_FCLK_DIV3		2
+#define SDHC_CLOCK_SRC_FCLK_DIV5		3
+#define SDHC_ISTA_W1C_ALL			   0x7fff
+#define SDHC_SRST_ALL				   0x3f
+#define SDHC_ICTL_ALL						0x7fff
+
+struct sd_emmc_regs {
+	u32 gclock;	 /* 0x00 */
+	u32 gdelay;	 /* 0x04 */
+	u32 gadjust;	/* 0x08 */
+	u32 reserved_0c;	   /* 0x0c */
+	u32 gcalout[4];	/* 0x10~0x1c */
+	u32 reserved_20[8];   /* 0x20~0x3c */
+	u32 gstart;	 /* 0x40 */
+	u32 gcfg;	   /* 0x44 */
+	u32 gstatus;	/* 0x48 */
+	u32 girq_en;	/* 0x4c */
+	u32 gcmd_cfg;   /* 0x50 */
+	u32 gcmd_arg;   /* 0x54 */
+	u32 gcmd_dat;   /* 0x58 */
+	u32 gcmd_rsp0;   /* 0x5c */
+	u32 gcmd_rsp1;  /* 0x60 */
+	u32 gcmd_rsp2;  /* 0x64 */
+	u32 gcmd_rsp3;  /* 0x68 */
+	u32 reserved_6c;	   /* 0x6c */
+	u32 gcurr_cfg;  /* 0x70 */
+	u32 gcurr_arg;  /* 0x74 */
+	u32 gcurr_dat;  /* 0x78 */
+	u32 gcurr_rsp;  /* 0x7c */
+	u32 gnext_cfg;  /* 0x80 */
+	u32 gnext_arg;  /* 0x84 */
+	u32 gnext_dat;  /* 0x88 */
+	u32 gnext_rsp;  /* 0x8c */
+	u32 grxd;	   /* 0x90 */
+	u32 gtxd;	   /* 0x94 */
+	u32 reserved_98[90];   /* 0x98~0x1fc */
+	u32 gdesc[128]; /* 0x200 */
+	u32 gping[128]; /* 0x400 */
+	u32 gpong[128]; /* 0x800 */
+};
+struct sd_emmc_clock {
+	/*[5:0]	 Clock divider.
+	 *Frequency = clock source/cfg_div, Maximum divider 63.
+	 */
+	u32 div:6;
+	/*[7:6]	 Clock source, 0: Crystal 24MHz, 1: Fix PLL, 850MHz*/
+	u32 src:2;
+	/*[9:8]	 Core clock phase. 0: 0 phase,
+	 *1: 90 phase, 2: 180 phase, 3: 270 phase.
+	 */
+	u32 core_phase:2;
+	/*[11:10]   TX clock phase. 0: 0 phase,
+	 *1: 90 phase, 2: 180 phase, 3: 270 phase.
+	 */
+	u32 tx_phase:2;
+	/*[13:12]   RX clock phase. 0: 0 phase,
+	 *1: 90 phase, 2: 180 phase, 3: 270 phase.
+	 */
+	u32 rx_phase:2;
+	u32 reserved14:2;
+	/*[19:16]   TX clock delay line. 0: no delay,
+	 *n: delay n*200ps. Maximum delay 3ns.
+	 */
+	u32 tx_delay:4;
+	/*[23:20]   RX clock delay line. 0: no delay,
+	 *n: delay n*200ps. Maximum delay 3ns.
+	 */
+	u32 rx_delay:4;
+	/*[24]	  1: Keep clock always on.
+	 *0: Clock on/off controlled by activities.
+	 */
+	u32 always_on:1;
+	/*[25]	1: enable IRQ sdio when in sleep mode. */
+	u32 irq_sdio_sleep:1;
+	/*[26]	1: select DS as IRQ source during sleep.. */
+	u32 irq_sdio_sleep_ds:1;
+	u32 reserved27:5;
+};
+struct sd_emmc_delay {
+	u32 dat0:4;		 /*[3:0]	   Data 0 delay line. */
+	u32 dat1:4;		 /*[7:4]	   Data 1 delay line. */
+	u32 dat2:4;		 /*[11:8]	  Data 2 delay line. */
+	u32 dat3:4;		 /*[15:12]	 Data 3 delay line. */
+	u32 dat4:4;		 /*[19:16]	 Data 4 delay line. */
+	u32 dat5:4;		 /*[23:20]	 Data 5 delay line. */
+	u32 dat6:4;		 /*[27:24]	 Data 6 delay line. */
+	u32 dat7:4;		 /*[31:28]	 Data 7 delay line. */
+};
+struct sd_emmc_adjust {
+	/*[3:0]	   Command delay line. */
+	u32 cmd_delay:4;
+	/*[7:4]	   DS delay line. */
+	u32 ds_delay:4;
+	/*[11:8]	  Select one signal to be tested.*/
+	u32 cali_sel:4;
+	/*[12]		Enable calibration. */
+	u32 cali_enable:1;
+	/*[13]	   Adjust interface timing
+	 *by resampling the input signals.
+	 */
+	u32 adj_enable:1;
+	/*[14]	   1: test the rising edge.
+	 *0: test the falling edge.
+	 */
+	u32 cali_rise:1;
+	/*[15]	   1: Sampling the DAT based on DS in HS400 mode.
+	 *0: Sampling the DAT based on RXCLK.
+	 */
+	u32 ds_enable:1;
+	/*[21:16]	   Resample the input signals
+	 *when clock index==adj_delay.
+	 */
+	u32 adj_delay:6;
+	/*[22]	   1: Use cali_dut first falling edge to adjust
+	 *	the timing, set cali_enable to 1 to use this function.
+	 *0: no use adj auto.
+	 */
+	u32 adj_auto:1;
+	u32 reserved22:9;
+};
+struct sd_emmc_calout {
+	/*[5:0]	   Calibration reading.
+	 *The event happens at this index.
+	 */
+	u32 cali_idx:6;
+	u32 reserved6:1;
+	/*[7]		 The reading is valid. */
+	u32 cali_vld:1;
+	/*[15:8]	  Copied from BASE+0x8
+	 *[15:8] include cali_sel, cali_enable, adj_enable, cali_rise.
+	 */
+	u32 cali_setup:8;
+	u32 reserved16:16;
+};
+struct sd_emmc_start {
+	/*[0]   1: Read descriptor from internal SRAM,
+	 *limited to 32 descriptors.
+	 */
+	u32 init:1;
+	/*[1]   1: Start command chain execution process. 0: Stop */
+	u32 busy:1;
+	/*[31:2] Descriptor address, the last 2 bits are 0,
+	 *4 bytes aligned.
+	 */
+	u32 addr:30;
+};
+struct sd_emmc_config {
+	/*[1:0]	 0: 1 bit, 1: 4 bits,
+	 *2: 8 bits, 3: 2 bits (not supported)
+	 */
+	u32 bus_width:2;
+	/*[2]	   1: DDR mode, 0: SDR mode */
+	u32 ddr:1;
+	/*[3]	   1: DDR access urgent, 0: DDR access normal. */
+	u32 dc_ugt:1;
+	/*[7:4]	 Block length 2^cfg_bl_len,
+	 *because internal buffer size is limited to 512 bytes,
+	 *the cfg_bl_len <=9.
+	 */
+	u32 bl_len:4;
+	/*[11:8]	Wait response till 2^cfg_resp_timeout core clock cycles.
+	 *Maximum 32768 core cycles.
+	 */
+	u32 resp_timeout:4;
+	/*[15:12]   Wait response-command,
+	 *command-command gap before next command,
+	 *2^cfg_rc_cc core clock cycles.
+	 */
+	u32 rc_cc:4;
+	/*[16]	  DDR mode only. The command and TXD start from rising edge.
+	 *Set 1 to start from falling edge.
+	 */
+	u32 out_fall:1;
+	/*[17]	  1: Enable SDIO data block gap interrupt period.
+	 *0: Disabled.
+	 */
+	u32 blk_gap_ip:1;
+	/*[18]	  Spare,  ??? need check*/
+	u32 spare:1;
+	/*[19]	  Use this descriptor
+	 *even if its owner bit is ???0????.
+	 */
+	u32 ignore_owner:1;
+	/*[20]	  Check data strobe in HS400.*/
+	u32 chk_ds:1;
+	/*[21]	  Hold CMD as output Low, eMMC boot mode.*/
+	u32 cmd_low:1;
+	/*[22]	  1: stop clock. 0: normal clock.*/
+	u32 stop_clk:1;
+	/*[23]	  1: when BUS is idle and no descriptor is available,
+	 *turn off clock, to save power.
+	 */
+	u32 auto_clk:1;
+	/*[24]	TXD add error test*/
+	u32 txd_add_err:1;
+	/*[25]	When TXD CRC error, host sends the block again.*/
+	u32 txd_retry:1;
+	/*[26]	1: Use DS pin as SDIO IRQ input,
+	 *0: Use DAT1 pin as SDIO IRQ input..
+	 */
+	u32 irq_ds:1;
+	u32 err_abort:1;
+	u32 revd:4;			/*[31:27]   reved*/
+};
+struct sd_emmc_status {
+	/*[7:0]	 RX data CRC error per wire, for multiple block read,
+	 *the CRC errors are ORed together.
+	 */
+	u32 rxd_err:8;
+	/*[8]	   TX data CRC error, for multiple block write,
+	 *any one of blocks CRC error.
+	 */
+	u32 txd_err:1;
+	/*[9]	   SD/eMMC controller doesn????t own descriptor.
+	 *The owner bit is set cfg_ignore_owner to ignore this error.
+	 */
+	u32 desc_err:1;
+	/*[10]	  Response CRC error.*/
+	u32 resp_err:1;
+	/*[11]	  No response received before time limit.
+	 *The timeout limit is set by cfg_resp_timeout.
+	 */
+	u32 resp_timeout:1;
+	/*[12]	  Descriptor execution time over time limit.
+	 *The timeout limit is set by descriptor itself.
+	 */
+	u32 desc_timeout:1;
+	/*[13]	  End of Chain IRQ, Normal IRQ. */
+	u32 end_of_chain:1;
+	/*[14]	  This descriptor requests an IRQ, Normal IRQ,
+	 *the descriptor chain execution keeps going on.
+	 */
+	u32 desc_irq:1;
+	/*[15]	  SDIO device uses DAT[1] to request IRQ. */
+	u32 irq_sdio:1;
+	/*[23:16]   Input data signals. */
+	u32 dat_i:8;
+	/*[24]	  nput response signal. */
+	u32 cmd_i:1;
+	/*[25]	  Input data strobe. */
+	u32 ds:1;
+	/*[29:26]   BUS fsm */
+	u32 bus_fsm:4;
+	/*[30]	  Descriptor write back process is done
+	 *and it is ready for CPU to read.
+	 */
+	u32 desc_wr_rdy:1;
+	/*[31]	  Core is busy,desc_busy or sd_emmc_irq
+	 *  or bus_fsm is not idle.
+	 */
+	u32 core_wr_rdy:1;
+};
+struct sd_emmc_irq_en {
+	/*[7:0]	 RX data CRC error per wire.*/
+	u32 rxd_err:8;
+	/*[8]	   TX data CRC error. */
+	u32 txd_err:1;
+	/*[9]	   SD/eMMC controller doesn????t own descriptor. */
+	u32 desc_err:1;
+	/*[10]	  Response CRC error.*/
+	u32 resp_err:1;
+	/*[11]	  No response received before time limit. */
+	u32 resp_timeout:1;
+	/*[12]	  Descriptor execution time over time limit. */
+	u32 desc_timeout:1;
+	/*[13]	  End of Chain IRQ. */
+	u32 end_of_chain:1;
+	/*[14]	  This descriptor requests an IRQ. */
+	u32 desc_irq:1;
+	/*[15]	  Enable sdio interrupt. */
+	u32 irq_sdio:1;
+	/*[31:16]   reved*/
+	u32 revd:16;
+};
+struct sd_emmc_data_info {
+	/*[9:0]	 Rxd words received from BUS. Txd words received from DDR.*/
+	u32 cnt:10;
+	/*[24:16]   Rxd Blocks received from BUS.
+	 *Txd blocks received from DDR.
+	 */
+	u32 blk:9;
+	/*[31:17]   Reved. */
+	u32 revd:30;
+};
+struct sd_emmc_card_info {
+	/*[9:0]	 Txd BUS cycle counter. */
+	u32 txd_cnt:10;
+	/*[24:16]   Txd BUS block counter.*/
+	u32 txd_blk:9;
+	/*[31:17]   Reved. */
+	u32 revd:30;
+};
+struct cmd_cfg {
+	u32 length:9;
+	u32 block_mode:1;
+	u32 r1b:1;
+	u32 end_of_chain:1;
+	u32 timeout:4;
+	u32 no_resp:1;
+	u32 no_cmd:1;
+	u32 data_io:1;
+	u32 data_wr:1;
+	u32 resp_nocrc:1;
+	u32 resp_128:1;
+	u32 resp_num:1;
+	u32 data_num:1;
+	u32 cmd_index:6;
+	u32 error:1;
+	u32 owner:1;
+};
+struct sd_emmc_desc_info {
+	u32 cmd_info;
+	u32 cmd_arg;
+	u32 data_addr;
+	u32 resp_addr;
+};
+#define SD_EMMC_MAX_DESC_MUN					512
+#define SD_EMMC_REQ_DESC_MUN					4
+#define SD_EMMC_CLOCK_SRC_OSC				 0 /* 24MHz */
+#define SD_EMMC_CLOCK_SRC_FCLK_DIV2		   1 /* 1GHz */
+#define SD_EMMC_CLOCK_SRC_MPLL				2 /* MPLL */
+#define SD_EMMC_CLOCK_SRC_DIFF_PLL			3
+#define SD_EMMC_IRQ_ALL					0x3fff
+#define SD_EMMC_RESP_SRAM_OFF					0
+/*#define SD_EMMC_DESC_SET_REG*/
+
+#define SD_EMMC_DESC_REG_CONF					0x4
+#define SD_EMMC_DESC_REG_IRQC					0xC
+#define SD_EMMC_DESC_RESP_STAT				0xfff80000
+#define SD_EMMC_IRQ_EN_ALL_INIT
+#define SD_EMMC_REQ_DMA_SGMAP
+/* #define SD_EMMC_CLK_CTRL*/
+/* #define SD_EMMC_DATA_TASKLET */
+#define STAT_POLL_TIMEOUT				0xfffff
+#define STAT_POLL_TIMEOUT				0xfffff
+
+#define MMC_RSP_136_NUM					4
+#define MMC_MAX_DEVICE					3
+#define MMC_TIMEOUT						5000
+
+/* #define pr_info(a...) */
+#define DBG_LINE_INFO() \
+{ \
+	pr_info("[%s] : %s\n", __func__, __FILE__); \
+}
+/* #define DBG_LINE_INFO() */
+/* #define dev_err(a,s) pr_info(KERN_INFO s); */
+#define BOOT_POLL_UP_DOWN (0x3C << 2)
+#define BOOT_POLL_UP_DOWN_EN (0x4A << 2)
+
+#define AML_MMC_DISABLED_TIMEOUT	100
+#define AML_MMC_SLEEP_TIMEOUT		1000
+#define AML_MMC_OFF_TIMEOUT 8000
+
+#define SD_EMMC_BOUNCE_REQ_SIZE		(512*1024)
+#define SDHC_BOUNCE_REQ_SIZE		(512*1024)
+#define SDIO_BOUNCE_REQ_SIZE		(128*1024)
+#define MMC_TIMEOUT_MS		20
+
+#define MESON_SDIO_PORT_A 0
+#define MESON_SDIO_PORT_B 1
+#define MESON_SDIO_PORT_C 2
+#define MESON_SDIO_PORT_XC_A 3
+#define MESON_SDIO_PORT_XC_B 4
+#define MESON_SDIO_PORT_XC_C 5
+
+void aml_sdhc_request(struct mmc_host *mmc, struct mmc_request *mrq);
+int aml_sdhc_get_cd(struct mmc_host *mmc);
+extern void amlsd_init_debugfs(struct mmc_host *host);
+
+extern struct mmc_host *sdio_host;
+
+#define	 SPI_BOOT_FLAG				   0
+#define	 NAND_BOOT_FLAG				  1
+#define	 EMMC_BOOT_FLAG				  2
+#define	 CARD_BOOT_FLAG				  3
+#define	 SPI_NAND_FLAG				   4
+#define	 SPI_EMMC_FLAG				   5
+
+#define R_BOOT_DEVICE_FLAG  (aml_read_cbus(ASSIST_POR_CONFIG))
+
+
+#define POR_BOOT_VALUE ((((R_BOOT_DEVICE_FLAG>>9)&1)<<2)|\
+		((R_BOOT_DEVICE_FLAG>>6)&3)) /* {poc[9],poc[7:6]} */
+
+#define POR_NAND_BOOT() ((POR_BOOT_VALUE == 7) \
+		|| (POR_BOOT_VALUE == 6))
+#define POR_SPI_BOOT() ((POR_BOOT_VALUE == 5) || (POR_BOOT_VALUE == 4))
+/* #define POR_EMMC_BOOT() (POR_BOOT_VALUE == 3) */
+#define POR_EMMC_BOOT()	(POR_BOOT_VALUE == 3)
+
+#define POR_CARD_BOOT() (POR_BOOT_VALUE == 0)
+
+#define print_tmp(fmt, args...) \
+{ \
+	pr_info("[%s] " fmt, __func__, ##args); \
+}
+
+#define print_dbg(fmt, args...) \
+{ \
+	pr_info("[%s] " fmt, __func__, ##args); \
+}
+
+/* for external codec status, if using external codec,
+ *	jtag should not be set.
+ */
+extern int ext_codec;
+
+#ifndef CONFIG_MESON_TRUSTZONE
+/* P_AO_SECURE_REG1 is "Secure Register 1" in <M8-Secure-AHB-Registers.doc> */
+#define aml_jtag_gpioao()
+/*do{\
+ *	aml_clr_reg32_mask(P_AO_SECURE_REG1, ((1<<5) | (1<<9))); \
+ *	if(!ext_codec)\
+ *	aml_set_reg32_mask(P_AO_SECURE_REG1, ((1<<8) | (1<<1))); \
+ *}while(0)
+ */
+
+#define aml_jtag_sd()
+/*do{\
+ *	aml_clr_reg32_mask(P_AO_SECURE_REG1, ((1<<8) | (1<<1))); \
+ *	aml_set_reg32_mask(P_AO_SECURE_REG1, ((1<<5) | (1<<9))); \
+ *}while(0)
+ */
+#else
+/* Secure REG can only be accessed in Secure World if TrustZone enabled.*/
+#include <mach/meson-secure.h>
+#define aml_jtag_gpioao() \
+{ \
+	meson_secure_reg_write(P_AO_SECURE_REG1, \
+			meson_secure_reg_read(P_AO_SECURE_REG1) \
+			& (~((1<<5) | (1<<9)))); \
+}
+
+#define aml_jtag_sd() do {\
+	meson_secure_reg_write(P_AO_SECURE_REG1,\
+			meson_secure_reg_read(P_AO_SECURE_REG1)\
+			& (~(1<<8) | (1<<1))); \
+	meson_secure_reg_write(P_AO_SECURE_REG1,\
+			meson_secure_reg_read(P_AO_SECURE_REG1)\
+			| ((1<<5) | (1<<9))); \
+} while (0)
+#endif /* CONFIG_MESON_TRUSTZONE */
+
+#define aml_uart_pinctrl() do {\
+	\
+} while (0)
+
+#endif
+
diff --git a/include/linux/mmc/card.h b/include/linux/mmc/card.h
index aad015e..5b2474c 100644
--- a/include/linux/mmc/card.h
+++ b/include/linux/mmc/card.h
@@ -251,6 +251,13 @@ struct mmc_card {
 #define MMC_TYPE_SDIO		2		/* SDIO card */
 #define MMC_TYPE_SD_COMBO	3		/* SD combo (IO+mem) card */
 	unsigned int		state;		/* (our) card state */
+#define MMC_STATE_PRESENT      (1<<0)          /* present in sysfs */
+#define MMC_STATE_READONLY     (1<<1)          /* card is read-only */
+#define MMC_STATE_BLOCKADDR    (1<<2)          /* card uses block-addressing */
+#define MMC_CARD_SDXC          (1<<3)          /* card is SDXC */
+#define MMC_CARD_REMOVED       (1<<4)          /* card has been removed */
+#define MMC_STATE_DOING_BKOPS  (1<<5)          /* card is doing BKOPS */
+#define MMC_STATE_SUSPENDED    (1<<6)          /* card is suspended */
 	unsigned int		quirks; 	/* card quirks */
 #define MMC_QUIRK_LENIENT_FN0	(1<<0)		/* allow SDIO FN0 writes outside of the VS CCCR range */
 #define MMC_QUIRK_BLKSZ_FOR_BYTE_MODE (1<<1)	/* use func->cur_blksize */
@@ -321,4 +328,23 @@ static inline bool mmc_large_sector(struct mmc_card *card)
 #define mmc_card_sd(c)		((c)->type == MMC_TYPE_SD)
 #define mmc_card_sdio(c)	((c)->type == MMC_TYPE_SDIO)

+#define mmc_card_present(c)     ((c)->state & MMC_STATE_PRESENT)
+#define mmc_card_readonly(c)    ((c)->state & MMC_STATE_READONLY)
+#define mmc_card_blockaddr(c)   ((c)->state & MMC_STATE_BLOCKADDR)
+#define mmc_card_ext_capacity(c) ((c)->state & MMC_CARD_SDXC)
+#define mmc_card_removed(c)     ((c) && ((c)->state & MMC_CARD_REMOVED))
+#define mmc_card_doing_bkops(c) ((c)->state & MMC_STATE_DOING_BKOPS)
+#define mmc_card_suspended(c)   ((c)->state & MMC_STATE_SUSPENDED)
+
+#define mmc_card_set_present(c) ((c)->state |= MMC_STATE_PRESENT)
+#define mmc_card_set_readonly(c) ((c)->state |= MMC_STATE_READONLY)
+#define mmc_card_set_blockaddr(c) ((c)->state |= MMC_STATE_BLOCKADDR)
+#define mmc_card_set_ext_capacity(c) ((c)->state |= MMC_CARD_SDXC)
+#define mmc_card_set_removed(c) ((c)->state |= MMC_CARD_REMOVED)
+#define mmc_card_set_doing_bkops(c)     ((c)->state |= MMC_STATE_DOING_BKOPS)
+#define mmc_card_clr_doing_bkops(c)     ((c)->state &= ~MMC_STATE_DOING_BKOPS)
+#define mmc_card_set_suspended(c) ((c)->state |= MMC_STATE_SUSPENDED)
+#define mmc_card_clr_suspended(c) ((c)->state &= ~MMC_STATE_SUSPENDED)
+
+
 #endif /* LINUX_MMC_CARD_H */
diff --git a/include/linux/mmc/emmc_partitions.h b/include/linux/mmc/emmc_partitions.h
new file mode 100644
index 0000000..712c9f6
--- /dev/null
+++ b/include/linux/mmc/emmc_partitions.h
@@ -0,0 +1,78 @@
+#ifndef _EMMC_PARTITIONS_H
+#define _EMMC_PARTITIONS_H
+
+#include<linux/genhd.h>
+
+#include <linux/mmc/host.h>
+#include <linux/mmc/card.h>
+#include <linux/mmc/mmc.h>
+#include <linux/mmc/core.h>
+
+/* #include <mach/register.h> */
+/* #include <mach/am_regs.h> */
+#define CONFIG_DTB_SIZE  (256*1024U)
+#define	STORE_CODE				1
+#define	STORE_CACHE				(1<<1)
+#define	STORE_DATA				(1<<2)
+
+#define     MAX_PART_NAME_LEN               16
+#define     MAX_MMC_PART_NUM                32
+
+/* MMC Partition Table */
+#define     MMC_PARTITIONS_MAGIC            "MPT"
+#define     MMC_RESERVED_NAME               "reserved"
+
+#define     SZ_1M                           0x00100000
+
+/* the size of bootloader partition */
+#define     MMC_BOOT_PARTITION_SIZE         (4*SZ_1M)
+
+/* the size of reserve space behind bootloader partition */
+#define     MMC_BOOT_PARTITION_RESERVED     (32*SZ_1M)
+
+#define     RESULT_OK                       0
+#define     RESULT_FAIL                     1
+#define     RESULT_UNSUP_HOST               2
+#define     RESULT_UNSUP_CARD               3
+
+struct partitions {
+	/* identifier string */
+	char name[MAX_PART_NAME_LEN];
+	/* partition size, byte unit */
+	uint64_t size;
+	/* offset within the master space, byte unit */
+	uint64_t offset;
+	/* master flags to mask out for this partition */
+	unsigned mask_flags;
+};
+
+struct mmc_partitions_fmt {
+	char magic[4];
+	unsigned char version[12];
+	int part_num;
+	int checksum;
+	struct partitions partitions[MAX_MMC_PART_NUM];
+};
+/*#ifdef CONFIG_MMC_AML*/
+int aml_emmc_partition_ops(struct mmc_card *card, struct gendisk *disk);
+/*
+ *#else
+ *static inline int aml_emmc_partition_ops(struct mmc_card *card,
+ *					 struct gendisk *disk)
+ *{
+ *	return -1;
+ *}
+ *#endif
+ */
+unsigned int mmc_capacity(struct mmc_card *card);
+int mmc_read_internal(struct mmc_card *card,
+		unsigned dev_addr, unsigned blocks, void *buf);
+int mmc_write_internal(struct mmc_card *card,
+		unsigned dev_addr, unsigned blocks, void *buf);
+int get_reserve_partition_off_from_tbl(void);
+int get_reserve_partition_off(struct mmc_card *card);/* byte unit */
+
+#endif
+
+extern struct mmc_partitions_fmt *pt_fmt;
+
diff --git a/include/linux/mmc/host.h b/include/linux/mmc/host.h
index 21385ac..2ec8c22f 100644
--- a/include/linux/mmc/host.h
+++ b/include/linux/mmc/host.h
@@ -218,6 +218,9 @@ struct mmc_host {
 	unsigned int		f_min;
 	unsigned int		f_max;
 	unsigned int		f_init;
+#ifdef CONFIG_AMLOGIC_MMC
+       u8 first_init_flag;
+#endif
 	u32			ocr_avail;
 	u32			ocr_avail_sdio;	/* SDIO-specific OCR */
 	u32			ocr_avail_sd;	/* SD-specific OCR */
@@ -281,6 +284,9 @@ struct mmc_host {

 #define MMC_CAP2_BOOTPART_NOACC	(1 << 0)	/* Boot partition no access */
 #define MMC_CAP2_FULL_PWR_CYCLE	(1 << 2)	/* Can do full power cycle */
+#ifdef CONFIG_AMLOGIC_MMC
+#define MMC_CAP2_NO_MULTI_READ  (1 << 3) /* Multiblock reads don't work */
+#endif
 #define MMC_CAP2_HS200_1_8V_SDR	(1 << 5)        /* can support */
 #define MMC_CAP2_HS200_1_2V_SDR	(1 << 6)        /* can support */
 #define MMC_CAP2_HS200		(MMC_CAP2_HS200_1_8V_SDR | \
--
1.9.1
